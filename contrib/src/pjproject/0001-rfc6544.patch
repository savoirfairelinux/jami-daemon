From 85dbcd3c341057cbcb99155c0457fe1b1e48839b Mon Sep 17 00:00:00 2001
From: jrun <darwinskernel@gmail.com>
Date: Wed, 19 Feb 2020 13:57:06 -0500
Subject: [PATCH 01/12] rfc6544

---
 pjnath/include/pjnath/ice_session.h     |  265 ++-
 pjnath/include/pjnath/ice_strans.h      |   21 +
 pjnath/include/pjnath/stun_session.h    |  178 +-
 pjnath/include/pjnath/stun_sock.h       |  122 +-
 pjnath/include/pjnath/turn_sock.h       |   35 +-
 pjnath/src/pjnath-test/concur_test.c    |    6 +-
 pjnath/src/pjnath-test/sess_auth.c      |   13 +-
 pjnath/src/pjnath-test/stun_sock_test.c |   71 +-
 pjnath/src/pjnath/ice_session.c         | 2412 +++++++++++++----------
 pjnath/src/pjnath/ice_strans.c          | 1095 ++++++----
 pjnath/src/pjnath/nat_detect.c          |   65 +-
 pjnath/src/pjnath/stun_session.c        |   16 +-
 pjnath/src/pjnath/stun_sock.c           | 1215 +++++++++---
 pjnath/src/pjnath/turn_session.c        |    3 +-
 pjnath/src/pjnath/turn_sock.c           |   17 +
 pjnath/src/pjturn-client/client_main.c  |   43 +-
 pjnath/src/pjturn-srv/allocation.c      |    3 +-
 pjnath/src/pjturn-srv/server.c          |    2 +-
 pjsip-apps/src/samples/icedemo.c        |  666 ++++---
 pjsip/src/pjsua-lib/pjsua_core.c        |    2 +-
 20 files changed, 4086 insertions(+), 2164 deletions(-)

diff --git a/pjnath/include/pjnath/ice_session.h b/pjnath/include/pjnath/ice_session.h
index 8971220f0..ccf5cec54 100644
--- a/pjnath/include/pjnath/ice_session.h
+++ b/pjnath/include/pjnath/ice_session.h
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #ifndef __PJNATH_ICE_SESSION_H__
 #define __PJNATH_ICE_SESSION_H__
@@ -42,7 +42,7 @@ PJ_BEGIN_DECL
  *
  * \section pj_ice_sess_sec ICE Session
  *
- * An ICE session, represented by #pj_ice_sess structure, is the lowest 
+ * An ICE session, represented by #pj_ice_sess structure, is the lowest
  * abstraction of ICE in PJNATH, and it is used to perform and manage
  * connectivity checks of transport address candidates <b>within a
  * single media stream</b> (note: this differs from what is described
@@ -51,12 +51,12 @@ PJ_BEGIN_DECL
  *
  * The ICE session described here is independent from any transports,
  * meaning that the actual network I/O for this session would have to
- * be performed by the application, or higher layer abstraction. 
+ * be performed by the application, or higher layer abstraction.
  * Using this framework, application would give any incoming packets to
  * the ICE session, and it would provide the ICE session with a callback
  * to send outgoing message.
  *
- * For higher abstraction of ICE where transport is included, please 
+ * For higher abstraction of ICE where transport is included, please
  * see \ref PJNATH_ICE_STREAM_TRANSPORT.
  *
  * \subsection pj_ice_sess_using_sec Using The ICE Session
@@ -163,6 +163,52 @@ typedef enum pj_ice_cand_type
 
 } pj_ice_cand_type;
 
+/**
+ * ICE candidates types like described by RFC 6544.
+ */
+typedef enum pj_ice_cand_transport {
+    /**
+     * Candidates UDP compatible
+     */
+    PJ_CAND_UDP,
+    /**
+     * Candidates sending outgoing TCP connections
+     */
+    PJ_CAND_TCP_ACTIVE,
+    /**
+     * Candidates accepting incoming TCP connections
+     */
+    PJ_CAND_TCP_PASSIVE,
+    /**
+     * Candidates capable of receiving incoming connections and sending
+     * connections
+     */
+    PJ_CAND_TCP_SO
+} pj_ice_cand_transport;
+
+/**
+ * ICE transport types, which will be used both to specify the connection
+ * type for reaching candidates and other client
+ */
+typedef enum pj_ice_tp_type {
+    /**
+     * UDP transport, which value corresponds to IANA protocol number.
+     */
+    PJ_ICE_TP_UDP = 17,
+
+    /**
+     * TCP transport, which value corresponds to IANA protocol number.
+     */
+    PJ_ICE_TP_TCP = 6,
+
+    /**
+     * TLS transport. The TLS transport will only be used as the connection
+     * type to reach the server and never as the allocation transport type.
+     */
+    PJ_ICE_TP_TLS = 255
+
+} pj_ice_tp_type;
+
 
 /** Forward declaration for pj_ice_sess */
 typedef struct pj_ice_sess pj_ice_sess;
@@ -172,8 +218,8 @@ typedef struct pj_ice_sess_check pj_ice_sess_check;
 
 
 /**
- * This structure describes ICE component. 
- * A media stream may require multiple components, each of which has 
+ * This structure describes ICE component.
+ * A media stream may require multiple components, each of which has
  * to work for the media stream as a whole to work.  For media streams
  * based on RTP, there are two components per media stream - one for RTP,
  * and one for RTCP.
@@ -242,10 +288,10 @@ typedef struct pj_ice_sess_cand
      */
     pj_ice_cand_type	 type;
 
-    /** 
+    /**
      * Status of this candidate. The value will be PJ_SUCCESS if candidate
      * address has been resolved successfully, PJ_EPENDING when the address
-     * resolution process is in progress, or other value when the address 
+     * resolution process is in progress, or other value when the address
      * resolution has completed with failure.
      */
     pj_status_t		 status;
@@ -269,8 +315,8 @@ typedef struct pj_ice_sess_cand
 
     /**
      * The foundation string, which is an identifier which value will be
-     * equivalent for two candidates that are of the same type, share the 
-     * same base, and come from the same STUN server. The foundation is 
+     * equivalent for two candidates that are of the same type, share the
+     * same base, and come from the same STUN server. The foundation is
      * used to optimize ICE performance in the Frozen algorithm.
      */
     pj_str_t		 foundation;
@@ -287,16 +333,16 @@ typedef struct pj_ice_sess_cand
      * the local address of the socket. For reflexive candidates, the value
      * will be the public address allocated in NAT router for the host
      * candidate and as reported in MAPPED-ADDRESS or XOR-MAPPED-ADDRESS
-     * attribute of STUN Binding request. For relayed candidate, the value 
+     * attribute of STUN Binding request. For relayed candidate, the value
      * will be the address allocated in the TURN server by STUN Allocate
      * request.
      */
     pj_sockaddr		 addr;
 
     /**
-     * Base address of this candidate. "Base" refers to the address an agent 
+     * Base address of this candidate. "Base" refers to the address an agent
      * sends from for a particular candidate.  For host candidates, the base
-     * is the same as the host candidate itself. For reflexive candidates, 
+     * is the same as the host candidate itself. For reflexive candidates,
      * the base is the local IP address of the socket. For relayed candidates,
      * the base address is the transport address allocated in the TURN server
      * for this candidate.
@@ -309,6 +355,11 @@ typedef struct pj_ice_sess_cand
      */
     pj_sockaddr		 rel_addr;
 
+    /**
+     * Transport used (TCP or UDP)
+     */
+    pj_ice_cand_transport transport;
+
 } pj_ice_sess_cand;
 
 
@@ -324,6 +375,22 @@ typedef enum pj_ice_sess_check_state
      */
     PJ_ICE_SESS_CHECK_STATE_FROZEN,
 
+    /**
+     * The following status is used when a packet sent via TURN got a
+     * "Connection reset by peer". This mean that the peer didn't allow
+     * us to connect yet. The socket will be reconnected during the next
+     * loop.
+     */
+    PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY,
+
+    /**
+     * TODO (sblin): REMOVE THIS! - https://github.com/coturn/coturn/issues/408
+     * For now, this status is only used because sometimes, the first packet
+     * doesn't receive any response. So, we retry to send the packet every
+     * 50 loops.
+     */
+    PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET,
+
     /**
      * A check has not been performed for this pair, and can be
      * performed as soon as it is the highest priority Waiting pair on
@@ -331,6 +398,12 @@ typedef enum pj_ice_sess_check_state
      */
     PJ_ICE_SESS_CHECK_STATE_WAITING,
 
+    /**
+     * A check has not been performed for this pair, but TCP socket
+     * is currently connecting to the pair. Wait to finish the connection.
+     */
+    PJ_ICE_SESS_CHECK_STATE_PENDING,
+
     /**
      * A check has not been performed for this pair, and can be
      * performed as soon as it is the highest priority Waiting pair on
@@ -357,9 +430,9 @@ typedef enum pj_ice_sess_check_state
 
 /**
  * This structure describes an ICE connectivity check. An ICE check
- * contains a candidate pair, and will involve sending STUN Binding 
- * Request transaction for the purposes of verifying connectivity. 
- * A check is sent from the local candidate to the remote candidate 
+ * contains a candidate pair, and will involve sending STUN Binding
+ * Request transaction for the purposes of verifying connectivity.
+ * A check is sent from the local candidate to the remote candidate
  * of a candidate pair.
  */
 struct pj_ice_sess_check
@@ -385,8 +458,8 @@ struct pj_ice_sess_check
     pj_ice_sess_check_state	 state;
 
     /**
-     * STUN transmit data containing STUN Binding request that was sent 
-     * as part of this check. The value will only be set when this check 
+     * STUN transmit data containing STUN Binding request that was sent
+     * as part of this check. The value will only be set when this check
      * has a pending transaction, and is used to cancel the transaction
      * when other check has succeeded.
      */
@@ -432,7 +505,7 @@ typedef enum pj_ice_sess_checklist_state
 
 
 /**
- * This structure represents ICE check list, that is an ordered set of 
+ * This structure represents ICE check list, that is an ordered set of
  * candidate pairs that an agent will use to generate checks.
  */
 struct pj_ice_sess_checklist
@@ -486,7 +559,7 @@ typedef struct pj_ice_sess_cb
 
     /**
      * A mandatory callback which will be called by the ICE session when
-     * it needs to send outgoing STUN packet. 
+     * it needs to send outgoing STUN packet.
      *
      * @param ice	    The ICE session.
      * @param comp_id	    ICE component ID.
@@ -496,7 +569,7 @@ typedef struct pj_ice_sess_cb
      * @param dst_addr	    Packet destination address.
      * @param dst_addr_len  Length of destination address.
      */
-    pj_status_t (*on_tx_pkt)(pj_ice_sess *ice, unsigned comp_id, 
+    pj_status_t (*on_tx_pkt)(pj_ice_sess *ice, unsigned comp_id,
 			     unsigned transport_id,
 			     const void *pkt, pj_size_t size,
 			     const pj_sockaddr_t *dst_addr,
@@ -511,15 +584,65 @@ typedef struct pj_ice_sess_cb
      * @param transport_id  Transport ID.
      * @param pkt	    The whole packet.
      * @param size	    Size of the packet.
-     * @param src_addr	    Source address where this packet was received 
+     * @param src_addr	    Source address where this packet was received
      *			    from.
      * @param src_addr_len  The length of source address.
      */
     void	(*on_rx_data)(pj_ice_sess *ice, unsigned comp_id,
-			      unsigned transport_id, 
+			      unsigned transport_id,
 			      void *pkt, pj_size_t size,
 			      const pj_sockaddr_t *src_addr,
 			      unsigned src_addr_len);
+
+    /**
+     * Wait for TCP and send connectivity check
+     *
+     * @param ice			The ICE session.
+     * @param clist			The ICE connection list
+     * @param check_id		The wanted check.
+     */
+    pj_status_t (*wait_tcp_connection)(pj_ice_sess *ice,
+                                       pj_ice_sess_checklist *clist,
+                                       unsigned check_id);
+
+    /**
+     * Select incoming TURN dataconn
+     *
+     * @param ice			The ICE session.
+     * @param clist			The ICE connection list
+     * @param check_id		The wanted check.
+     */
+    pj_status_t (*select_turn_dataconn)(pj_ice_sess *ice,
+                                        pj_ice_sess_checklist *clist,
+                                        unsigned check_id);
+
+    /**
+     * Reconnect a resetted TCP connection and send connectivity check
+     * cf. PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY
+     *
+     * @param ice			The ICE session.
+     * @param clist			The ICE connection list
+     * @param check_id		The wanted check.
+     */
+    pj_status_t (*reconnect_tcp_connection)(pj_ice_sess *ice,
+                                            pj_ice_sess_checklist *clist,
+                                            unsigned check_id);
+
+    /**
+     * Close TCP socket
+     *
+     * @param ice			The ICE session.
+     * @param clist			The ICE connection list
+     * @param check_id		The wanted check.
+     */
+    pj_status_t (*close_tcp_connection)(pj_ice_sess *ice,
+                                        pj_ice_sess_checklist *clist,
+                                        unsigned check_id);
+    /**
+     * If an internal TCP keep alive, this mount the error to the application
+     */
+    void	(*on_ice_destroy)(pj_ice_sess *ice);
+
 } pj_ice_sess_cb;
 
 
@@ -574,7 +697,7 @@ typedef struct pj_ice_rx_check
 
 /**
  * This structure describes various ICE session options. Application
- * configure the ICE session with these options by calling 
+ * configure the ICE session with these options by calling
  * #pj_ice_sess_set_options().
  */
 typedef struct pj_ice_sess_options
@@ -586,7 +709,7 @@ typedef struct pj_ice_sess_options
 
     /**
      * For controlling agent if it uses regular nomination, specify the delay
-     * to perform nominated check (connectivity check with USE-CANDIDATE 
+     * to perform nominated check (connectivity check with USE-CANDIDATE
      * attribute) after all components have a valid pair.
      *
      * Default value is PJ_ICE_NOMINATED_CHECK_DELAY.
@@ -594,14 +717,14 @@ typedef struct pj_ice_sess_options
     unsigned		nominated_check_delay;
 
     /**
-     * For a controlled agent, specify how long it wants to wait (in 
-     * milliseconds) for the controlling agent to complete sending 
+     * For a controlled agent, specify how long it wants to wait (in
+     * milliseconds) for the controlling agent to complete sending
      * connectivity check with nominated flag set to true for all components
      * after the controlled agent has found that all connectivity checks in
      * its checklist have been completed and there is at least one successful
      * (but not nominated) check for every component.
      *
-     * Default value for this option is 
+     * Default value for this option is
      * ICE_CONTROLLED_AGENT_WAIT_NOMINATION_TIMEOUT. Specify -1 to disable
      * this timer.
      */
@@ -636,6 +759,7 @@ struct pj_ice_sess
     pj_bool_t            valid_pair_found;          /**< First pair found   */
     pj_status_t		 ice_status;		    /**< Error status.	    */
     pj_timer_entry	 timer;			    /**< ICE timer.	    */
+    pj_timer_entry	 timer_connect;			    /**< ICE timer tcp timeout	    */
     pj_ice_sess_cb	 cb;			    /**< Callback.	    */
 
     pj_stun_config	 stun_cfg;		    /**< STUN settings.	    */
@@ -669,10 +793,10 @@ struct pj_ice_sess
 
     /* Checklist */
     pj_ice_sess_checklist clist;		    /**< Active checklist   */
-    
+
     /* Valid list */
     pj_ice_sess_checklist valid_list;		    /**< Valid list.	    */
-    
+
     /** Temporary buffer for misc stuffs to avoid using stack too much */
     union {
     	char txt[128];
@@ -741,7 +865,7 @@ PJ_DECL(void) pj_ice_sess_options_default(pj_ice_sess_options *opt);
  * @param cb		ICE callback.
  * @param local_ufrag	Optional string to be used as local username to
  *			authenticate incoming STUN binding request. If
- *			the value is NULL, a random string will be 
+ *			the value is NULL, a random string will be
  *			generated.
  * @param local_passwd	Optional string to be used as local password.
  * @param grp_lock	Optional group lock to be used by this session.
@@ -818,8 +942,8 @@ PJ_DECL(pj_status_t) pj_ice_sess_change_role(pj_ice_sess *ice,
 /**
  * Assign a custom preference values for ICE candidate types. By assigning
  * custom preference value, application can control the order of candidates
- * to be checked first. The default preference settings is to use 126 for 
- * host candidates, 100 for server reflexive candidates, 110 for peer 
+ * to be checked first. The default preference settings is to use 126 for
+ * host candidates, 100 for server reflexive candidates, 110 for peer
  * reflexive candidates, an 0 for relayed candidates.
  *
  * Note that this function must be called before any candidates are added
@@ -839,7 +963,7 @@ PJ_DECL(pj_status_t) pj_ice_sess_set_prefs(pj_ice_sess *ice,
 
 /**
  * Add a candidate to this ICE session. Application must add candidates for
- * each components ID before it can start pairing the candidates and 
+ * each components ID before it can start pairing the candidates and
  * performing connectivity checks.
  *
  * @param ice		ICE session instance.
@@ -855,6 +979,7 @@ PJ_DECL(pj_status_t) pj_ice_sess_set_prefs(pj_ice_sess *ice,
  * @param rel_addr	Optional related address.
  * @param addr_len	Length of addresses.
  * @param p_cand_id	Optional pointer to receive the candidate ID.
+ * @param transport	Candidate's type
  *
  * @return		PJ_SUCCESS if candidate is successfully added.
  */
@@ -868,14 +993,15 @@ PJ_DECL(pj_status_t) pj_ice_sess_add_cand(pj_ice_sess *ice,
 					  const pj_sockaddr_t *base_addr,
 					  const pj_sockaddr_t *rel_addr,
 					  int addr_len,
-					  unsigned *p_cand_id);
+					  unsigned *p_cand_id,
+					  pj_ice_cand_transport transport);
 
 /**
  * Find default candidate for the specified component ID, using this
  * rule:
  *  - if the component has a successful candidate pair, then the
  *    local candidate of this pair will be returned.
- *  - otherwise a relay, reflexive, or host candidate will be selected 
+ *  - otherwise a relay, reflexive, or host candidate will be selected
  *    on that specified order.
  *
  * @param ice		The ICE session instance.
@@ -898,23 +1024,23 @@ PJ_DECL(pj_status_t) pj_ice_sess_find_default_cand(pj_ice_sess *ice,
  * #pj_ice_sess_start_check().
  *
  * @param ice		ICE session instance.
- * @param rem_ufrag	Remote ufrag, as seen in the SDP received from 
+ * @param rem_ufrag	Remote ufrag, as seen in the SDP received from
  *			the remote agent.
  * @param rem_passwd	Remote password, as seen in the SDP received from
  *			the remote agent.
  * @param rem_cand_cnt	Number of remote candidates.
  * @param rem_cand	Remote candidate array. Remote candidates are
- *			gathered from the SDP received from the remote 
+ *			gathered from the SDP received from the remote
  *			agent.
  *
  * @return		PJ_SUCCESS or the appropriate error code.
  */
-PJ_DECL(pj_status_t) 
-pj_ice_sess_create_check_list(pj_ice_sess *ice,
-			      const pj_str_t *rem_ufrag,
-			      const pj_str_t *rem_passwd,
-			      unsigned rem_cand_cnt,
-			      const pj_ice_sess_cand rem_cand[]);
+PJ_DECL(pj_status_t)
+    pj_ice_sess_create_check_list(pj_ice_sess *ice,
+				  const pj_str_t *rem_ufrag,
+				  const pj_str_t *rem_passwd,
+				  unsigned rem_cand_cnt,
+				  const pj_ice_sess_cand rem_cand[]);
 
 /**
  * Start ICE periodic check. This function will return immediately, and
@@ -980,6 +1106,55 @@ PJ_DECL(pj_status_t) pj_ice_sess_on_rx_pkt(pj_ice_sess *ice,
 					   const pj_sockaddr_t *src_addr,
 					   int src_addr_len);
 
+/**
+ * Notification when ICE session get a new incoming connection
+ *
+ * @param ice          The ICE session.
+ * @param transport_id Related transport
+ * @param status       PJ_SUCCESS when connection is made, or any errors
+ *                     if the connection has failed (or if the peer has
+ *                     disconnected after an established connection).
+ * @param remote_addr  Connected remove address
+ */
+PJ_DECL(void) ice_sess_on_peer_connection(pj_ice_sess *ice,
+					  pj_uint8_t transport_id,
+					  pj_status_t status,
+					  pj_sockaddr_t* remote_addr);
+
+/**
+ * Notification when ICE session get a new resetted connection
+ * cf PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY
+ *
+ * @param ice          The ICE session.
+ * @param transport_id Related transport
+ * @param remote_addr  Connected remove address
+ */
+PJ_DECL(void) ice_sess_on_peer_reset_connection(pj_ice_sess *ice,
+						pj_uint8_t transport_id,
+						pj_sockaddr_t* remote_addr);
+
+/**
+ * Notification when ICE session get a new packet
+ * Used to remove the PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET status
+ *
+ * @param ice          The ICE session.
+ * @param transport_id Related transport
+ * @param remote_addr  Connected remove address
+ */
+PJ_DECL(void) ice_sess_on_peer_packet(pj_ice_sess *ice,
+				      pj_uint8_t transport_id,
+				      pj_sockaddr_t* remote_addr);
+
+/**
+ * Select dataconn from TURN
+ *
+ * @param ice          The ICE session.
+ * @param clist        The ice check list
+ * @param check_id     The wanted check
+ */
+PJ_DECL(void) ice_select_incoming_turn(pj_ice_sess *ice,
+				       pj_ice_sess_checklist *clist,
+				       unsigned check_id);
 
 
 /**
diff --git a/pjnath/include/pjnath/ice_strans.h b/pjnath/include/pjnath/ice_strans.h
index d0af76679..9eb74b35f 100644
--- a/pjnath/include/pjnath/ice_strans.h
+++ b/pjnath/include/pjnath/ice_strans.h
@@ -274,6 +274,13 @@ typedef struct pj_ice_strans_stun_cfg
      */
     pj_bool_t		 ignore_stun_error;
 
+    /**
+     * Type of connection to the STUN server.
+     *
+     * Default is PJ_STUN_TP_UDP.
+     */
+    pj_stun_tp_type conn_type;
+
 } pj_ice_strans_stun_cfg;
 
 
@@ -289,6 +296,13 @@ typedef struct pj_ice_strans_turn_cfg
      */
     int			 af;
 
+    /**
+     * If we want to use UDP or TCP as described by RFC 6544.
+     * This will discover candidates via TCP sockets. Then it will
+     * transfer messages on the transport via TCP.
+     */
+    pj_ice_tp_type protocol;
+
     /**
      * Optional TURN socket settings. The default values will be
      * initialized by #pj_turn_sock_cfg_default(). This contains
@@ -368,6 +382,13 @@ typedef struct pj_ice_strans_cfg
      */
     int			 af;
 
+    /**
+     * If we want to use UDP or TCP as described by RFC 6544.
+     * This will discover candidates via TCP sockets. Then it will
+     * transfer messages on the transport via TCP.
+     */
+    pj_ice_tp_type protocol;
+
     /**
      * STUN configuration which contains the timer heap and
      * ioqueue instance to be used, and STUN retransmission
diff --git a/pjnath/include/pjnath/stun_session.h b/pjnath/include/pjnath/stun_session.h
index bee630ab4..5b8bb8e62 100644
--- a/pjnath/include/pjnath/stun_session.h
+++ b/pjnath/include/pjnath/stun_session.h
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #ifndef __PJNATH_STUN_SESSION_H__
 #define __PJNATH_STUN_SESSION_H__
@@ -41,26 +41,26 @@ PJ_BEGIN_DECL
  * @addtogroup PJNATH_STUN_SESSION
  * @{
  *
- * This is is a transport-independent object to manage a client or server 
+ * This is is a transport-independent object to manage a client or server
  * STUN session. It has the following features:
- * 
+ *
  *  - <b>transport independent</b>:\n
  *    the object does not have it's own socket, but rather it provides
  *    functions and callbacks to send and receive packets. This way the
- *    object can be used by different transport types (e.g. UDP, TCP, 
+ *    object can be used by different transport types (e.g. UDP, TCP,
  *    TLS, etc.) as well as better integration to application which
  *    already has its own means to send and receive packets.
- * 
+ *
  *  - <b>authentication management</b>:\n
  *    the object manages STUN authentication throughout the lifetime of
  *    the session. For client sessions, once it's given a credential to
  *    authenticate itself with the server, the object will automatically
  *    add authentication info (the MESSAGE-INTEGRITY) to the request as
- *    well as authenticate the response. It will also handle long-term 
+ *    well as authenticate the response. It will also handle long-term
  *    authentication challenges, including handling of nonce expiration,
- *    and retry the request automatically. For server sessions, it can 
+ *    and retry the request automatically. For server sessions, it can
  *    be configured to authenticate incoming requests automatically.
- *  
+ *
  *  - <b>static or dynamic credential</b>:\n
  *    application may specify static or dynamic credential to be used by
  *    the STUN session. Static credential means a static combination of
@@ -68,16 +68,16 @@ PJ_BEGIN_DECL
  *    duration), while dynamic credential provides callback to ask the
  *    application about which username/password to use everytime
  *    authentication is about to be performed.
- *    
+ *
  *  - <b>client transaction management</b>:\n
  *    outgoing requests may be sent with a STUN transaction for reliability,
  *    and the object will manage the transaction internally (including
  *    performing retransmissions). Application will be notified about the
  *    result of the request when the response arrives (or the transaction
  *    times out). When the request is challenged with authentication, the
- *    object will retry the request with new authentication info, and 
+ *    object will retry the request with new authentication info, and
  *    application will be notified about the final result of this request.
- * 
+ *
  *  - <b>server transaction management</b>:\n
  *    application may ask response to incoming requests to be cached by
  *    the object, and in this case the object will check for cached
@@ -96,7 +96,7 @@ PJ_BEGIN_DECL
  *
  *  - <b>create the STUN session</b>:\n
  *    by calling #pj_stun_session_create(). Among other things, this
- *    function requires the instance of #pj_stun_config and also 
+ *    function requires the instance of #pj_stun_config and also
  *    #pj_stun_session_cb structure which stores callbacks to send
  *    outgoing packets as well as to notify application about incoming
  *    STUN requests, responses, and indicates and other events.
@@ -125,8 +125,8 @@ PJ_BEGIN_DECL
  *    use #pj_stun_session_send_msg() to send outgoing STUN messages (this
  *    includes STUN requests, indications, and responses). The function has
  *    options whether to retransmit the request (for non reliable transports)
- *    or to cache the response if we're sending response. This function in 
- *    turn will call the \a on_send_msg() callback of #pj_stun_session_cb 
+ *    or to cache the response if we're sending response. This function in
+ *    turn will call the \a on_send_msg() callback of #pj_stun_session_cb
  *    to request the application to send the packet.
  *
  *  - <b>handling incoming packet:</b>\n
@@ -147,7 +147,7 @@ PJ_BEGIN_DECL
  *
  *  - <b>creating and sending response:</b>\n
  *    create the STUN response with #pj_stun_session_create_res(). This will
- *    create a transmit data buffer containing a blank STUN response. You 
+ *    create a transmit data buffer containing a blank STUN response. You
  *    will then typically need to add STUN attributes that are relevant to
  *    the response, but note that some default attributes will
  *    be added by the session later when the message is sent (such as
@@ -158,7 +158,7 @@ PJ_BEGIN_DECL
  *  - <b>convenient way to send response:</b>\n
  *    the #pj_stun_session_respond() is provided as a convenient way to
  *    create and send simple STUN responses, such as error responses.
- *    
+ *
  *  - <b>destroying the session:</b>\n
  *    once the session is done, use #pj_stun_session_destroy() to destroy
  *    the session.
@@ -174,6 +174,29 @@ typedef struct pj_stun_rx_data pj_stun_rx_data;
 /** Forward declaration for pj_stun_session */
 typedef struct pj_stun_session pj_stun_session;
 
+/**
+ * STUN transport types, which will be used both to specify the connection
+ * type for reaching STUN server and the type of allocation transport to be
+ * requested to server (the REQUESTED-TRANSPORT attribute).
+ */
+typedef enum pj_stun_tp_type {
+    /**
+     * UDP transport, which value corresponds to IANA protocol number.
+     */
+    PJ_STUN_TP_UDP = 17,
+
+    /**
+     * TCP transport, which value corresponds to IANA protocol number.
+     */
+    PJ_STUN_TP_TCP = 6,
+
+    /**
+     * TLS transport. The TLS transport will only be used as the connection
+     * type to reach the server and never as the allocation transport type.
+     */
+    PJ_STUN_TP_TLS = 255
+
+} pj_stun_tp_type;
 
 /**
  * This is the callback to be registered to pj_stun_session, to send
@@ -187,7 +210,7 @@ typedef struct pj_stun_session_cb
      *
      * @param sess	    The STUN session.
      * @param token	    The token associated with this outgoing message
-     *			    and was set by the application. This token was 
+     *			    and was set by the application. This token was
      *			    set by application in pj_stun_session_send_msg()
      *			    for outgoing messages that are initiated by the
      *			    application, or in pj_stun_session_on_rx_pkt()
@@ -210,11 +233,11 @@ typedef struct pj_stun_session_cb
 			       const pj_sockaddr_t *dst_addr,
 			       unsigned addr_len);
 
-    /** 
+    /**
      * Callback to be called on incoming STUN request message. This function
      * is called when application calls pj_stun_session_on_rx_pkt() and when
      * the STUN session has detected that the incoming STUN message is a
-     * STUN request message. In the 
+     * STUN request message. In the
      * callback processing, application MUST create a response by calling
      * pj_stun_session_create_response() function and send the response
      * with pj_stun_session_send_msg() function, before returning from
@@ -242,7 +265,7 @@ typedef struct pj_stun_session_cb
 				 unsigned src_addr_len);
 
     /**
-     * Callback to be called when response is received or the transaction 
+     * Callback to be called when response is received or the transaction
      * has timed out. This callback is called either when application calls
      * pj_stun_session_on_rx_pkt() with the packet containing a STUN
      * response for the client transaction, or when the internal timer of
@@ -255,7 +278,7 @@ typedef struct pj_stun_session_cb
      *			    or other error has occurred, and the response
      *			    argument may be NULL.
      *			    Note that when the status is not success, the
-     *			    response may contain non-NULL value if the 
+     *			    response may contain non-NULL value if the
      *			    response contains STUN ERROR-CODE attribute.
      * @param token	    The token that was set by the application  when
      *			    calling pj_stun_session_send_msg() function.
@@ -265,9 +288,9 @@ typedef struct pj_stun_session_cb
      * @param response	    The response message, on successful transaction,
      *			    or otherwise MAY BE NULL if status is not success.
      *			    Note that when the status is not success, this
-     *			    argument may contain non-NULL value if the 
+     *			    argument may contain non-NULL value if the
      *			    response contains STUN ERROR-CODE attribute.
-     * @param src_addr	    The source address where the response was 
+     * @param src_addr	    The source address where the response was
      *			    received, or NULL if the response is NULL.
      * @param src_addr_len  The length of the source  address.
      */
@@ -307,6 +330,38 @@ typedef struct pj_stun_session_cb
 				    const pj_sockaddr_t *src_addr,
 				    unsigned src_addr_len);
 
+    /**
+     * Notification when STUN session get a ConnectionAttempt indication.
+     *
+     * @param stun_session  The STUN session.
+     * @param status        PJ_SUCCESS when connection is made, or any errors
+     *                      if the connection has failed (or if the peer has
+     *                      disconnected after an established connection).
+     * @param remote_addr   The remote connected
+     */
+    void (*on_peer_connection)(pj_stun_session *sess,
+                               pj_status_t status,
+                               pj_sockaddr_t* remote_addr);
+
+    /**
+     * Notification when STUN connection is resetted (TCP only).
+     *
+     * @param stun_session  The STUN session.
+     * @param remote_addr   The remote resetted
+     */
+    void (*on_peer_reset_connection)(pj_stun_session *sess,
+                                     pj_sockaddr_t*
+                                     remote_addr);
+
+    /**
+     * Notification when STUN connection is resetted (TCP only).
+     *
+     * @param stun_session  The STUN session.
+     * @param remote_addr   The remote resetted
+     */
+    void (*on_peer_packet)(pj_stun_session *sess,
+                           pj_sockaddr_t* remote_addr);
+
 } pj_stun_session_cb;
 
 
@@ -321,8 +376,8 @@ struct pj_stun_rx_data
     pj_stun_msg		    *msg;
 
     /**
-     * Credential information that is found and used to authenticate 
-     * incoming request. Application may use this information when 
+     * Credential information that is found and used to authenticate
+     * incoming request. Application may use this information when
      * generating  authentication for the outgoing response.
      */
     pj_stun_req_cred_info   info;
@@ -348,7 +403,7 @@ struct pj_stun_tx_data
     pj_bool_t		 retransmit;	/**< Retransmit request?	    */
     pj_uint32_t		 msg_magic;	/**< Message magic.		    */
     pj_uint8_t		 msg_key[12];	/**< Message/transaction key.	    */
-    
+
     pj_grp_lock_t	*grp_lock;	/**< Group lock (for resp cache).   */
 
     pj_stun_req_cred_info auth_info;	/**< Credential info		    */
@@ -390,15 +445,17 @@ typedef enum pj_stun_sess_msg_log_flag
  * @param grp_lock	Optional group lock to be used by this session.
  * 			If NULL, the session will create one itself.
  * @param p_sess	Pointer to receive STUN session instance.
+ * @param conn_type	If the session use UDP or TCP
  *
- * @return	    PJ_SUCCESS on success, or the appropriate error code.
+ * @return		PJ_SUCCESS on success, or the appropriate error code.
  */
 PJ_DECL(pj_status_t) pj_stun_session_create(pj_stun_config *cfg,
 					    const char *name,
 					    const pj_stun_session_cb *cb,
 					    pj_bool_t fingerprint,
-					    pj_grp_lock_t *grp_lock,
-					    pj_stun_session **p_sess);
+                                            pj_grp_lock_t *grp_lock,
+                                            pj_stun_session **p_sess,
+                                            pj_stun_tp_type conn_type);
 
 /**
  * Destroy the STUN session and all objects created in the context of
@@ -499,7 +556,7 @@ PJ_DECL(pj_bool_t) pj_stun_session_use_fingerprint(pj_stun_session *sess,
 
 /**
  * Create a STUN request message. After the message has been successfully
- * created, application can send the message by calling 
+ * created, application can send the message by calling
  * pj_stun_session_send_msg().
  *
  * @param sess	    The STUN session instance.
@@ -520,7 +577,7 @@ PJ_DECL(pj_status_t) pj_stun_session_create_req(pj_stun_session *sess,
 
 /**
  * Create a STUN Indication message. After the message  has been successfully
- * created, application can send the message by calling 
+ * created, application can send the message by calling
  * pj_stun_session_send_msg().
  *
  * @param sess	    The STUN session instance.
@@ -537,8 +594,8 @@ PJ_DECL(pj_status_t) pj_stun_session_create_ind(pj_stun_session *sess,
 					        pj_stun_tx_data **p_tdata);
 
 /**
- * Create a STUN response message. After the message has been 
- * successfully created, application can send the message by calling 
+ * Create a STUN response message. After the message has been
+ * successfully created, application can send the message by calling
  * pj_stun_session_send_msg(). Alternatively application may use
  * pj_stun_session_respond() to create and send response in one function
  * call.
@@ -576,8 +633,8 @@ PJ_DECL(pj_status_t) pj_stun_session_create_res(pj_stun_session *sess,
  * @param sess	    The STUN session instance.
  * @param token	    Optional token which will be given back to application in
  *		    \a on_send_msg() callback and \a on_request_complete()
- *		    callback, if the message is a STUN request message. 
- *		    Internally this function will put the token in the 
+ *		    callback, if the message is a STUN request message.
+ *		    Internally this function will put the token in the
  *		    \a token field of pj_stun_tx_data, hence it will
  *		    overwrite any value that the application puts there.
  * @param cache_res If the message is a response message for an incoming
@@ -595,8 +652,8 @@ PJ_DECL(pj_status_t) pj_stun_session_create_res(pj_stun_session *sess,
  *		    be sent.
  *
  * @return	    PJ_SUCCESS on success, or the appropriate error code.
- *		    This function will return PJNATH_ESTUNDESTROYED if 
- *		    application has destroyed the session in 
+ *		    This function will return PJNATH_ESTUNDESTROYED if
+ *		    application has destroyed the session in
  *		    \a on_send_msg() callback.
  */
 PJ_DECL(pj_status_t) pj_stun_session_send_msg(pj_stun_session *sess,
@@ -625,30 +682,30 @@ PJ_DECL(pj_status_t) pj_stun_session_send_msg(pj_stun_session *sess,
  *		    be used.
  * @param token	    Optional token which will be given back to application in
  *		    \a on_send_msg() callback and \a on_request_complete()
- *		    callback, if the message is a STUN request message. 
- *		    Internally this function will put the token in the 
+ *		    callback, if the message is a STUN request message.
+ *		    Internally this function will put the token in the
  *		    \a token field of pj_stun_tx_data, hence it will
  *		    overwrite any value that the application puts there.
  * @param cache	    Specify whether session should cache this response for
  *		    future request retransmission. If TRUE, subsequent request
- *		    retransmission will be handled by the session and it 
+ *		    retransmission will be handled by the session and it
  *		    will not call request callback.
  * @param dst_addr  Destination address of the response (or equal to the
  *		    source address of the original request).
  * @param addr_len  Address length.
  *
  * @return	    PJ_SUCCESS on success, or the appropriate error code.
- *		    This function will return PJNATH_ESTUNDESTROYED if 
- *		    application has destroyed the session in 
+ *		    This function will return PJNATH_ESTUNDESTROYED if
+ *		    application has destroyed the session in
  *		    \a on_send_msg() callback.
  */
-PJ_DECL(pj_status_t) pj_stun_session_respond(pj_stun_session *sess, 
+PJ_DECL(pj_status_t) pj_stun_session_respond(pj_stun_session *sess,
 					     const pj_stun_rx_data *rdata,
-					     unsigned code, 
+					     unsigned code,
 					     const char *err_msg,
 					     void *token,
-					     pj_bool_t cache, 
-					     const pj_sockaddr_t *dst_addr, 
+					     pj_bool_t cache,
+					     const pj_sockaddr_t *dst_addr,
 					     unsigned addr_len);
 
 /**
@@ -665,8 +722,8 @@ PJ_DECL(pj_status_t) pj_stun_session_respond(pj_stun_session *sess,
  *		    callback. This error status MUST NOT be PJ_SUCCESS.
  *
  * @return	    PJ_SUCCESS if transaction is successfully cancelled.
- *		    This function will return PJNATH_ESTUNDESTROYED if 
- *		    application has destroyed the session in 
+ *		    This function will return PJNATH_ESTUNDESTROYED if
+ *		    application has destroyed the session in
  *		    \a on_request_complete() callback.
  */
 PJ_DECL(pj_status_t) pj_stun_session_cancel_req(pj_stun_session *sess,
@@ -685,7 +742,7 @@ PJ_DECL(pj_status_t) pj_stun_session_cancel_req(pj_stun_session *sess,
  *                  needs to be incremented.
  *
  * @return	    PJ_SUCCESS on success, or the appropriate error.
- *		    This function will return PJNATH_ESTUNDESTROYED if 
+ *		    This function will return PJNATH_ESTUNDESTROYED if
  *		    application has destroyed the session in \a on_send_msg()
  *		    callback.
  */
@@ -716,8 +773,8 @@ PJ_DECL(pj_status_t) pj_stun_session_retransmit_req(pj_stun_session *sess,
  *			STUN message (useful if packet is received via a
  *			stream oriented protocol).
  * @param token		Optional token which will be given back to application
- *			in the \a on_rx_request(), \a on_rx_indication() and 
- *			\a on_send_msg() callbacks. The token can be used to 
+ *			in the \a on_rx_request(), \a on_rx_indication() and
+ *			\a on_send_msg() callbacks. The token can be used to
  *			associate processing or incoming request or indication
  *			with some context.
  * @param src_addr	The source address of the packet, which will also
@@ -726,7 +783,7 @@ PJ_DECL(pj_status_t) pj_stun_session_retransmit_req(pj_stun_session *sess,
  * @param src_addr_len	Length of the source address.
  *
  * @return		PJ_SUCCESS on success, or the appropriate error code.
- *			This function will return PJNATH_ESTUNDESTROYED if 
+ *			This function will return PJNATH_ESTUNDESTROYED if
  *			application has destroyed the session in one of the
  *			callback.
  */
@@ -752,6 +809,21 @@ PJ_DECL(pj_status_t) pj_stun_session_on_rx_pkt(pj_stun_session *sess,
 PJ_DECL(void) pj_stun_msg_destroy_tdata(pj_stun_session *sess,
 					pj_stun_tx_data *tdata);
 
+/**
+ *
+ * @param sess     The STUN session.
+ *
+ * @return         The callback linked to the STUN session
+ */
+PJ_DECL(pj_stun_session_cb *) pj_stun_session_callback(pj_stun_session *sess);
+
+/**
+ *
+ * @param sess     The STUN session.
+ *
+ * @return         The connection type linked to the STUN session
+ */
+PJ_DECL(pj_stun_tp_type) pj_stun_session_tp_type(pj_stun_session *sess);
 
 /**
  * @}
diff --git a/pjnath/include/pjnath/stun_sock.h b/pjnath/include/pjnath/stun_sock.h
index fff4df885..8d0bc0d6d 100644
--- a/pjnath/include/pjnath/stun_sock.h
+++ b/pjnath/include/pjnath/stun_sock.h
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #ifndef __PJNATH_STUN_SOCK_H__
 #define __PJNATH_STUN_SOCK_H__
@@ -24,10 +24,14 @@
  * @file stun_sock.h
  * @brief STUN aware socket transport
  */
+#include <pj/activesock.h>
 #include <pjnath/stun_config.h>
+#include <pjnath/stun_session.h>
 #include <pjlib-util/resolver.h>
+#include <pjlib-util/srv_resolver.h>
 #include <pj/ioqueue.h>
 #include <pj/lock.h>
+#include <pj/pool.h>
 #include <pj/sock.h>
 #include <pj/sock_qos.h>
 
@@ -87,7 +91,17 @@ typedef enum pj_stun_sock_op
     /**
      * IP address change notification from the keep-alive operation.
      */
-    PJ_STUN_SOCK_MAPPED_ADDR_CHANGE
+    PJ_STUN_SOCK_MAPPED_ADDR_CHANGE,
+
+    /**
+     * STUN session was destroyed.
+     */
+    PJ_STUN_SESS_DESTROYED,
+
+    /**
+     * TCP fails to connect
+     */
+    PJ_STUN_TCP_CONNECT_ERROR
 
 
 } pj_stun_sock_op;
@@ -144,7 +158,7 @@ typedef struct pj_stun_sock_cb
      * callback may be called for the following conditions:
      *	- the first time the publicly mapped address has been resolved from
      *	  the STUN server, this callback will be called with \a op argument
-     *    set to PJ_STUN_SOCK_BINDING_OP \a status  argument set to 
+     *    set to PJ_STUN_SOCK_BINDING_OP \a status  argument set to
      *    PJ_SUCCESS.
      *	- anytime when the transport has detected that the publicly mapped
      *    address has changed, this callback will be called with \a op
@@ -153,7 +167,7 @@ typedef struct pj_stun_sock_cb
      *    application will get the resolved public address in the
      *    #pj_stun_sock_info structure.
      *	- for any terminal error (such as STUN time-out, DNS resolution
-     *    failure, or keep-alive failure), this callback will be called 
+     *    failure, or keep-alive failure), this callback will be called
      *	  with the \a status argument set to non-PJ_SUCCESS.
      *
      * @param stun_sock	The STUN transport.
@@ -167,7 +181,7 @@ typedef struct pj_stun_sock_cb
      *			should return PJ_TRUE to let the STUN socket operation
      *			continues.
      */
-    pj_bool_t	(*on_status)(pj_stun_sock *stun_sock, 
+    pj_bool_t	(*on_status)(pj_stun_sock *stun_sock,
 			     pj_stun_sock_op op,
 			     pj_status_t status);
 
@@ -178,35 +192,45 @@ typedef struct pj_stun_sock_cb
  * This structure contains information about the STUN transport. Application
  * may query this information by calling #pj_stun_sock_get_info().
  */
-typedef struct pj_stun_sock_info
+typedef             struct pj_stun_sock_info
 {
     /**
      * The bound address of the socket.
      */
-    pj_sockaddr	    bound_addr;
+    pj_sockaddr     bound_addr;
 
     /**
      * IP address of the STUN server.
      */
-    pj_sockaddr	    srv_addr;
+    pj_sockaddr     srv_addr;
 
     /**
      * The publicly mapped address. It may contain zero address when the
      * mapped address has not been resolved. Application may query whether
      * this field contains valid address with pj_sockaddr_has_addr().
      */
-    pj_sockaddr	    mapped_addr;
+    pj_sockaddr     mapped_addr;
+
+    /**
+     * If connected, the remote address will be stored here.
+     */
+    pj_sockaddr     outgoing_addr;
 
     /**
      * Number of interface address aliases. The interface address aliases
      * are list of all interface addresses in this host.
      */
-    unsigned	    alias_cnt;
+    unsigned        alias_cnt;
 
     /**
      * Array of interface address aliases.
      */
-    pj_sockaddr	    aliases[PJ_ICE_ST_MAX_CAND];
+    pj_sockaddr     aliases[PJ_ICE_ST_MAX_CAND];
+
+    /**
+     * The tranport type of the socket
+     */
+    pj_stun_tp_type conn_type;
 
 } pj_stun_sock_info;
 
@@ -263,7 +287,7 @@ typedef struct pj_stun_sock_cfg
 
     /**
      * Specify the STUN keep-alive duration, in seconds. The STUN transport
-     * does keep-alive by sending STUN Binding request to the STUN server. 
+     * does keep-alive by sending STUN Binding request to the STUN server.
      * If this value is zero, the PJ_STUN_KEEP_ALIVE_SEC value will be used.
      * If the value is negative, it will disable STUN keep-alive.
      */
@@ -342,7 +366,8 @@ PJ_DECL(void) pj_stun_sock_cfg_default(pj_stun_sock_cfg *cfg);
  *			things the ioqueue and timer heap instance for
  *			the operation of this transport.
  * @param af		Address family of socket. Currently pj_AF_INET()
- *			and pj_AF_INET6() are supported. 
+ *			and pj_AF_INET6() are supported.
+ * @param conn_type     Connection type to the STUN server. Both TCP and UDP are supported.
  * @param name		Optional name to be given to this transport to
  *			assist debugging.
  * @param cb		Callback to receive events/data from the transport.
@@ -355,12 +380,13 @@ PJ_DECL(void) pj_stun_sock_cfg_default(pj_stun_sock_cfg *cfg);
  *			or the appropriate error code on failure.
  */
 PJ_DECL(pj_status_t) pj_stun_sock_create(pj_stun_config *stun_cfg,
-					 const char *name,
-					 int af,
-					 const pj_stun_sock_cb *cb,
-					 const pj_stun_sock_cfg *cfg,
-					 void *user_data,
-					 pj_stun_sock **p_sock);
+                                         const char *name,
+                                         int af,
+                                         pj_stun_tp_type conn_type,
+                                         const pj_stun_sock_cb *cb,
+                                         const pj_stun_sock_cfg *cfg,
+                                         void *user_data,
+                                         pj_stun_sock **p_sock);
 
 
 /**
@@ -454,7 +480,7 @@ PJ_DECL(pj_grp_lock_t *) pj_stun_sock_get_grp_lock(pj_stun_sock *stun_sock);
  *			or the appropriate error code on failure.
  */
 PJ_DECL(pj_status_t) pj_stun_sock_get_info(pj_stun_sock *stun_sock,
-					   pj_stun_sock_info *info);
+                                           pj_stun_sock_info *info);
 
 
 /**
@@ -476,14 +502,54 @@ PJ_DECL(pj_status_t) pj_stun_sock_get_info(pj_stun_sock *stun_sock,
  *			this case the \a on_data_sent() callback will be
  *			called when data is actually sent. Any other return
  *			value indicates error condition.
- */ 
+ */
 PJ_DECL(pj_status_t) pj_stun_sock_sendto(pj_stun_sock *stun_sock,
-					 pj_ioqueue_op_key_t *send_key,
-					 const void *pkt,
-					 unsigned pkt_len,
-					 unsigned flag,
-					 const pj_sockaddr_t *dst_addr,
-					 unsigned addr_len);
+                                         pj_ioqueue_op_key_t *send_key,
+                                         const void *pkt,
+                                         unsigned pkt_len,
+                                         unsigned flag,
+                                         const pj_sockaddr_t *dst_addr,
+                                         unsigned addr_len,
+                                         pj_ssize_t* size);
+
+#if PJ_HAS_TCP
+/**
+ * Connect active socket to remote address
+ * @param stun_sock
+ * @param remote_addr the destination
+ * @param af          address family
+ */
+PJ_DECL(pj_status_t) pj_stun_sock_connect_active(pj_stun_sock *stun_sock,
+                                                 const pj_sockaddr_t *remote_addr,
+                                                 int af);
+
+/**
+ * Connect active socket to remote address
+ * @param stun_sock
+ * @param remote_addr the destination
+ * @param af          address family
+ */
+PJ_DECL(pj_status_t) pj_stun_sock_reconnect_active(pj_stun_sock *stun_sock,
+                                                   const pj_sockaddr_t *remote_addr,
+                                                   int af);
+
+/**
+ * Close active socket
+ * @param stun_sock
+ * @param remote_addr    The remote address linked
+ */
+PJ_DECL(pj_status_t) pj_stun_sock_close(pj_stun_sock *stun_sock,
+                                        const pj_sockaddr_t *remote_addr);
+
+#endif
+
+/**
+ * Retrieve the linked session
+ * @param stun_sock
+ */
+PJ_DECL(pj_stun_session *) pj_stun_sock_get_session(pj_stun_sock *stun_sock);
+
+
 
 /**
  * @}
diff --git a/pjnath/include/pjnath/turn_sock.h b/pjnath/include/pjnath/turn_sock.h
index e4d306174..ad40d4df4 100644
--- a/pjnath/include/pjnath/turn_sock.h
+++ b/pjnath/include/pjnath/turn_sock.h
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #ifndef __PJNATH_TURN_SOCK_H__
 #define __PJNATH_TURN_SOCK_H__
@@ -57,7 +57,7 @@ Also see <b>\ref samples_page</b> for other samples.
  */
 
 
-/** 
+/**
  * Opaque declaration for TURN client.
  */
 typedef struct pj_turn_sock pj_turn_sock;
@@ -76,7 +76,7 @@ typedef struct pj_turn_sock_cb
      * function is called).
      *
      * @param turn_sock	    The TURN client transport.
-     * @param data	    The data as received from the peer.    
+     * @param data	    The data as received from the peer.
      * @param data_len	    Length of the data.
      * @param peer_addr	    The peer address.
      * @param addr_len	    The length of the peer address.
@@ -112,7 +112,7 @@ typedef struct pj_turn_sock_cb
      * @param old_state	    Previous state.
      * @param new_state	    Current state.
      */
-    void (*on_state)(pj_turn_sock *turn_sock, 
+    void (*on_state)(pj_turn_sock *turn_sock,
 		     pj_turn_state_t old_state,
 		     pj_turn_state_t new_state);
 
@@ -213,8 +213,8 @@ typedef struct pj_turn_sock_tls_cfg
     pj_ssl_cert_buffer cert_buf;
 
     /**
-     * Optional private key buffer of the endpoint certificate to be used. 
-     * If ca_list_file, ca_list_path, cert_file or privkey_file are set, 
+     * Optional private key buffer of the endpoint certificate to be used.
+     * If ca_list_file, ca_list_path, cert_file or privkey_file are set,
      * this setting will be ignored.
      */
     pj_ssl_cert_buffer privkey_buf;
@@ -463,7 +463,7 @@ PJ_DECL(pj_status_t) pj_turn_sock_get_info(pj_turn_sock *turn_sock,
 
 /**
  * Acquire the internal mutex of the TURN transport. Application may need
- * to call this function to synchronize access to other objects alongside 
+ * to call this function to synchronize access to other objects alongside
  * the TURN transport, to avoid deadlock.
  *
  * @param turn_sock	The TURN transport instance.
@@ -486,7 +486,7 @@ PJ_DECL(pj_status_t) pj_turn_sock_unlock(pj_turn_sock *turn_sock);
 
 
 /**
- * Set STUN message logging for this TURN session. 
+ * Set STUN message logging for this TURN session.
  * See #pj_stun_session_set_log().
  *
  * @param turn_sock	The TURN transport instance.
@@ -543,7 +543,7 @@ PJ_DECL(pj_status_t) pj_turn_sock_set_software_name(pj_turn_sock *turn_sock,
  *			When this function returns PJ_SUCCESS, the final
  *			result of the allocation process will be notified
  *			to application in \a on_state() callback.
- *			
+ *
  */
 PJ_DECL(pj_status_t) pj_turn_sock_alloc(pj_turn_sock *turn_sock,
 				        const pj_str_t *domain,
@@ -576,7 +576,7 @@ PJ_DECL(pj_status_t) pj_turn_sock_set_perm(pj_turn_sock *turn_sock,
 					   unsigned options);
 
 /**
- * Send a data to the specified peer address via the TURN relay. This 
+ * Send a data to the specified peer address via the TURN relay. This
  * function will encapsulate the data as STUN Send Indication or TURN
  * ChannelData packet and send the message to the TURN server. The TURN
  * server then will send the data to the peer.
@@ -596,7 +596,7 @@ PJ_DECL(pj_status_t) pj_turn_sock_set_perm(pj_turn_sock *turn_sock,
  *			this case the \a on_data_sent() callback will be
  *			called when data is actually sent. Any other return
  *			value indicates error condition.
- */ 
+ */
 PJ_DECL(pj_status_t) pj_turn_sock_sendto(pj_turn_sock *turn_sock,
 					const pj_uint8_t *pkt,
 					unsigned pkt_len,
@@ -623,6 +623,16 @@ PJ_DECL(pj_status_t) pj_turn_sock_bind_channel(pj_turn_sock *turn_sock,
 					       const pj_sockaddr_t *peer,
 					       unsigned addr_len);
 
+/**
+ *  Check if peer is a dataconn
+ *
+ * @param turn_sock    The turn sock
+ * @param peer         The peer addr to check
+ *
+ * @return true if dataconn else false
+ */
+PJ_DECL(pj_bool_t) pj_turn_sock_has_dataconn(pj_turn_sock *turn_sock,
+                                             const pj_sockaddr_t *peer);
 
 /**
  * @}
@@ -633,4 +643,3 @@ PJ_END_DECL
 
 
 #endif	/* __PJNATH_TURN_SOCK_H__ */
-
diff --git a/pjnath/src/pjnath-test/concur_test.c b/pjnath/src/pjnath-test/concur_test.c
index c3013d2ab..b80a9306f 100644
--- a/pjnath/src/pjnath-test/concur_test.c
+++ b/pjnath/src/pjnath-test/concur_test.c
@@ -183,9 +183,9 @@ static int stun_destroy_test_session(struct stun_test_session *test_sess)
     for (i=0; i<MAX_SOCK_CLIENTS; ++i) {
 	char name[10];
 	sprintf(name, "stun%02d", i);
-	status = pj_stun_sock_create(&test_sess->stun_cfg, name, pj_AF_INET(),
-	                             &stun_cb, NULL, test_sess,
-	                             &stun_sock[i]);
+        status = pj_stun_sock_create(&test_sess->stun_cfg, name, pj_AF_INET(),
+                                     PJ_STUN_TP_UDP, &stun_cb, NULL, test_sess,
+                                     &stun_sock[i]);
 	if (status != PJ_SUCCESS) {
 	    PJ_PERROR(1,(THIS_FILE, status, "Error creating stun socket"));
 	    return -10;
diff --git a/pjnath/src/pjnath-test/sess_auth.c b/pjnath/src/pjnath-test/sess_auth.c
index 055eaad61..f2fc78e01 100644
--- a/pjnath/src/pjnath-test/sess_auth.c
+++ b/pjnath/src/pjnath-test/sess_auth.c
@@ -248,7 +248,8 @@ static int create_std_server(pj_stun_auth_type auth_type,
     pj_bzero(&sess_cb, sizeof(sess_cb));
     sess_cb.on_rx_request = &server_on_rx_request;
     sess_cb.on_send_msg = &server_send_msg;
-    status = pj_stun_session_create(&stun_cfg, "server", &sess_cb, PJ_FALSE, NULL, &server->sess);
+    status = pj_stun_session_create(&stun_cfg, "server", &sess_cb, PJ_FALSE,
+                                    NULL, &server->sess, PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS) {
 	destroy_server();
 	return -10;
@@ -489,7 +490,8 @@ static int run_client_test(const char *title,
     pj_bzero(&sess_cb, sizeof(sess_cb));
     sess_cb.on_request_complete = &client_on_request_complete;
     sess_cb.on_send_msg = &client_send_msg;
-    status = pj_stun_session_create(&stun_cfg, "client", &sess_cb, PJ_FALSE, NULL, &client->sess);
+    status = pj_stun_session_create(&stun_cfg, "client", &sess_cb, PJ_FALSE,
+                                    NULL, &client->sess, PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS) {
 	destroy_client_server();
 	return -200;
@@ -575,8 +577,11 @@ static int run_client_test(const char *title,
     }
 
     /* Send the request */
-    status = pj_stun_session_send_msg(client->sess, NULL, PJ_FALSE, PJ_TRUE, &server->addr,
-				      pj_sockaddr_get_len(&server->addr), tdata);
+    status = pj_stun_session_send_msg(client->sess, NULL, PJ_FALSE,
+                                      (pj_stun_session_tp_type(client->sess) == PJ_STUN_TP_UDP),
+                                      &server->addr,
+                                      pj_sockaddr_get_len(&server->addr),
+                                      tdata);
     if (status != PJ_SUCCESS) {
 	destroy_client_server();
 	return -270;
diff --git a/pjnath/src/pjnath-test/stun_sock_test.c b/pjnath/src/pjnath-test/stun_sock_test.c
index fff4fad26..d3c17d2c5 100644
--- a/pjnath/src/pjnath-test/stun_sock_test.c
+++ b/pjnath/src/pjnath-test/stun_sock_test.c
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #include "test.h"
 
@@ -67,9 +67,9 @@ static pj_bool_t srv_on_data_recvfrom(pj_activesock_t *asock,
 	pj_stun_msg *req_msg, *res_msg;
 
 	pool = pj_pool_create(mem, "stunsrv", 512, 512, NULL);
-    
+
 	/* Parse request */
-	status = pj_stun_msg_decode(pool, (pj_uint8_t*)data, size, 
+	status = pj_stun_msg_decode(pool, (pj_uint8_t*)data, size,
 				    PJ_STUN_IS_DATAGRAM | PJ_STUN_CHECK_PACKET,
 				    &req_msg, NULL, NULL);
 	if (status != PJ_SUCCESS) {
@@ -91,8 +91,8 @@ static pj_bool_t srv_on_data_recvfrom(pj_activesock_t *asock,
 	if (srv->flag & WITH_MAPPED) {
 	    pj_sockaddr addr;
 	    pj_bool_t use_ipv6 = (srv->addr.addr.sa_family == pj_AF_INET6());
-	    
-	    pj_sockaddr_init(GET_AF(use_ipv6), &addr, &srv->ip_to_send, 
+
+	    pj_sockaddr_init(GET_AF(use_ipv6), &addr, &srv->ip_to_send,
 			     srv->port_to_send);
 
 	    pj_stun_msg_add_sockaddr_attr(pool, res_msg, PJ_STUN_ATTR_MAPPED_ADDR,
@@ -100,17 +100,17 @@ static pj_bool_t srv_on_data_recvfrom(pj_activesock_t *asock,
 	} else if (srv->flag & WITH_XOR_MAPPED) {
 	    pj_sockaddr addr;
 	    pj_bool_t use_ipv6 = (srv->addr.addr.sa_family == pj_AF_INET6());
-	    
-	    pj_sockaddr_init(GET_AF(use_ipv6), &addr, &srv->ip_to_send, 
+
+	    pj_sockaddr_init(GET_AF(use_ipv6), &addr, &srv->ip_to_send,
 			     srv->port_to_send);
 
-	    pj_stun_msg_add_sockaddr_attr(pool, res_msg, 
+	    pj_stun_msg_add_sockaddr_attr(pool, res_msg,
 					  PJ_STUN_ATTR_XOR_MAPPED_ADDR,
 					  PJ_TRUE, &addr, sizeof(addr));
 	}
 
 	/* Encode */
-	status = pj_stun_msg_encode(res_msg, (pj_uint8_t*)data, 100, 0, 
+	status = pj_stun_msg_encode(res_msg, (pj_uint8_t*)data, 100, 0,
 				    NULL, &size);
 	if (status != PJ_SUCCESS) {
 	    app_perror("   pj_stun_msg_encode()", status);
@@ -120,7 +120,7 @@ static pj_bool_t srv_on_data_recvfrom(pj_activesock_t *asock,
 
 	/* Send back */
 	sent = size;
-	pj_activesock_sendto(asock, &srv->send_key, data, &sent, 0, 
+	pj_activesock_sendto(asock, &srv->send_key, data, &sent, 0,
 			     src_addr, addr_len);
 
 	pj_pool_release(pool);
@@ -128,7 +128,7 @@ static pj_bool_t srv_on_data_recvfrom(pj_activesock_t *asock,
     } else if (srv->flag & ECHO) {
 	/* Send back */
 	sent = size;
-	pj_activesock_sendto(asock, &srv->send_key, data, &sent, 0, 
+	pj_activesock_sendto(asock, &srv->send_key, data, &sent, 0,
 			     src_addr, addr_len);
 
     }
@@ -158,7 +158,7 @@ static pj_status_t create_server(pj_pool_t *pool,
     pj_bzero(&activesock_cb, sizeof(activesock_cb));
     activesock_cb.on_data_recvfrom = &srv_on_data_recvfrom;
     status = pj_activesock_create_udp(pool, &srv->addr, NULL, ioqueue,
-				      &activesock_cb, srv, &srv->asock, 
+				      &activesock_cb, srv, &srv->asock,
 				      &srv->addr);
     if (status != PJ_SUCCESS)
 	return status;
@@ -196,7 +196,7 @@ struct stun_client
     unsigned		 on_rx_data_cnt;
 };
 
-static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock, 
+static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock,
 				     pj_stun_sock_op op,
 				     pj_status_t status)
 {
@@ -255,8 +255,8 @@ static pj_status_t create_client(pj_stun_config *cfg,
     pj_bzero(&cb, sizeof(cb));
     cb.on_status = &stun_sock_on_status;
     cb.on_rx_data = &stun_sock_on_rx_data;
-    status = pj_stun_sock_create(cfg, NULL, GET_AF(use_ipv6), &cb, &sock_cfg, 
-				 client, &client->sock);
+    status = pj_stun_sock_create(cfg, NULL, GET_AF(use_ipv6), PJ_STUN_TP_UDP,
+				 &cb, &sock_cfg, client, &client->sock);
     if (status != PJ_SUCCESS) {
 	app_perror("   pj_stun_sock_create()", status);
 	pj_pool_release(pool);
@@ -300,7 +300,7 @@ static void handle_events(pj_stun_config *cfg, unsigned msec_delay)
 /*
  * Timeout test: scenario when no response is received from server
  */
-static int timeout_test(pj_stun_config *cfg, pj_bool_t destroy_on_err, 
+static int timeout_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
 			pj_bool_t use_ipv6)
 {
     struct stun_srv *srv;
@@ -310,7 +310,7 @@ static int timeout_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
     int i, ret = 0;
     pj_status_t status;
 
-    PJ_LOG(3,(THIS_FILE, "  timeout test [%d] - (%s)", destroy_on_err, 
+    PJ_LOG(3,(THIS_FILE, "  timeout test [%d] - (%s)", destroy_on_err,
 	   (use_ipv6)?"IPv6":"IPv4"));
 
     status =  create_client(cfg, &client, destroy_on_err, use_ipv6);
@@ -325,7 +325,7 @@ static int timeout_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
 
     srv_addr = (use_ipv6)?pj_str("::1"):pj_str("127.0.0.1");
 
-    status = pj_stun_sock_start(client->sock, &srv_addr, 
+    status = pj_stun_sock_start(client->sock, &srv_addr,
 				pj_sockaddr_get_port(&srv->addr), NULL);
     if (status != PJ_SUCCESS) {
 	destroy_server(srv);
@@ -384,7 +384,7 @@ on_return:
  * Invalid response scenario: when server returns no MAPPED-ADDRESS or
  * XOR-MAPPED-ADDRESS attribute.
  */
-static int missing_attr_test(pj_stun_config *cfg, pj_bool_t destroy_on_err, 
+static int missing_attr_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
 			     pj_bool_t use_ipv6)
 {
     struct stun_srv *srv;
@@ -394,14 +394,14 @@ static int missing_attr_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
     int i, ret = 0;
     pj_status_t status;
 
-    PJ_LOG(3,(THIS_FILE, "  missing attribute test [%d] - (%s)", 
+    PJ_LOG(3,(THIS_FILE, "  missing attribute test [%d] - (%s)",
 	   destroy_on_err, (use_ipv6)?"IPv6":"IPv4"));
 
     status =  create_client(cfg, &client, destroy_on_err, use_ipv6);
     if (status != PJ_SUCCESS)
 	return -110;
 
-    status = create_server(client->pool, cfg->ioqueue, RESPOND_STUN, use_ipv6, 
+    status = create_server(client->pool, cfg->ioqueue, RESPOND_STUN, use_ipv6,
 			   &srv);
     if (status != PJ_SUCCESS) {
 	destroy_client(client);
@@ -409,8 +409,8 @@ static int missing_attr_test(pj_stun_config *cfg, pj_bool_t destroy_on_err,
     }
     srv_addr = (use_ipv6)?pj_str("::1"):pj_str("127.0.0.1");
 
-    status = pj_stun_sock_start(client->sock, &srv_addr, 
-				pj_sockaddr_get_port(&srv->addr), NULL);				
+    status = pj_stun_sock_start(client->sock, &srv_addr,
+				pj_sockaddr_get_port(&srv->addr), NULL);
     if (status != PJ_SUCCESS) {
 	destroy_server(srv);
 	destroy_client(client);
@@ -469,14 +469,14 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
     int i, ret = 0;
     pj_status_t status;
 
-    PJ_LOG(3,(THIS_FILE, "  normal operation - (%s)", 
+    PJ_LOG(3,(THIS_FILE, "  normal operation - (%s)",
 	   (use_ipv6)?"IPv6":"IPv4"));
 
     status =  create_client(cfg, &client, PJ_TRUE, use_ipv6);
     if (status != PJ_SUCCESS)
 	return -310;
 
-    status = create_server(client->pool, cfg->ioqueue, RESPOND_STUN|WITH_XOR_MAPPED, 
+    status = create_server(client->pool, cfg->ioqueue, RESPOND_STUN|WITH_XOR_MAPPED,
 			   use_ipv6, &srv);
     if (status != PJ_SUCCESS) {
 	destroy_client(client);
@@ -490,7 +490,7 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
 
     srv_addr = (use_ipv6)?pj_str("::1"):pj_str("127.0.0.1");
 
-    status = pj_stun_sock_start(client->sock, &srv_addr, 
+    status = pj_stun_sock_start(client->sock, &srv_addr,
 				pj_sockaddr_get_port(&srv->addr), NULL);
     if (status != PJ_SUCCESS) {
 	destroy_server(srv);
@@ -547,7 +547,7 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
 	goto on_return;
     }
     /* verify the mapped address */
-    pj_sockaddr_init(GET_AF(use_ipv6), &mapped_addr, 
+    pj_sockaddr_init(GET_AF(use_ipv6), &mapped_addr,
 		     &srv->ip_to_send, srv->port_to_send);
     if (pj_sockaddr_cmp(&info.mapped_addr, &mapped_addr) != 0) {
 	PJ_LOG(3,(THIS_FILE, "    error: mapped address mismatched"));
@@ -584,9 +584,10 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
 	char txt[100];
 	PJ_LOG(3,(THIS_FILE, "     sending to %s", pj_sockaddr_print(&info.srv_addr, txt, sizeof(txt), 3)));
     }
+    pj_ssize_t size;
     status = pj_stun_sock_sendto(client->sock, NULL, &ret, sizeof(ret),
-				 0, &info.srv_addr, 
-				 pj_sockaddr_get_len(&info.srv_addr));
+				 0, &info.srv_addr,
+				 pj_sockaddr_get_len(&info.srv_addr), &size);
     if (status != PJ_SUCCESS && status != PJ_EPENDING) {
 	app_perror("    error: server sending data", status);
 	ret = -390;
@@ -685,7 +686,7 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
     srv->flag = RESPOND_STUN | WITH_XOR_MAPPED;
 
     /* Change mapped address in the response */
-    srv->ip_to_send = (use_ipv6)?pj_str("2002:202:202::"):pj_str("2.2.2.2");    
+    srv->ip_to_send = (use_ipv6)?pj_str("2002:202:202::"):pj_str("2.2.2.2");
     srv->port_to_send++;
 
     /* Reset server */
@@ -756,7 +757,7 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
 	goto on_return;
     }
     /* verify the mapped address */
-    pj_sockaddr_init(GET_AF(use_ipv6), &mapped_addr, 
+    pj_sockaddr_init(GET_AF(use_ipv6), &mapped_addr,
 		     &srv->ip_to_send, srv->port_to_send);
     if (pj_sockaddr_cmp(&info.mapped_addr, &mapped_addr) != 0) {
 	PJ_LOG(3,(THIS_FILE, "    error: mapped address mismatched"));
@@ -781,7 +782,7 @@ static int keep_alive_test(pj_stun_config *cfg, pj_bool_t use_ipv6)
      * Part 5: Failed keep-alive
      */
     PJ_LOG(3,(THIS_FILE, "    failed keep-alive scenario"));
-    
+
     /* Change server operation mode to respond without attribute */
     srv->flag = RESPOND_STUN;
 
@@ -866,7 +867,7 @@ int stun_sock_test(void)
 	ret = -8;
 	goto on_return;
     }
-    
+
     pj_stun_config_init(&stun_cfg, mem, 0, ioqueue, timer_heap);
 
     DO_TEST(timeout_test(&stun_cfg, PJ_FALSE, USE_IPV6));
@@ -883,5 +884,3 @@ on_return:
     if (pool) pj_pool_release(pool);
     return ret;
 }
-
-
diff --git a/pjnath/src/pjnath/ice_session.c b/pjnath/src/pjnath/ice_session.c
index 2a4125bc5..248c1217d 100644
--- a/pjnath/src/pjnath/ice_session.c
+++ b/pjnath/src/pjnath/ice_session.c
@@ -44,7 +44,10 @@ static const char *cand_type_names[] =
 static const char *check_state_name[] = 
 {
     "Frozen",
+    "Needs Retry",
+    "Needs First Packet",
     "Waiting",
+    "Pending",
     "In Progress",
     "Succeeded",
     "Failed"
@@ -75,7 +78,8 @@ enum timer_type
 				     valid check for every components.	*/
     TIMER_START_NOMINATED_CHECK,/**< Controlling agent start connectivity
 				     checks with USE-CANDIDATE flag.	*/
-    TIMER_KEEP_ALIVE		/**< ICE keep-alive timer.		*/
+    TIMER_KEEP_ALIVE,		/**< ICE keep-alive timer.		*/
+    TIMER_CONNECTION_TIMEOUT
 
 };
 
@@ -123,6 +127,8 @@ typedef struct timer_data
 {
     pj_ice_sess		    *ice;
     pj_ice_sess_checklist   *clist;
+    /* TODO (remove), for now, needed for the NEEDS_FIRST_PACKET state */
+    unsigned                first_packet_counter;
 } timer_data;
 
 
@@ -133,6 +139,7 @@ typedef struct timer_data
 
 /* Forward declarations */
 static void on_timer(pj_timer_heap_t *th, pj_timer_entry *te);
+static void on_tcp_connect_timeout(pj_ice_sess *ice);
 static void on_ice_complete(pj_ice_sess *ice, pj_status_t status);
 static void ice_keep_alive(pj_ice_sess *ice, pj_bool_t send_now);
 static void ice_on_destroy(void *obj);
@@ -288,10 +295,11 @@ static pj_status_t init_comp(pj_ice_sess *ice,
     sess_cb.on_send_msg = &on_stun_send_msg;
 
     /* Create STUN session for this candidate */
-    status = pj_stun_session_create(&ice->stun_cfg, NULL, 
-			            &sess_cb, PJ_TRUE,
-			            ice->grp_lock,
-				    &comp->stun_sess);
+    status = pj_stun_session_create(&ice->stun_cfg, NULL,
+                                    &sess_cb, PJ_TRUE,
+                                    ice->grp_lock,
+                                    &comp->stun_sess,
+                                    PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS)
 	return status;
 
@@ -715,9 +723,10 @@ PJ_DEF(pj_status_t) pj_ice_sess_add_cand(pj_ice_sess *ice,
 					 const pj_str_t *foundation,
 					 const pj_sockaddr_t *addr,
 					 const pj_sockaddr_t *base_addr,
-					 const pj_sockaddr_t *rel_addr,
-					 int addr_len,
-					 unsigned *p_cand_id)
+                                         const pj_sockaddr_t *rel_addr,
+                                         int addr_len,
+                                         unsigned *p_cand_id,
+                                         pj_ice_cand_transport transport)
 {
     pj_ice_sess_cand *lcand;
     pj_status_t status = PJ_SUCCESS;
@@ -740,6 +749,7 @@ PJ_DEF(pj_status_t) pj_ice_sess_add_cand(pj_ice_sess *ice,
     lcand->comp_id = (pj_uint8_t)comp_id;
     lcand->transport_id = (pj_uint8_t)transport_id;
     lcand->type = type;
+    lcand->transport = transport;
     pj_strdup(ice->pool, &lcand->foundation, foundation);
     lcand->prio = CALC_CAND_PRIO(ice, type, local_pref, lcand->comp_id);
     pj_sockaddr_cp(&lcand->addr, addr);
@@ -961,24 +971,32 @@ static void check_set_state(pj_ice_sess *ice, pj_ice_sess_check *check,
 			    pj_ice_sess_check_state st, 
 			    pj_status_t err_code)
 {
+    /* Nothing to do */
+    if (check->state == st ||
+        (st == PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET &&
+        check->state == PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS))
+    {
+        return;
+    }
+
     pj_assert(check->state < PJ_ICE_SESS_CHECK_STATE_SUCCEEDED);
 
     LOG5((ice->obj_name, "Check %s: state changed from %s to %s",
-	 dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), &ice->clist, check),
-	 check_state_name[check->state],
-	 check_state_name[st]));
+          dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), &ice->clist, check),
+          check_state_name[check->state],
+          check_state_name[st]));
     check->state = st;
     check->err_code = err_code;
 }
 
 static void clist_set_state(pj_ice_sess *ice, pj_ice_sess_checklist *clist,
-			    pj_ice_sess_checklist_state st)
+                            pj_ice_sess_checklist_state st)
 {
     if (clist->state != st) {
-	LOG5((ice->obj_name, "Checklist: state changed from %s to %s",
-	     clist_state_name[clist->state],
-	     clist_state_name[st]));
-	clist->state = st;
+        LOG5((ice->obj_name, "Checklist: state changed from %s to %s",
+              clist_state_name[clist->state],
+              clist_state_name[st]));
+        clist->state = st;
     }
 }
 
@@ -990,44 +1008,44 @@ static void sort_checklist(pj_ice_sess *ice, pj_ice_sess_checklist *clist)
     unsigned check_ptr_cnt = 0;
 
     for (i=0; i<ice->comp_cnt; ++i) {
-	if (ice->comp[i].valid_check) {
-	    check_ptr[check_ptr_cnt++] = &ice->comp[i].valid_check;
-	}
-	if (ice->comp[i].nominated_check) {
-	    check_ptr[check_ptr_cnt++] = &ice->comp[i].nominated_check;
-	}
+        if (ice->comp[i].valid_check) {
+            check_ptr[check_ptr_cnt++] = &ice->comp[i].valid_check;
+        }
+        if (ice->comp[i].nominated_check) {
+            check_ptr[check_ptr_cnt++] = &ice->comp[i].nominated_check;
+        }
     }
 
     pj_assert(clist->count > 0);
     for (i=0; i<clist->count-1; ++i) {
-	unsigned j, highest = i;
+        unsigned j, highest = i;
 
-	for (j=i+1; j<clist->count; ++j) {
-	    if (CMP_CHECK_PRIO(&clist->checks[j], &clist->checks[highest]) > 0) {
-		highest = j;
-	    }
-	}
+        for (j=i+1; j<clist->count; ++j) {
+            if (CMP_CHECK_PRIO(&clist->checks[j], &clist->checks[highest]) > 0) {
+                highest = j;
+            }
+        }
 
-	if (highest != i) {
-	    pj_ice_sess_check tmp;
-	    unsigned k;
+        if (highest != i) {
+            pj_ice_sess_check tmp;
+            unsigned k;
 
-	    pj_memcpy(&tmp, &clist->checks[i], sizeof(pj_ice_sess_check));
-	    pj_memcpy(&clist->checks[i], &clist->checks[highest], 
-		      sizeof(pj_ice_sess_check));
-	    pj_memcpy(&clist->checks[highest], &tmp, 
-		      sizeof(pj_ice_sess_check));
+            pj_memcpy(&tmp, &clist->checks[i], sizeof(pj_ice_sess_check));
+            pj_memcpy(&clist->checks[i], &clist->checks[highest], 
+                      sizeof(pj_ice_sess_check));
+            pj_memcpy(&clist->checks[highest], &tmp, 
+                      sizeof(pj_ice_sess_check));
 
-	    /* Update valid and nominated check pointers, since we're moving
-	     * around checks
-	     */
-	    for (k=0; k<check_ptr_cnt; ++k) {
-		if (*check_ptr[k] == &clist->checks[highest])
-		    *check_ptr[k] = &clist->checks[i];
-		else if (*check_ptr[k] == &clist->checks[i])
-		    *check_ptr[k] = &clist->checks[highest];
-	    }
-	}
+            /* Update valid and nominated check pointers, since we're moving
+             * around checks
+             */
+            for (k=0; k<check_ptr_cnt; ++k) {
+                if (*check_ptr[k] == &clist->checks[highest])
+                    *check_ptr[k] = &clist->checks[i];
+                else if (*check_ptr[k] == &clist->checks[i])
+                    *check_ptr[k] = &clist->checks[highest];
+            }
+        }
     }
 }
 
@@ -1035,7 +1053,7 @@ static void sort_checklist(pj_ice_sess *ice, pj_ice_sess_checklist *clist)
  * is sorted.
  */
 static pj_status_t prune_checklist(pj_ice_sess *ice, 
-				   pj_ice_sess_checklist *clist)
+                                   pj_ice_sess_checklist *clist)
 {
     unsigned i;
 
@@ -1051,36 +1069,47 @@ static pj_status_t prune_checklist(pj_ice_sess *ice,
      */
     /* First replace SRFLX candidates with their base */
     for (i=0; i<clist->count; ++i) {
-	pj_ice_sess_cand *srflx = clist->checks[i].lcand;
+        pj_ice_sess_cand *srflx = clist->checks[i].lcand;
 
-	if (clist->checks[i].lcand->type == PJ_ICE_CAND_TYPE_SRFLX) {
-	    /* Find the base for this candidate */
-	    unsigned j;
-	    for (j=0; j<ice->lcand_cnt; ++j) {
-		pj_ice_sess_cand *host = &ice->lcand[j];
+        if (clist->checks[i].lcand->type == PJ_ICE_CAND_TYPE_SRFLX) {
+            /* Find the base for this candidate */
+            unsigned j;
+            for (j=0; j<ice->lcand_cnt; ++j) {
+                pj_ice_sess_cand *host = &ice->lcand[j];
 
-		if (host->type != PJ_ICE_CAND_TYPE_HOST)
-		    continue;
+                if (host->type != PJ_ICE_CAND_TYPE_HOST)
+                    continue;
 
-		if (pj_sockaddr_cmp(&srflx->base_addr, &host->addr) == 0) {
-		    /* Replace this SRFLX with its BASE */
-		    clist->checks[i].lcand = host;
-		    break;
-		}
-	    }
+                if (pj_sockaddr_cmp(&srflx->base_addr, &host->addr) == 0) {
+                    /* Replace this SRFLX with its BASE */
+                    clist->checks[i].lcand = host;
+                    break;
+                }
+            }
 
-	    if (j==ice->lcand_cnt) {
-		char baddr[PJ_INET6_ADDRSTRLEN];
-		/* Host candidate not found this this srflx! */
-		LOG4((ice->obj_name, 
-		      "Base candidate %s:%d not found for srflx candidate %d",
-		      pj_sockaddr_print(&srflx->base_addr, baddr,
-		                        sizeof(baddr), 2),
-		      pj_sockaddr_get_port(&srflx->base_addr),
-		      GET_LCAND_ID(clist->checks[i].lcand)));
-		return PJNATH_EICENOHOSTCAND;
-	    }
-	}
+            if (j==ice->lcand_cnt) {
+                char baddr[PJ_INET6_ADDRSTRLEN];
+                /* Host candidate not found this this srflx! */
+                LOG4((ice->obj_name, 
+                      "Base candidate %s:%d not found for srflx candidate %d",
+                      pj_sockaddr_print(&srflx->base_addr, baddr,
+                                        sizeof(baddr), 2),
+                      pj_sockaddr_get_port(&srflx->base_addr),
+                      GET_LCAND_ID(clist->checks[i].lcand)));
+                return PJNATH_EICENOHOSTCAND;
+            }
+        }
+
+        /* Section 6.2, RFC 6544 (https://tools.ietf.org/html/rfc6544)
+         * When the agent prunes the check list, it MUST also remove any pair
+         * for which the local candidate is a passive TCP candidate
+         */
+        if (clist->checks[i].lcand->transport == PJ_CAND_TCP_PASSIVE) {
+            pj_array_erase(clist->checks, sizeof(clist->checks[0]),
+                           clist->count, i);
+            --clist->count;
+            --i;
+        }
     }
 
     /* Next remove a pair if its local and remote candidates are identical
@@ -1092,39 +1121,39 @@ static pj_status_t prune_checklist(pj_ice_sess *ice,
      * Remove host candidates if their base are the the same!
      */
     for (i=0; i<clist->count; ++i) {
-	pj_ice_sess_cand *licand = clist->checks[i].lcand;
-	pj_ice_sess_cand *ricand = clist->checks[i].rcand;
-	unsigned j;
+        pj_ice_sess_cand *licand = clist->checks[i].lcand;
+        pj_ice_sess_cand *ricand = clist->checks[i].rcand;
+        unsigned j;
 
-	for (j=i+1; j<clist->count;) {
-	    pj_ice_sess_cand *ljcand = clist->checks[j].lcand;
-	    pj_ice_sess_cand *rjcand = clist->checks[j].rcand;
-	    const char *reason = NULL;
+        for (j=i+1; j<clist->count;) {
+            pj_ice_sess_cand *ljcand = clist->checks[j].lcand;
+            pj_ice_sess_cand *rjcand = clist->checks[j].rcand;
+            const char *reason = NULL;
 
-	    if ((licand == ljcand) && (ricand == rjcand)) {
-		reason = "duplicate found";
-	    } else if ((rjcand == ricand) &&
-		       (pj_sockaddr_cmp(&ljcand->base_addr, 
-				     &licand->base_addr)==0)) 
-	    {
-		reason = "equal base";
-	    }
+            if ((licand == ljcand) && (ricand == rjcand)) {
+                reason = "duplicate found";
+            } else if ((rjcand == ricand) &&
+                       (pj_sockaddr_cmp(&ljcand->base_addr, 
+                                        &licand->base_addr)==0)) 
+            {
+                reason = "equal base";
+            }
 
-	    if (reason != NULL) {
-		/* Found duplicate, remove it */
-		LOG5((ice->obj_name, "Check %s pruned (%s)",
-		      dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-				 &ice->clist, &clist->checks[j]),
-		      reason));
+            if (reason != NULL) {
+                /* Found duplicate, remove it */
+                LOG5((ice->obj_name, "Check %s pruned (%s)",
+                      dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                                 &ice->clist, &clist->checks[j]),
+                      reason));
 
-		pj_array_erase(clist->checks, sizeof(clist->checks[0]),
-			       clist->count, j);
-		--clist->count;
+                pj_array_erase(clist->checks, sizeof(clist->checks[0]),
+                               clist->count, j);
+                --clist->count;
 
-	    } else {
-		++j;
-	    }
-	}
+            } else {
+                ++j;
+            }
+        }
     }
 
     return PJ_SUCCESS;
@@ -1143,49 +1172,52 @@ static void on_timer(pj_timer_heap_t *th, pj_timer_entry *te)
     te->id = TIMER_NONE;
 
     if (ice->is_destroying) {
-	/* Stray timer, could happen when destroy is invoked while callback
-	 * is pending. */
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        /* Stray timer, could happen when destroy is invoked while callback
+         * is pending. */
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
     switch (type) {
     case TIMER_CONTROLLED_WAIT_NOM:
-	LOG4((ice->obj_name, 
-	      "Controlled agent timed-out in waiting for the controlling "
-	      "agent to send nominated check. Setting state to fail now.."));
-	on_ice_complete(ice, PJNATH_EICENOMTIMEOUT);
-	break;
+        LOG4((ice->obj_name, 
+              "Controlled agent timed-out in waiting for the controlling "
+              "agent to send nominated check. Setting state to fail now.."));
+        on_ice_complete(ice, PJNATH_EICENOMTIMEOUT);
+        break;
     case TIMER_COMPLETION_CALLBACK:
-	{
-	    void (*on_ice_complete)(pj_ice_sess *ice, pj_status_t status);
-	    pj_status_t ice_status;
+        {
+            void (*on_ice_complete)(pj_ice_sess *ice, pj_status_t status);
+            pj_status_t ice_status;
 
-	    /* Start keep-alive timer but don't send any packets yet.
-	     * Need to do it here just in case app destroy the session
-	     * in the callback.
-	     */
-	    if (ice->ice_status == PJ_SUCCESS)
-		ice_keep_alive(ice, PJ_FALSE);
+            /* Start keep-alive timer but don't send any packets yet.
+             * Need to do it here just in case app destroy the session
+             * in the callback.
+             */
+            if (ice->ice_status == PJ_SUCCESS)
+                ice_keep_alive(ice, PJ_FALSE);
 
-	    /* Release mutex in case app destroy us in the callback */
-	    ice_status = ice->ice_status;
-	    on_ice_complete = ice->cb.on_ice_complete;
+            /* Release mutex in case app destroy us in the callback */
+            ice_status = ice->ice_status;
+            on_ice_complete = ice->cb.on_ice_complete;
 
-	    /* Notify app about ICE completion*/
-	    if (on_ice_complete)
-		(*on_ice_complete)(ice, ice_status);
-	}
-	break;
+            /* Notify app about ICE completion*/
+            if (on_ice_complete)
+                (*on_ice_complete)(ice, ice_status);
+        }
+        break;
     case TIMER_START_NOMINATED_CHECK:
-	start_nominated_check(ice);
-	break;
+        start_nominated_check(ice);
+        break;
     case TIMER_KEEP_ALIVE:
-	ice_keep_alive(ice, PJ_TRUE);
-	break;
+        ice_keep_alive(ice, PJ_TRUE);
+        break;
+    case TIMER_CONNECTION_TIMEOUT:
+        on_tcp_connect_timeout(ice);
+        break;
     case TIMER_NONE:
-	/* Nothing to do, just to get rid of gcc warning */
-	break;
+        /* Nothing to do, just to get rid of gcc warning */
+        break;
     }
 
     pj_grp_lock_release(ice->grp_lock);
@@ -1195,66 +1227,66 @@ static void on_timer(pj_timer_heap_t *th, pj_timer_entry *te)
 static void ice_keep_alive(pj_ice_sess *ice, pj_bool_t send_now)
 {
     if (send_now) {
-	/* Send Binding Indication for the component */
-	pj_ice_sess_comp *comp = &ice->comp[ice->comp_ka];
-	pj_stun_tx_data *tdata;
-	pj_ice_sess_check *the_check;
-	pj_ice_msg_data *msg_data;
-	int addr_len;
-	pj_bool_t saved;
-	pj_status_t status;
+        /* Send Binding Indication for the component */
+        pj_ice_sess_comp *comp = &ice->comp[ice->comp_ka];
+        pj_stun_tx_data *tdata;
+        pj_ice_sess_check *the_check;
+        pj_ice_msg_data *msg_data;
+        int addr_len;
+        pj_bool_t saved;
+        pj_status_t status;
 
-	/* Must have nominated check by now */
-	pj_assert(comp->nominated_check != NULL);
-	the_check = comp->nominated_check;
+        /* Must have nominated check by now */
+        pj_assert(comp->nominated_check != NULL);
+        the_check = comp->nominated_check;
 
-	/* Create the Binding Indication */
-	status = pj_stun_session_create_ind(comp->stun_sess, 
-					    PJ_STUN_BINDING_INDICATION,
-					    &tdata);
-	if (status != PJ_SUCCESS)
-	    goto done;
+        /* Create the Binding Indication */
+        status = pj_stun_session_create_ind(comp->stun_sess, 
+                                            PJ_STUN_BINDING_INDICATION,
+                                            &tdata);
+        if (status != PJ_SUCCESS)
+            goto done;
 
-	/* Need the transport_id */
-	msg_data = PJ_POOL_ZALLOC_T(tdata->pool, pj_ice_msg_data);
-	msg_data->transport_id = the_check->lcand->transport_id;
+        /* Need the transport_id */
+        msg_data = PJ_POOL_ZALLOC_T(tdata->pool, pj_ice_msg_data);
+        msg_data->transport_id = the_check->lcand->transport_id;
 
-	/* RFC 5245 Section 10:
-	 * The Binding Indication SHOULD contain the FINGERPRINT attribute
-	 * to aid in demultiplexing, but SHOULD NOT contain any other
-	 * attributes.
-	 */
-	saved = pj_stun_session_use_fingerprint(comp->stun_sess, PJ_TRUE);
+        /* RFC 5245 Section 10:
+         * The Binding Indication SHOULD contain the FINGERPRINT attribute
+         * to aid in demultiplexing, but SHOULD NOT contain any other
+         * attributes.
+         */
+        saved = pj_stun_session_use_fingerprint(comp->stun_sess, PJ_TRUE);
 
-	/* Send to session */
-	addr_len = pj_sockaddr_get_len(&the_check->rcand->addr);
-	status = pj_stun_session_send_msg(comp->stun_sess, msg_data,
-					  PJ_FALSE, PJ_FALSE, 
-					  &the_check->rcand->addr, 
-					  addr_len, tdata);
+        /* Send to session */
+        addr_len = pj_sockaddr_get_len(&the_check->rcand->addr);
+        status = pj_stun_session_send_msg(comp->stun_sess, msg_data,
+                                          PJ_FALSE, PJ_FALSE, 
+                                          &the_check->rcand->addr, 
+                                          addr_len, tdata);
 
-	/* Restore FINGERPRINT usage */
-	pj_stun_session_use_fingerprint(comp->stun_sess, saved);
+        /* Restore FINGERPRINT usage */
+        pj_stun_session_use_fingerprint(comp->stun_sess, saved);
 
 done:
-	ice->comp_ka = (ice->comp_ka + 1) % ice->comp_cnt;
+        ice->comp_ka = (ice->comp_ka + 1) % ice->comp_cnt;
     }
 
     if (ice->timer.id == TIMER_NONE) {
-	pj_time_val delay = { 0, 0 };
+        pj_time_val delay = { 0, 0 };
 
-	delay.msec = (PJ_ICE_SESS_KEEP_ALIVE_MIN + 
-		      (pj_rand() % PJ_ICE_SESS_KEEP_ALIVE_MAX_RAND)) * 1000 / 
-		     ice->comp_cnt;
-	pj_time_val_normalize(&delay);
+        delay.msec = (PJ_ICE_SESS_KEEP_ALIVE_MIN + 
+                      (pj_rand() % PJ_ICE_SESS_KEEP_ALIVE_MAX_RAND)) * 1000 / 
+            ice->comp_cnt;
+        pj_time_val_normalize(&delay);
 
-	pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
-	                                  &ice->timer, &delay,
-	                                  TIMER_KEEP_ALIVE,
-	                                  ice->grp_lock);
+        pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                          &ice->timer, &delay,
+                                          TIMER_KEEP_ALIVE,
+                                          ice->grp_lock);
 
     } else {
-	pj_assert(!"Not expected any timer active");
+        pj_assert(!"Not expected any timer active");
     }
 }
 
@@ -1262,59 +1294,59 @@ done:
 static void on_ice_complete(pj_ice_sess *ice, pj_status_t status)
 {
     if (!ice->is_complete) {
-	ice->is_complete = PJ_TRUE;
-	ice->ice_status = status;
-    
-	pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
-	                               TIMER_NONE);
+        ice->is_complete = PJ_TRUE;
+        ice->ice_status = status;
 
-	/* Log message */
-	LOG4((ice->obj_name, "ICE process complete, status=%s", 
-	     pj_strerror(status, ice->tmp.errmsg, 
-			 sizeof(ice->tmp.errmsg)).ptr));
+        pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
+                                       TIMER_NONE);
 
-	dump_checklist("Valid list", ice, &ice->valid_list);
+        /* Log message */
+        LOG4((ice->obj_name, "ICE process complete, status=%s", 
+              pj_strerror(status, ice->tmp.errmsg, 
+                          sizeof(ice->tmp.errmsg)).ptr));
 
-	/* Call callback */
-	if (ice->cb.on_ice_complete) {
-	    pj_time_val delay = {0, 0};
+        dump_checklist("Valid list", ice, &ice->valid_list);
 
-	    pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
-	                                      &ice->timer, &delay,
-	                                      TIMER_COMPLETION_CALLBACK,
-	                                      ice->grp_lock);
-	}
+        /* Call callback */
+        if (ice->cb.on_ice_complete) {
+            pj_time_val delay = {0, 0};
+
+            pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                              &ice->timer, &delay,
+                                              TIMER_COMPLETION_CALLBACK,
+                                              ice->grp_lock);
+        }
     }
 }
 
 /* Update valid check and nominated check for the candidate */
 static void update_comp_check(pj_ice_sess *ice, unsigned comp_id, 
-			      pj_ice_sess_check *check)
+                              pj_ice_sess_check *check)
 {
     pj_ice_sess_comp *comp;
 
     comp = find_comp(ice, comp_id);
     if (comp->valid_check == NULL) {
-	comp->valid_check = check;
+        comp->valid_check = check;
     } else {
-	if (CMP_CHECK_PRIO(comp->valid_check, check) < 0)
-	    comp->valid_check = check;
+        if (CMP_CHECK_PRIO(comp->valid_check, check) < 0)
+            comp->valid_check = check;
     }
 
     if (check->nominated) {
-	/* Update the nominated check for the component */
-	if (comp->nominated_check == NULL) {
-	    comp->nominated_check = check;
-	} else {
-	    if (CMP_CHECK_PRIO(comp->nominated_check, check) < 0)
-		comp->nominated_check = check;
-	}
+        /* Update the nominated check for the component */
+        if (comp->nominated_check == NULL) {
+            comp->nominated_check = check;
+        } else {
+            if (CMP_CHECK_PRIO(comp->nominated_check, check) < 0)
+                comp->nominated_check = check;
+        }
     }
 }
 
 /* This function is called when one check completes */
 static pj_bool_t on_check_complete(pj_ice_sess *ice,
-				   pj_ice_sess_check *check)
+                                   pj_ice_sess_check *check)
 {
     pj_ice_sess_comp *comp;
     unsigned i;
@@ -1337,27 +1369,27 @@ static pj_bool_t on_check_complete(pj_ice_sess *ice,
      */
     if (check->err_code==PJ_SUCCESS) {
 
-	for (i=0; i<ice->clist.count; ++i) {
-	    pj_ice_sess_check *c = &ice->clist.checks[i];
-	    if (pj_strcmp(&c->lcand->foundation, &check->lcand->foundation)==0
-		 && c->state == PJ_ICE_SESS_CHECK_STATE_FROZEN)
-	    {
-		check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_WAITING, 0);
-	    }
-	}
+        for (i=0; i<ice->clist.count; ++i) {
+            pj_ice_sess_check *c = &ice->clist.checks[i];
+            if (pj_strcmp(&c->lcand->foundation, &check->lcand->foundation)==0
+                && c->state == PJ_ICE_SESS_CHECK_STATE_FROZEN)
+            {
+                check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_WAITING, 0);
+            }
+        }
 
-	LOG5((ice->obj_name, "Check %d is successful%s",
-	     GET_CHECK_ID(&ice->clist, check),
-	     (check->nominated ? "  and nominated" : "")));
+        LOG5((ice->obj_name, "Check %d is successful%s",
+              GET_CHECK_ID(&ice->clist, check),
+              (check->nominated ? "  and nominated" : "")));
 
-	/* On the first valid pair, we call the callback, if present */
-	if (ice->valid_pair_found == PJ_FALSE) {
-	    ice->valid_pair_found = PJ_TRUE;
+        /* On the first valid pair, we call the callback, if present */
+        if (ice->valid_pair_found == PJ_FALSE) {
+            ice->valid_pair_found = PJ_TRUE;
 
-	    if (ice->cb.on_valid_pair) {
-		(*ice->cb.on_valid_pair)(ice);
-	    }
-	}
+            if (ice->cb.on_valid_pair) {
+                (*ice->cb.on_valid_pair)(ice);
+            }
+        }
     }
 
     /* 8.2.  Updating States
@@ -1383,42 +1415,42 @@ static pj_bool_t on_check_complete(pj_ice_sess *ice,
      */
     if (check->err_code==PJ_SUCCESS && check->nominated) {
 
-	for (i=0; i<ice->clist.count; ++i) {
+        for (i=0; i<ice->clist.count; ++i) {
 
-	    pj_ice_sess_check *c = &ice->clist.checks[i];
+            pj_ice_sess_check *c = &ice->clist.checks[i];
 
-	    if (c->lcand->comp_id == check->lcand->comp_id) {
+            if (c->lcand->comp_id == check->lcand->comp_id) {
 
-		if (c->state < PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS) {
+                if (c->state < PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS) {
 
-		    /* Just fail Frozen/Waiting check */
-		    LOG5((ice->obj_name, 
-			 "Check %s to be failed because state is %s",
-			 dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-				    &ice->clist, c), 
-			 check_state_name[c->state]));
-		    check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_FAILED,
-				    PJ_ECANCELLED);
+                    /* Just fail Frozen/Waiting check */
+                    LOG5((ice->obj_name, 
+                          "Check %s to be failed because state is %s",
+                          dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                                     &ice->clist, c), 
+                          check_state_name[c->state]));
+                    check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_FAILED,
+                                    PJ_ECANCELLED);
 
-		} else if (c->state == PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS
-			   && (PJ_ICE_CANCEL_ALL ||
-			        CMP_CHECK_PRIO(c, check) < 0)) {
+                } else if (c->state == PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS
+                           && (PJ_ICE_CANCEL_ALL ||
+                               CMP_CHECK_PRIO(c, check) < 0)) {
 
-		    /* State is IN_PROGRESS, cancel transaction */
-		    if (c->tdata) {
-			LOG5((ice->obj_name, 
-			     "Cancelling check %s (In Progress)",
-			     dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-					&ice->clist, c)));
-			pj_stun_session_cancel_req(comp->stun_sess, 
-						   c->tdata, PJ_FALSE, 0);
-			c->tdata = NULL;
-			check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_FAILED,
-					PJ_ECANCELLED);
-		    }
-		}
-	    }
-	}
+                    /* State is IN_PROGRESS, cancel transaction */
+                    if (c->tdata) {
+                        LOG5((ice->obj_name, 
+                              "Cancelling check %s (In Progress)",
+                              dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                                         &ice->clist, c)));
+                        pj_stun_session_cancel_req(comp->stun_sess, 
+                                                   c->tdata, PJ_FALSE, 0);
+                        c->tdata = NULL;
+                        check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_FAILED,
+                                        PJ_ECANCELLED);
+                    }
+                }
+            }
+        }
     }
 
 
@@ -1443,13 +1475,13 @@ static pj_bool_t on_check_complete(pj_ice_sess *ice,
      * ICE processing as success, otherwise wait.
      */
     for (i=0; i<ice->comp_cnt; ++i) {
-	if (ice->comp[i].nominated_check == NULL)
-	    break;
+        if (ice->comp[i].nominated_check == NULL)
+            break;
     }
     if (i == ice->comp_cnt) {
-	/* All components have nominated pair */
-	on_ice_complete(ice, PJ_SUCCESS);
-	return PJ_TRUE;
+        /* All components have nominated pair */
+        on_ice_complete(ice, PJ_SUCCESS);
+        return PJ_TRUE;
     }
 
     /* Note: this is the stuffs that we don't do in 7.1.2.2.2, since our
@@ -1480,95 +1512,94 @@ static pj_bool_t on_check_complete(pj_ice_sess *ice,
      * then mark ICE processing as failed.
      */
     for (i=0; i<ice->clist.count; ++i) {
-	pj_ice_sess_check *c = &ice->clist.checks[i];
-	if (c->state < PJ_ICE_SESS_CHECK_STATE_SUCCEEDED) {
-	    break;
-	}
+        pj_ice_sess_check *c = &ice->clist.checks[i];
+        if (c->state < PJ_ICE_SESS_CHECK_STATE_SUCCEEDED) {
+            break;
+        }
     }
 
     if (i == ice->clist.count) {
-	/* All checks have completed, but we don't have nominated pair.
-	 * If agent's role is controlled, check if all components have
-	 * valid pair. If it does, this means the controlled agent has
-	 * finished the check list and it's waiting for controlling
-	 * agent to send checks with USE-CANDIDATE flag set.
-	 */
-	if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLED) {
-	    for (i=0; i < ice->comp_cnt; ++i) {
-		if (ice->comp[i].valid_check == NULL)
-		    break;
-	    }
+        /* All checks have completed, but we don't have nominated pair.
+         * If agent's role is controlled, check if all components have
+         * valid pair. If it does, this means the controlled agent has
+         * finished the check list and it's waiting for controlling
+         * agent to send checks with USE-CANDIDATE flag set.
+         */
+        if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLED) {
+            for (i=0; i < ice->comp_cnt; ++i) {
+                if (ice->comp[i].valid_check == NULL)
+                    break;
+            }
 
-	    if (i < ice->comp_cnt) {
-		/* This component ID doesn't have valid pair.
-		 * Mark ICE as failed. 
-		 */
-		on_ice_complete(ice, PJNATH_EICEFAILED);
-		return PJ_TRUE;
-	    } else {
-		/* All components have a valid pair.
-		 * We should wait until we receive nominated checks.
-		 */
-		if (ice->timer.id == TIMER_NONE &&
-		    ice->opt.controlled_agent_want_nom_timeout >= 0) 
-		{
-		    pj_time_val delay;
+            if (i < ice->comp_cnt) {
+                /* This component ID doesn't have valid pair.
+                 * Mark ICE as failed. 
+                 */
+                on_ice_complete(ice, PJNATH_EICEFAILED);
+                return PJ_TRUE;
+            } else {
+                /* All components have a valid pair.
+                 * We should wait until we receive nominated checks.
+                 */
+                if (ice->timer.id == TIMER_NONE &&
+                    ice->opt.controlled_agent_want_nom_timeout >= 0) 
+                {
+                    pj_time_val delay;
 
-		    delay.sec = 0;
-		    delay.msec = ice->opt.controlled_agent_want_nom_timeout;
-		    pj_time_val_normalize(&delay);
+                    delay.sec = 0;
+                    delay.msec = ice->opt.controlled_agent_want_nom_timeout;
+                    pj_time_val_normalize(&delay);
 
-		    pj_timer_heap_schedule_w_grp_lock(
-					ice->stun_cfg.timer_heap,
-		                        &ice->timer, &delay,
-		                        TIMER_CONTROLLED_WAIT_NOM,
-		                        ice->grp_lock);
+                    pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                                      &ice->timer, &delay,
+                                                      TIMER_CONTROLLED_WAIT_NOM,
+                                                      ice->grp_lock);
 
-		    LOG5((ice->obj_name, 
-			  "All checks have completed. Controlled agent now "
-			  "waits for nomination from controlling agent "
-			  "(timeout=%d msec)",
-			  ice->opt.controlled_agent_want_nom_timeout));
-		}
-		return PJ_FALSE;
-	    }
+                    LOG5((ice->obj_name, 
+                          "All checks have completed. Controlled agent now "
+                          "waits for nomination from controlling agent "
+                          "(timeout=%d msec)",
+                          ice->opt.controlled_agent_want_nom_timeout));
+                }
+                return PJ_FALSE;
+            }
 
-	    /* Unreached */
+            /* Unreached */
 
-	} else if (ice->is_nominating) {
-	    /* We are controlling agent and all checks have completed but
-	     * there's at least one component without nominated pair (or
-	     * more likely we don't have any nominated pairs at all).
-	     */
-	    on_ice_complete(ice, PJNATH_EICEFAILED);
-	    return PJ_TRUE;
+        } else if (ice->is_nominating) {
+            /* We are controlling agent and all checks have completed but
+             * there's at least one component without nominated pair (or
+             * more likely we don't have any nominated pairs at all).
+             */
+            on_ice_complete(ice, PJNATH_EICEFAILED);
+            return PJ_TRUE;
 
-	} else {
-	    /* We are controlling agent and all checks have completed. If
-	     * we have valid list for every component, then move on to
-	     * sending nominated check, otherwise we have failed.
-	     */
-	    for (i=0; i<ice->comp_cnt; ++i) {
-		if (ice->comp[i].valid_check == NULL)
-		    break;
-	    }
+        } else {
+            /* We are controlling agent and all checks have completed. If
+             * we have valid list for every component, then move on to
+             * sending nominated check, otherwise we have failed.
+             */
+            for (i=0; i<ice->comp_cnt; ++i) {
+                if (ice->comp[i].valid_check == NULL)
+                    break;
+            }
 
-	    if (i < ice->comp_cnt) {
-		/* At least one component doesn't have a valid check. Mark
-		 * ICE as failed.
-		 */
-		on_ice_complete(ice, PJNATH_EICEFAILED);
-		return PJ_TRUE;
-	    }
+            if (i < ice->comp_cnt) {
+                /* At least one component doesn't have a valid check. Mark
+                 * ICE as failed.
+                 */
+                on_ice_complete(ice, PJNATH_EICEFAILED);
+                return PJ_TRUE;
+            }
 
-	    /* Now it's time to send connectivity check with nomination 
-	     * flag set.
-	     */
-	    LOG4((ice->obj_name, 
-		  "All checks have completed, starting nominated checks now"));
-	    start_nominated_check(ice);
-	    return PJ_FALSE;
-	}
+            /* Now it's time to send connectivity check with nomination 
+             * flag set.
+             */
+            LOG4((ice->obj_name, 
+                  "All checks have completed, starting nominated checks now"));
+            start_nominated_check(ice);
+            return PJ_FALSE;
+        }
     }
 
     /* If this connectivity check has been successful, scan all components
@@ -1576,57 +1607,90 @@ static pj_bool_t on_check_complete(pj_ice_sess *ice,
      * started our nominated check yet.
      */
     if (check->err_code == PJ_SUCCESS && 
-	ice->role==PJ_ICE_SESS_ROLE_CONTROLLING &&
-	!ice->is_nominating &&
-	ice->timer.id == TIMER_NONE) 
+        ice->role==PJ_ICE_SESS_ROLE_CONTROLLING &&
+        !ice->is_nominating &&
+        ice->timer.id == TIMER_NONE) 
     {
-	pj_time_val delay;
+        pj_time_val delay;
 
-	for (i=0; i<ice->comp_cnt; ++i) {
-	    if (ice->comp[i].valid_check == NULL)
-		break;
-	}
+        for (i=0; i<ice->comp_cnt; ++i) {
+            if (ice->comp[i].valid_check == NULL)
+                break;
+        }
 
-	if (i < ice->comp_cnt) {
-	    /* Some components still don't have valid pair, continue
-	     * processing.
-	     */
-	    return PJ_FALSE;
-	}
+        if (i < ice->comp_cnt) {
+            /* Some components still don't have valid pair, continue
+             * processing.
+             */
+            return PJ_FALSE;
+        }
 
-	LOG4((ice->obj_name, 
-	      "Scheduling nominated check in %d ms",
-	      ice->opt.nominated_check_delay));
+        LOG4((ice->obj_name, 
+              "Scheduling nominated check in %d ms",
+              ice->opt.nominated_check_delay));
 
-	pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
-	                               TIMER_NONE);
+        pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
+                                       TIMER_NONE);
 
-	/* All components have valid pair. Let connectivity checks run for
-	 * a little bit more time, then start our nominated check.
-	 */
-	delay.sec = 0;
-	delay.msec = ice->opt.nominated_check_delay;
-	pj_time_val_normalize(&delay);
+        /* All components have valid pair. Let connectivity checks run for
+         * a little bit more time, then start our nominated check.
+         */
+        delay.sec = 0;
+        delay.msec = ice->opt.nominated_check_delay;
+        pj_time_val_normalize(&delay);
 
-	pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
-	                                  &ice->timer, &delay,
-	                                  TIMER_START_NOMINATED_CHECK,
-	                                  ice->grp_lock);
-	return PJ_FALSE;
+        pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                          &ice->timer, &delay,
+                                          TIMER_START_NOMINATED_CHECK,
+                                          ice->grp_lock);
+        return PJ_FALSE;
     }
 
     /* We still have checks to perform */
     return PJ_FALSE;
 }
 
+static void on_tcp_connect_timeout(pj_ice_sess* ice)
+{
+    pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap,&ice->timer,
+                                   TIMER_NONE);
+
+    pj_bool_t first_found = PJ_FALSE, set_timer = PJ_FALSE;
+
+    for (int i = 0; i < ice->clist.count; ++i) {
+        pj_ice_sess_check *check = &ice->clist.checks[i];
+        if (check->state == PJ_ICE_SESS_CHECK_STATE_PENDING && !first_found) {
+            if (*ice->cb.close_tcp_connection)
+                (*ice->cb.close_tcp_connection)(ice, &ice->clist, i);
+
+            check_set_state(ice, check,
+                            PJ_ICE_SESS_CHECK_STATE_FAILED, PJ_ECANCELLED);
+            on_check_complete(ice, check);
+            first_found = PJ_TRUE;
+        } else if(check->state == PJ_ICE_SESS_CHECK_STATE_PENDING) {
+            set_timer = PJ_TRUE;
+            break;
+        }
+    }
+
+    if (set_timer && ice->timer.id == TIMER_NONE) {
+        // Reschedule
+        pj_time_val delay = {0, 0};
+        delay.msec = 1500;
+        pj_time_val_normalize(&delay);
+        pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                          &ice->timer, &delay,
+                                          TIMER_CONNECTION_TIMEOUT,
+                                          ice->grp_lock);
+    }
+}
 
 /* Create checklist by pairing local candidates with remote candidates */
-PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
-			      pj_ice_sess *ice,
-			      const pj_str_t *rem_ufrag,
-			      const pj_str_t *rem_passwd,
-			      unsigned rem_cand_cnt,
-			      const pj_ice_sess_cand rem_cand[])
+PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(pj_ice_sess *ice,
+                                                  const pj_str_t *rem_ufrag,
+                                                  const pj_str_t *rem_passwd,
+                                                  unsigned rem_cand_cnt,
+                                                  const pj_ice_sess_cand rem_cand[])
 {
     pj_ice_sess_checklist *clist;
     char buf[128];
@@ -1637,9 +1701,9 @@ PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
     pj_status_t status;
 
     PJ_ASSERT_RETURN(ice && rem_ufrag && rem_passwd && rem_cand_cnt &&
-		     rem_cand, PJ_EINVAL);
+                     rem_cand, PJ_EINVAL);
     PJ_ASSERT_RETURN(rem_cand_cnt + ice->rcand_cnt <= PJ_ICE_MAX_CAND,
-		     PJ_ETOOMANY);
+                     PJ_ETOOMANY);
 
     pj_grp_lock_acquire(ice->grp_lock);
 
@@ -1664,63 +1728,83 @@ PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
     /* Save remote candidates */
     ice->rcand_cnt = 0;
     for (i=0; i<rem_cand_cnt; ++i) {
-	pj_ice_sess_cand *cn = &ice->rcand[ice->rcand_cnt];
+        pj_ice_sess_cand *cn = &ice->rcand[ice->rcand_cnt];
 
-	/* Ignore candidate which has no matching component ID */
-	if (rem_cand[i].comp_id==0 || rem_cand[i].comp_id > ice->comp_cnt) {
-	    continue;
-	}
+        /* Ignore candidate which has no matching component ID */
+        if (rem_cand[i].comp_id==0 || rem_cand[i].comp_id > ice->comp_cnt) {
+            continue;
+        }
 
-	if (rem_cand[i].comp_id > highest_comp)
-	    highest_comp = rem_cand[i].comp_id;
+        if (rem_cand[i].comp_id > highest_comp)
+            highest_comp = rem_cand[i].comp_id;
 
-	pj_memcpy(cn, &rem_cand[i], sizeof(pj_ice_sess_cand));
-	pj_strdup(ice->pool, &cn->foundation, &rem_cand[i].foundation);
-	ice->rcand_cnt++;
+        pj_memcpy(cn, &rem_cand[i], sizeof(pj_ice_sess_cand));
+        pj_strdup(ice->pool, &cn->foundation, &rem_cand[i].foundation);
+        ice->rcand_cnt++;
     }
 
     /* Generate checklist */
     clist = &ice->clist;
     for (i=0; i<ice->lcand_cnt; ++i) {
-	for (j=0; j<ice->rcand_cnt; ++j) {
-
-	    pj_ice_sess_cand *lcand = &ice->lcand[i];
-	    pj_ice_sess_cand *rcand = &ice->rcand[j];
-	    pj_ice_sess_check *chk = NULL;
-
-	    if (clist->count >= PJ_ICE_MAX_CHECKS) {
-		pj_grp_lock_release(ice->grp_lock);
-		return PJ_ETOOMANY;
-	    } 
-
-           chk = &clist->checks[clist->count];
-
-	    /* A local candidate is paired with a remote candidate if
-	     * and only if the two candidates have the same component ID 
-	     * and have the same IP address version. 
-	     */
-	    if ((lcand->comp_id != rcand->comp_id) ||
-		(lcand->addr.addr.sa_family != rcand->addr.addr.sa_family))
-	    {
-		continue;
-	    }
-
-
-	    chk->lcand = lcand;
-	    chk->rcand = rcand;
-	    chk->state = PJ_ICE_SESS_CHECK_STATE_FROZEN;
-
-	    chk->prio = CALC_CHECK_PRIO(ice, lcand, rcand);
-
-	    clist->count++;
-	}
+        for (j=0; j<ice->rcand_cnt; ++j) {
+
+            pj_ice_sess_cand *lcand = &ice->lcand[i];
+            pj_ice_sess_cand *rcand = &ice->rcand[j];
+            pj_ice_sess_check *chk = NULL;
+
+            if (clist->count >= PJ_ICE_MAX_CHECKS) {
+                pj_grp_lock_release(ice->grp_lock);
+                return PJ_ETOOMANY;
+            } 
+
+            chk = &clist->checks[clist->count];
+
+            /* A local candidate is paired with a remote candidate if
+             * and only if the two candidates have the same component ID 
+             * and have the same IP address version. 
+             */
+            if ((lcand->comp_id != rcand->comp_id) ||
+                (lcand->addr.addr.sa_family != rcand->addr.addr.sa_family))
+            {
+                continue;
+            }
+
+            /* Section 6.2, RFC 6544 (https://tools.ietf.org/html/rfc6544)
+             * As with UDP, check lists are formed only by full ICE implementations.
+             * When forming candidate pairs, the following types of TCP candidates
+             * can be paired with each other:
+             *
+             * Local           Remote
+             * Candidate       Candidate
+             * ---------------------------
+             * tcp-so          tcp-so
+             * tcp-active      tcp-passive
+             * tcp-passive     tcp-active
+             */
+            if ((lcand->transport == PJ_CAND_UDP && rcand->transport != PJ_CAND_UDP) ||
+                (lcand->transport == PJ_CAND_TCP_PASSIVE && rcand->transport != PJ_CAND_TCP_ACTIVE) ||
+                (lcand->transport == PJ_CAND_TCP_ACTIVE && rcand->transport != PJ_CAND_TCP_PASSIVE) ||
+                (lcand->transport == PJ_CAND_TCP_SO && rcand->transport != PJ_CAND_TCP_SO))
+            {
+                continue;
+            }
+
+
+            chk->lcand = lcand;
+            chk->rcand = rcand;
+            chk->state = PJ_ICE_SESS_CHECK_STATE_FROZEN;
+
+            chk->prio = CALC_CHECK_PRIO(ice, lcand, rcand);
+
+            clist->count++;
+        }
     }
 
     /* This could happen if candidates have no matching address families */
     if (clist->count == 0) {
-	LOG4((ice->obj_name,  "Error: no checklist can be created"));
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_ENOTFOUND;
+        LOG4((ice->obj_name,  "Error: no checklist can be created"));
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_ENOTFOUND;
     }
 
     /* Sort checklist based on priority */
@@ -1729,16 +1813,16 @@ PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
     /* Prune the checklist */
     status = prune_checklist(ice, clist);
     if (status != PJ_SUCCESS) {
-	pj_grp_lock_release(ice->grp_lock);
-	return status;
+        pj_grp_lock_release(ice->grp_lock);
+        return status;
     }
 
     /* Disable our components which don't have matching component */
     for (i=highest_comp; i<ice->comp_cnt; ++i) {
-	if (ice->comp[i].stun_sess) {
-	    pj_stun_session_destroy(ice->comp[i].stun_sess);
-	    pj_bzero(&ice->comp[i], sizeof(ice->comp[i]));
-	}
+        if (ice->comp[i].stun_sess) {
+            pj_stun_session_destroy(ice->comp[i].stun_sess);
+            pj_bzero(&ice->comp[i], sizeof(ice->comp[i]));
+        }
     }
     ice->comp_cnt = highest_comp;
 
@@ -1749,6 +1833,7 @@ PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
     td = PJ_POOL_ZALLOC_T(ice->pool, timer_data);
     td->ice = ice;
     td->clist = clist;
+    td->first_packet_counter = 1;
     clist->timer.user_data = (void*)td;
     clist->timer.cb = &periodic_timer;
 
@@ -1761,11 +1846,48 @@ PJ_DEF(pj_status_t) pj_ice_sess_create_check_list(
     return PJ_SUCCESS;
 }
 
+static pj_status_t send_connectivity_check(pj_ice_sess *ice,
+                                           pj_ice_sess_checklist *clist,
+                                           unsigned check_id,
+                                           pj_bool_t nominate,
+                                           pj_ice_msg_data *msg_data)
+{
+    pj_ice_sess_check      *check;
+    const pj_ice_sess_cand *lcand;
+    const pj_ice_sess_cand *rcand;
+    pj_ice_sess_comp       *comp;
+    pj_status_t            status;
+
+    check = &clist->checks[check_id];
+    lcand = check->lcand;
+    rcand = check->rcand;
+    comp  = find_comp(ice, lcand->comp_id);
+
+    /* Note that USERNAME and MESSAGE-INTEGRITY will be added by the
+     * STUN session.
+     */
+
+    /* Initiate STUN transaction to send the request */
+    status = pj_stun_session_send_msg(comp->stun_sess, msg_data, PJ_FALSE,
+                                      pj_stun_session_tp_type(comp->stun_sess) == PJ_STUN_TP_UDP,
+                                      &rcand->addr,
+                                      pj_sockaddr_get_len(&rcand->addr),
+                                      check->tdata);
+    if (status != PJ_SUCCESS) {
+        check->tdata = NULL;
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+        on_check_complete(ice, check);
+        pjnath_perror(ice->obj_name, "Error sending STUN request", status);
+        pj_log_pop_indent();
+    }
+    return status;
+}
+
 /* Perform check on the specified candidate pair. */
 static pj_status_t perform_check(pj_ice_sess *ice, 
-				 pj_ice_sess_checklist *clist,
-				 unsigned check_id,
-				 pj_bool_t nominate)
+                                 pj_ice_sess_checklist *clist,
+                                 unsigned check_id,
+                                 pj_bool_t nominate)
 {
     pj_ice_sess_comp *comp;
     pj_ice_msg_data *msg_data;
@@ -1781,18 +1903,18 @@ static pj_status_t perform_check(pj_ice_sess *ice,
     comp = find_comp(ice, lcand->comp_id);
 
     LOG5((ice->obj_name, 
-	 "Sending connectivity check for check %s", 
-	 dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), clist, check)));
+          "Sending connectivity check for check %s", 
+          dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), clist, check)));
     pj_log_push_indent();
 
     /* Create request */
     status = pj_stun_session_create_req(comp->stun_sess, 
-					PJ_STUN_BINDING_REQUEST, PJ_STUN_MAGIC,
-					NULL, &check->tdata);
+                                        PJ_STUN_BINDING_REQUEST, PJ_STUN_MAGIC,
+                                        NULL, &check->tdata);
     if (status != PJ_SUCCESS) {
-	pjnath_perror(ice->obj_name, "Error creating STUN request", status);
-	pj_log_pop_indent();
-	return status;
+        pjnath_perror(ice->obj_name, "Error creating STUN request", status);
+        pj_log_pop_indent();
+        return status;
     }
 
     /* Attach data to be retrieved later when STUN request transaction
@@ -1808,63 +1930,109 @@ static pj_status_t perform_check(pj_ice_sess *ice,
     /* Add PRIORITY */
 #if PJNATH_ICE_PRIO_STD
     prio = CALC_CAND_PRIO(ice, PJ_ICE_CAND_TYPE_PRFLX, 65535, 
-			  lcand->comp_id);
+                          lcand->comp_id);
 #else
     prio = CALC_CAND_PRIO(ice, PJ_ICE_CAND_TYPE_PRFLX, 0, 
-			  lcand->comp_id);
+                          lcand->comp_id);
 #endif
     pj_stun_msg_add_uint_attr(check->tdata->pool, check->tdata->msg, 
-			      PJ_STUN_ATTR_PRIORITY, prio);
+                              PJ_STUN_ATTR_PRIORITY, prio);
 
     /* Add USE-CANDIDATE and set this check to nominated.
      * Also add ICE-CONTROLLING or ICE-CONTROLLED
      */
-    if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLING) {
-	if (nominate) {
-	    pj_stun_msg_add_empty_attr(check->tdata->pool, check->tdata->msg,
-				       PJ_STUN_ATTR_USE_CANDIDATE);
-	    check->nominated = PJ_TRUE;
-	}
+    if (nominate) {
+        check->nominated = PJ_TRUE;
+        if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLING)
+            pj_stun_msg_add_empty_attr(check->tdata->pool,
+                                       check->tdata->msg,
+                                       PJ_STUN_ATTR_USE_CANDIDATE);
+    }
+    pj_stun_msg_add_uint64_attr(check->tdata->pool, check->tdata->msg,
+                                PJ_STUN_ATTR_ICE_CONTROLLING,
+                                &ice->tie_breaker);
 
-	pj_stun_msg_add_uint64_attr(check->tdata->pool, check->tdata->msg, 
-				    PJ_STUN_ATTR_ICE_CONTROLLING,
-				    &ice->tie_breaker);
 
+#if PJ_HAS_TCP
+    switch (lcand->transport) {
+    case PJ_CAND_UDP:
+        status = send_connectivity_check(ice, clist, check_id,
+                                         nominate, msg_data);
+        break;
+    case PJ_CAND_TCP_ACTIVE:
+        switch (check->state) {
+        case PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY:
+            if (ice->timer.id != TIMER_NONE)
+                pj_assert(!"Not expected any timer active");
+            status = (*ice->cb.reconnect_tcp_connection)(ice, clist, check_id);
+            break;
+        case PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET:
+            status = send_connectivity_check(ice, clist, check_id,
+                                             nominate, msg_data);
+        default:
+            pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap,
+                                           &ice->timer, TIMER_NONE);
+            status = (*ice->cb.wait_tcp_connection)(ice, clist, check_id);
+            if (ice->timer.id != TIMER_NONE) {
+                pj_assert(!"Not expected any timer active");
+            } else {
+                pj_time_val delay = {0, 0};
+                delay.msec        = 1500;
+                pj_time_val_normalize(&delay);
+                pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                                  &ice->timer, &delay,
+                                                  TIMER_CONNECTION_TIMEOUT,
+                                                  ice->grp_lock);
+            }
+            break;
+        }
+    default:
+        /* TCP PASSIVE */
+        if (lcand->type == PJ_ICE_CAND_TYPE_RELAYED) {
+            pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap,
+                                           &ice->timer, TIMER_NONE);
+            status = (*ice->cb.select_turn_dataconn)(ice, clist, check_id);
+            if (ice->timer.id == TIMER_NONE) {
+                pj_time_val delay = {0, 0};
+                delay.msec        = 1500;
+                pj_time_val_normalize(&delay);
+                pj_timer_heap_schedule_w_grp_lock(ice->stun_cfg.timer_heap,
+                                                  &ice->timer, &delay,
+                                                  TIMER_CONNECTION_TIMEOUT,
+                                                  ice->grp_lock);
+            }
+        } else
+            status = send_connectivity_check(ice, clist, check_id,
+                                             nominate, msg_data);
+        break;
+    }
+#else
+    status = send_connectivity_check(&ice, &clist, check_id, nominate, msg_data);
+#endif
+
+    if (status == PJ_EPENDING) {
+        check_set_state(ice, check,
+                        PJ_ICE_SESS_CHECK_STATE_PENDING, status);
     } else {
-	pj_stun_msg_add_uint64_attr(check->tdata->pool, check->tdata->msg, 
-				    PJ_STUN_ATTR_ICE_CONTROLLED,
-				    &ice->tie_breaker);
+        if (check->rcand->type == PJ_ICE_CAND_TYPE_RELAYED) {
+            // TODO (sblin) remove this - https://github.com/coturn/coturn/issues/408
+            check_set_state(ice, check,
+                            PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET, status);
+        } else {
+            check_set_state(ice, check,
+                            PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS, PJ_SUCCESS);
+        }
     }
-
-
-    /* Note that USERNAME and MESSAGE-INTEGRITY will be added by the 
-     * STUN session.
-     */
-
-    /* Initiate STUN transaction to send the request */
-    status = pj_stun_session_send_msg(comp->stun_sess, msg_data, PJ_FALSE, 
-				      PJ_TRUE, &rcand->addr, 
-				      pj_sockaddr_get_len(&rcand->addr),
-				      check->tdata);
-    if (status != PJ_SUCCESS) {
-	check->tdata = NULL;
-	pjnath_perror(ice->obj_name, "Error sending STUN request", status);
-	pj_log_pop_indent();
-	return status;
-    }
-
-    check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS, 
-	            PJ_SUCCESS);
     pj_log_pop_indent();
-    return PJ_SUCCESS;
+    return status;
 }
 
 
 /* Start periodic check for the specified checklist.
  * This callback is called by timer on every Ta (20msec by default)
  */
-static pj_status_t start_periodic_check(pj_timer_heap_t *th, 
-					pj_timer_entry *te)
+static pj_status_t start_periodic_check(pj_timer_heap_t *th,
+                                        pj_timer_entry *te)
 {
     timer_data *td;
     pj_ice_sess *ice;
@@ -1879,8 +2047,8 @@ static pj_status_t start_periodic_check(pj_timer_heap_t *th,
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_SUCCESS;
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_SUCCESS;
     }
 
     /* Set timer ID to FALSE first */
@@ -1892,55 +2060,113 @@ static pj_status_t start_periodic_check(pj_timer_heap_t *th,
     LOG5((ice->obj_name, "Starting checklist periodic check"));
     pj_log_push_indent();
 
+    /* Send STUN Binding request for check with highest priority on
+     * retry state.
+     */
+
+    if (start_count == 0) {
+        for (i = 0; i < clist->count; ++i) {
+            pj_ice_sess_check *check = &clist->checks[i];
+            // Reconnect closed TURN sockets
+            if (check->state == PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY) {
+                status = perform_check(ice, clist, i, ice->is_nominating);
+                if (status != PJ_SUCCESS && status != PJ_EPENDING) {
+                    check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED,
+                                    status);
+                    on_check_complete(ice, check);
+                }
+                ++start_count;
+                break;
+            }
+        }
+    }
+
+    if (start_count == 0) {
+        // TODO (sblin) remove - https://github.com/coturn/coturn/issues/408
+        pj_bool_t inc_counter = PJ_TRUE;
+        for (i = 0; i < clist->count; ++i) {
+            pj_ice_sess_check *check = &clist->checks[i];
+            if (check->state == PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET) {
+                if (inc_counter) {
+                    td->first_packet_counter += 1;
+                    inc_counter = PJ_FALSE;
+                }
+                if (td->first_packet_counter % 50 == 0) {
+                    status = perform_check(ice, clist, i, ice->is_nominating);
+                    if (status != PJ_SUCCESS && status != PJ_EPENDING) {
+                        check_set_state(ice, check,
+                                        PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+                        on_check_complete(ice, check);
+                    }
+                }
+                ++start_count;
+                break;
+            }
+        }
+    }
+
     /* Send STUN Binding request for check with highest priority on
      * Waiting state.
      */
-    for (i=0; i<clist->count; ++i) {
-	pj_ice_sess_check *check = &clist->checks[i];
 
-	if (check->state == PJ_ICE_SESS_CHECK_STATE_WAITING) {
-	    status = perform_check(ice, clist, i, ice->is_nominating);
-	    if (status != PJ_SUCCESS) {
-		check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED,
-				status);
-		on_check_complete(ice, check);
-	    }
+    if (start_count == 0) {
+        for (i = 0; i < clist->count; ++i) {
+            pj_ice_sess_check *check = &clist->checks[i];
 
-	    ++start_count;
-	    break;
-	}
+            if (check->state == PJ_ICE_SESS_CHECK_STATE_WAITING) {
+                status = perform_check(ice, clist, i, ice->is_nominating);
+                if (status != PJ_SUCCESS && status != PJ_EPENDING) {
+                    check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED,
+                                    status);
+                    on_check_complete(ice, check);
+                }
+                ++start_count;
+                break;
+            }
+        }
     }
 
     /* If we don't have anything in Waiting state, perform check to
      * highest priority pair that is in Frozen state.
      */
-    if (start_count==0) {
-	for (i=0; i<clist->count; ++i) {
-	    pj_ice_sess_check *check = &clist->checks[i];
+    if (start_count == 0) {
+        for (i = 0; i < clist->count; ++i) {
+            pj_ice_sess_check *check = &clist->checks[i];
 
-	    if (check->state == PJ_ICE_SESS_CHECK_STATE_FROZEN) {
-		status = perform_check(ice, clist, i, ice->is_nominating);
-		if (status != PJ_SUCCESS) {
-		    check_set_state(ice, check,
-		    		    PJ_ICE_SESS_CHECK_STATE_FAILED, status);
-		    on_check_complete(ice, check);
-		}
+            if (check->state == PJ_ICE_SESS_CHECK_STATE_FROZEN) {
+                status = perform_check(ice, clist, i, ice->is_nominating);
+                if (status != PJ_SUCCESS && status != PJ_EPENDING) {
+                    check_set_state(ice, check,
+                                    PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+                    on_check_complete(ice, check);
+                }
+                ++start_count;
+                break;
+            }
+        }
+    }
 
-		++start_count;
-		break;
-	    }
-	}
+    if (start_count == 0) {
+        // If all sockets are pending, do nothing
+        pj_bool_t inc_counter = PJ_TRUE;
+        for (i = 0; i < clist->count; ++i) {
+            pj_ice_sess_check *check = &clist->checks[i];
+            if (check->state == PJ_ICE_SESS_CHECK_STATE_PENDING) {
+                ++start_count;
+                break;
+            }
+        }
     }
 
     /* Cannot start check because there's no suitable candidate pair.
-     */
+    */
     if (start_count!=0) {
-	/* Schedule for next timer */
-	pj_time_val timeout = {0, PJ_ICE_TA_VAL};
+        /* Schedule for next timer */
+        pj_time_val timeout = {0, PJ_ICE_TA_VAL};
 
-	pj_time_val_normalize(&timeout);
-	pj_timer_heap_schedule_w_grp_lock(th, te, &timeout, PJ_TRUE,
-	                                  ice->grp_lock);
+        pj_time_val_normalize(&timeout);
+        pj_timer_heap_schedule_w_grp_lock(th, te, &timeout, PJ_TRUE,
+                                          ice->grp_lock);
     }
 
     pj_grp_lock_release(ice->grp_lock);
@@ -1963,32 +2189,32 @@ static void start_nominated_check(pj_ice_sess *ice)
 
     /* Stop our timer if it's active */
     if (ice->timer.id == TIMER_START_NOMINATED_CHECK) {
-	pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
-	                               TIMER_NONE);
+        pj_timer_heap_cancel_if_active(ice->stun_cfg.timer_heap, &ice->timer,
+                                       TIMER_NONE);
     }
 
     /* For each component, set the check state of valid check with
      * highest priority to Waiting (it should have Success state now).
      */
     for (i=0; i<ice->comp_cnt; ++i) {
-	unsigned j;
-	const pj_ice_sess_check *vc = ice->comp[i].valid_check;
+        unsigned j;
+        const pj_ice_sess_check *vc = ice->comp[i].valid_check;
 
-	pj_assert(ice->comp[i].nominated_check == NULL);
-	pj_assert(vc->err_code == PJ_SUCCESS);
+        pj_assert(ice->comp[i].nominated_check == NULL);
+        pj_assert(vc->err_code == PJ_SUCCESS);
 
-	for (j=0; j<ice->clist.count; ++j) {
-	    pj_ice_sess_check *c = &ice->clist.checks[j];
-	    if (c->lcand->transport_id == vc->lcand->transport_id &&
-		c->rcand == vc->rcand)
-	    {
-		pj_assert(c->err_code == PJ_SUCCESS);
-		c->state = PJ_ICE_SESS_CHECK_STATE_FROZEN;
-		check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_WAITING, 
-			        PJ_SUCCESS);
-		break;
-	    }
-	}
+        for (j=0; j<ice->clist.count; ++j) {
+            pj_ice_sess_check *c = &ice->clist.checks[j];
+            if (c->lcand->transport_id == vc->lcand->transport_id &&
+                c->rcand == vc->rcand)
+            {
+                pj_assert(c->err_code == PJ_SUCCESS);
+                c->state = PJ_ICE_SESS_CHECK_STATE_FROZEN;
+                check_set_state(ice, c, PJ_ICE_SESS_CHECK_STATE_WAITING, 
+                                PJ_SUCCESS);
+                break;
+            }
+        }
     }
 
     /* And (re)start the periodic check */
@@ -2001,7 +2227,7 @@ static void start_nominated_check(pj_ice_sess *ice)
                                                PJ_TRUE,
                                                ice->grp_lock);
     if (status == PJ_SUCCESS) {
-	LOG5((ice->obj_name, "Periodic timer rescheduled.."));
+        LOG5((ice->obj_name, "Periodic timer rescheduled.."));
     }
 
     ice->is_nominating = PJ_TRUE;
@@ -2010,7 +2236,7 @@ static void start_nominated_check(pj_ice_sess *ice)
 
 /* Timer callback to perform periodic check */
 static void periodic_timer(pj_timer_heap_t *th, 
-			   pj_timer_entry *te)
+                           pj_timer_entry *te)
 {
     start_periodic_check(th, te);
 }
@@ -2018,12 +2244,12 @@ static void periodic_timer(pj_timer_heap_t *th,
 
 /* Utility: find string in string array */
 static const pj_str_t *find_str(const pj_str_t *strlist[], unsigned count,
-				const pj_str_t *str)
+                                const pj_str_t *str)
 {
     unsigned i;
     for (i=0; i<count; ++i) {
-	if (pj_strcmp(strlist[i], str)==0)
-	    return strlist[i];
+        if (pj_strcmp(strlist[i], str)==0)
+            return strlist[i];
     }
     return NULL;
 }
@@ -2057,7 +2283,7 @@ PJ_DEF(pj_status_t) pj_ice_sess_start_check(pj_ice_sess *ice)
 
     /* If we are using aggressive nomination, set the is_nominating state */
     if (ice->opt.aggressive)
-	ice->is_nominating = PJ_TRUE;
+        ice->is_nominating = PJ_TRUE;
 
     /* The agent examines the check list for the first media stream (a
      * media stream is the first media stream when it is described by
@@ -2075,22 +2301,22 @@ PJ_DEF(pj_status_t) pj_ice_sess_start_check(pj_ice_sess *ice)
 
     /* Pickup the first pair for component 1. */
     for (i=0; i<clist->count; ++i) {
-	if (clist->checks[i].lcand->comp_id == 1)
-	    break;
+        if (clist->checks[i].lcand->comp_id == 1)
+            break;
     }
     if (i == clist->count) {
-	pj_assert(!"Unable to find checklist for component 1");
-	pj_grp_lock_release(ice->grp_lock);
-	pj_log_pop_indent();
-	return PJNATH_EICEINCOMPID;
+        pj_assert(!"Unable to find checklist for component 1");
+        pj_grp_lock_release(ice->grp_lock);
+        pj_log_pop_indent();
+        return PJNATH_EICEINCOMPID;
     }
 
     /* Set this check to WAITING only if state is frozen. It may be possible
      * that this check has already been started by a trigger check
      */
     if (clist->checks[i].state == PJ_ICE_SESS_CHECK_STATE_FROZEN) {
-	check_set_state(ice, &clist->checks[i], 
-			PJ_ICE_SESS_CHECK_STATE_WAITING, PJ_SUCCESS);
+        check_set_state(ice, &clist->checks[i], 
+                        PJ_ICE_SESS_CHECK_STATE_WAITING, PJ_SUCCESS);
     }
 
     cand0 = clist->checks[i].lcand;
@@ -2101,31 +2327,31 @@ PJ_DEF(pj_status_t) pj_ice_sess_start_check(pj_ice_sess *ice)
      * states to Waiting as well.
      */
     for (++i; i<clist->count; ++i) {
-	const pj_ice_sess_cand *cand1;
+        const pj_ice_sess_cand *cand1;
 
-	cand1 = clist->checks[i].lcand;
+        cand1 = clist->checks[i].lcand;
 
-	if (cand1->comp_id==cand0->comp_id &&
-	    find_str(flist, flist_cnt, &cand1->foundation)==NULL)
-	{
-	    if (clist->checks[i].state == PJ_ICE_SESS_CHECK_STATE_FROZEN) {
-		check_set_state(ice, &clist->checks[i], 
-				PJ_ICE_SESS_CHECK_STATE_WAITING, PJ_SUCCESS);
-	    }
-	    flist[flist_cnt++] = &cand1->foundation;
-	}
+        if (cand1->comp_id==cand0->comp_id &&
+            find_str(flist, flist_cnt, &cand1->foundation)==NULL)
+        {
+            if (clist->checks[i].state == PJ_ICE_SESS_CHECK_STATE_FROZEN) {
+                check_set_state(ice, &clist->checks[i], 
+                                PJ_ICE_SESS_CHECK_STATE_WAITING, PJ_SUCCESS);
+            }
+            flist[flist_cnt++] = &cand1->foundation;
+        }
     }
 
     /* First, perform all pending triggered checks, simultaneously. */
     rcheck = ice->early_check.next;
     while (rcheck != &ice->early_check) {
-	LOG4((ice->obj_name, 
-	      "Performing delayed triggerred check for component %d",
-	      rcheck->comp_id));
-	pj_log_push_indent();
-	handle_incoming_check(ice, rcheck);
-	rcheck = rcheck->next;
-	pj_log_pop_indent();
+        LOG4((ice->obj_name, 
+              "Performing delayed triggerred check for component %d",
+              rcheck->comp_id));
+        pj_log_push_indent();
+        handle_incoming_check(ice, rcheck);
+        rcheck = rcheck->next;
+        pj_log_pop_indent();
     }
     pj_list_init(&ice->early_check);
 
@@ -2139,7 +2365,7 @@ PJ_DEF(pj_status_t) pj_ice_sess_start_check(pj_ice_sess *ice)
                                                &clist->timer, &delay,
                                                PJ_TRUE, ice->grp_lock);
     if (status != PJ_SUCCESS) {
-	clist->timer.id = PJ_FALSE;
+        clist->timer.id = PJ_FALSE;
     }
 
     pj_grp_lock_release(ice->grp_lock);
@@ -2154,42 +2380,218 @@ PJ_DEF(pj_status_t) pj_ice_sess_start_check(pj_ice_sess *ice)
  * STUN session also doesn't have a transport, remember?!
  */
 static pj_status_t on_stun_send_msg(pj_stun_session *sess,
-				    void *token,
-				    const void *pkt,
-				    pj_size_t pkt_size,
-				    const pj_sockaddr_t *dst_addr,
-				    unsigned addr_len)
+                                    void *token,
+                                    const void *pkt,
+                                    pj_size_t pkt_size,
+                                    const pj_sockaddr_t *dst_addr,
+                                    unsigned addr_len)
 {
     stun_data *sd = (stun_data*) pj_stun_session_get_user_data(sess);
     pj_ice_sess *ice = sd->ice;
     pj_ice_msg_data *msg_data = (pj_ice_msg_data*) token;
     pj_status_t status;
-    
+
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	/* Stray retransmit timer that could happen while
-	 * we're being destroyed */
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_EINVALIDOP;
+        /* Stray retransmit timer that could happen while
+         * we're being destroyed */
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_EINVALIDOP;
     }
 
     status = (*ice->cb.on_tx_pkt)(ice, sd->comp_id, msg_data->transport_id,
-				  pkt, pkt_size, dst_addr, addr_len);
+                                  pkt, pkt_size, dst_addr, addr_len);
 
     pj_grp_lock_release(ice->grp_lock);
     return status;
 }
 
+static pj_ice_sess_check* get_current_check_at_state(pj_ice_sess *ice,
+                                                     pj_sockaddr_t* remote_addr,
+                                                     pj_ice_sess_check_state state,
+                                                     int* current_check)
+{
+    if (!ice || !remote_addr)
+        return NULL;
+    // NOTE: Multiple checks can have the same remote, we only take care of the first
+    // First, check if the TCP is really connected. If not, abort
+    pj_ice_sess_check *check = NULL;
+    for (int i = 0; i < ice->clist.count; ++i) {
+        // Find related check
+        pj_ice_sess_check *c = &ice->clist.checks[i];
+        /* Host candidate not found this this srflx! */
+        if (pj_sockaddr_cmp(remote_addr, &c->rcand->addr) == 0) {
+            if (c->tdata == NULL || c->state != state)
+                continue;
+            /* Match */
+            check = c;
+            if (current_check) *current_check = i;
+            break;
+        }
+    }
+    return check;
+}
+
+void ice_sess_on_peer_connection(pj_ice_sess *ice,
+                                 pj_uint8_t transport_id,
+                                 pj_status_t status,
+                                 pj_sockaddr_t* remote_addr)
+{
+    // The TCP link is now ready. We can now send the first STUN message (send
+    // connectivity check) This should trigger on_stun_request_complete when
+    // finished
+    if (!remote_addr)
+        return;
+
+    int current_check = -1;
+    pj_ice_sess_check *check = get_current_check_at_state(ice,remote_addr,
+                                                          PJ_ICE_SESS_CHECK_STATE_PENDING,
+                                                          &current_check);
+    if (!check) {
+        // Handle peer reflexive candidates (incoming are still waiting here)
+        check = get_current_check_at_state(ice, remote_addr,
+                                           PJ_ICE_SESS_CHECK_STATE_WAITING,
+                                           &current_check);
+        if (!check) {
+            return;
+        }
+    }
+
+    if (status != PJ_SUCCESS) {
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+        on_check_complete(ice, check);
+        return;
+    }
+
+    // TCP is correctly connected. Craft the message to send
+    const pj_ice_sess_cand *lcand = check->lcand;
+    const pj_ice_sess_cand *rcand = check->rcand;
+    if (check->tdata == NULL) {
+        LOG5((ice->obj_name, "Error sending STUN request, empty data"));
+        return;
+    }
+    pj_ice_msg_data *msg_data =
+        PJ_POOL_ZALLOC_T(check->tdata->pool, pj_ice_msg_data);
+
+    msg_data->transport_id = transport_id;
+    msg_data->has_req_data = PJ_TRUE;
+    msg_data->data.req.ice = ice;
+    msg_data->data.req.clist = &ice->clist;
+    msg_data->data.req.ckid = current_check;
+
+    pj_ice_sess_comp *comp = find_comp(ice, lcand->comp_id);
+    pj_status_t status_send_msg;
+    // Note that USERNAME and MESSAGE-INTEGRITY will be added by the
+    // STUN session.
+
+    // Initiate STUN transaction to send the request
+    status_send_msg = pj_stun_session_send_msg(comp->stun_sess, msg_data,
+                                               PJ_FALSE, PJ_FALSE, &rcand->addr,
+                                               pj_sockaddr_get_len(&rcand->addr),
+                                               check->tdata);
+    if (status_send_msg == PJ_EBUSY /* EBUSY */) {
+        check_set_state(ice, check,
+                        PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET, status);
+        return;
+    }
+    if (status_send_msg == 120033 /* BROKEN PIPE */) {
+        check_set_state(ice, check,
+                        PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY, status);
+        return;
+    }
+
+    if ((status_send_msg == 120104 || status_send_msg == 130054)/* CONNECTION RESET BY PEER */
+        && rcand->type == PJ_ICE_CAND_TYPE_RELAYED) {
+        /**
+         * This part of the code is triggered when using ICE over TCP via TURN
+         * In fact, the other peer has to authorize this peer to connect to
+         * the relayed candidate. This is done by set_perm from the other case.
+         * But from this side, we can't know if the peer has authorized us. If it's
+         * not the case, the connection will got a CONNECTION RESET BY PEER status.
+         * In this case, we can try to reconnect a bit after and this until the check
+         * reached its timeout.
+         */
+        check_set_state(ice, check,PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY, status);
+    } else if (status_send_msg != PJ_SUCCESS) {
+        check->tdata = NULL;
+        pjnath_perror(ice->obj_name, "Error sending STUN request", status_send_msg);
+        pj_log_pop_indent();
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+        on_check_complete(ice, check);
+    } else if (rcand->type == PJ_ICE_CAND_TYPE_RELAYED) {
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET, status);
+    } else {
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS, status);
+    }
+}
+
+void ice_sess_on_peer_reset_connection(pj_ice_sess *ice,
+                                              pj_uint8_t transport_id,
+                                              pj_sockaddr_t* remote_addr)
+{
+    // The TCP link is reseted
+    if (!remote_addr)
+        return;
+
+    pj_ice_sess_check *check = get_current_check_at_state(ice, remote_addr,
+                                                          PJ_ICE_SESS_CHECK_STATE_PENDING,
+                                                          NULL);
+    if (!check) {
+        // Just check if it's not the first packet failing
+        check = get_current_check_at_state(ice, remote_addr,
+                                           PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET,
+                                           NULL);
+        if (!check)
+            return;
+    }
+
+    const pj_ice_sess_cand *rcand = check->rcand;
+    if (rcand->type == PJ_ICE_CAND_TYPE_RELAYED)
+        check_set_state(ice, check,
+                        PJ_ICE_SESS_CHECK_STATE_NEEDS_RETRY, 120104);
+}
+
+void ice_sess_on_peer_packet(pj_ice_sess *ice,
+                             pj_uint8_t transport_id,
+                             pj_sockaddr_t* remote_addr)
+{
+    // The TCP link received its bind  request response
+    if (!ice || !remote_addr)
+        return;
+    pj_ice_sess_check *check = get_current_check_at_state(ice, remote_addr,
+                                                          PJ_ICE_SESS_CHECK_STATE_NEEDS_FIRST_PACKET,
+                                                          NULL);
+    if (!check)
+        return;
+
+    const pj_ice_sess_cand *rcand = check->rcand;
+    if (rcand->type == PJ_ICE_CAND_TYPE_RELAYED)
+        check_set_state(ice, check,
+                        PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS, PJ_SUCCESS);
+}
+
+
+void ice_select_incoming_turn(pj_ice_sess *ice,
+                              pj_ice_sess_checklist *clist,
+                              unsigned check_id)
+{
+    check_set_state(ice, &clist->checks[check_id],
+                    PJ_ICE_SESS_CHECK_STATE_SUCCEEDED, PJ_SUCCESS);
+    update_comp_check(ice, clist->checks[check_id].lcand->comp_id,
+                      &clist->checks[check_id]);
+    on_check_complete(ice, &clist->checks[check_id]);
+}
+
 
 /* This callback is called when outgoing STUN request completed */
 static void on_stun_request_complete(pj_stun_session *stun_sess,
-				     pj_status_t status,
-				     void *token,
-				     pj_stun_tx_data *tdata,
-				     const pj_stun_msg *response,
-				     const pj_sockaddr_t *src_addr,
-				     unsigned src_addr_len)
+                                     pj_status_t status,
+                                     void *token,
+                                     pj_stun_tx_data *tdata,
+                                     const pj_stun_msg *response,
+                                     const pj_sockaddr_t *src_addr,
+                                     unsigned src_addr_len)
 {
     pj_ice_msg_data *msg_data = (pj_ice_msg_data*) token;
     pj_ice_sess *ice;
@@ -2208,7 +2610,7 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
     ice = msg_data->data.req.ice;
     clist = msg_data->data.req.clist;
     check = &clist->checks[msg_data->data.req.ckid];
-    
+
 
     /* Mark STUN transaction as complete */
     pj_assert(tdata == check->tdata);
@@ -2217,9 +2619,9 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	/* Not sure if this is possible but just in case */
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        /* Not sure if this is possible but just in case */
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
     /* Init lcand to NULL. lcand will be found from the mapped address
@@ -2228,66 +2630,66 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
     lcand = NULL;
 
     if (status != PJ_SUCCESS) {
-	char errmsg[PJ_ERR_MSG_SIZE];
+        char errmsg[PJ_ERR_MSG_SIZE];
 
-	if (status==PJ_STATUS_FROM_STUN_CODE(PJ_STUN_SC_ROLE_CONFLICT)) {
+        if (status==PJ_STATUS_FROM_STUN_CODE(PJ_STUN_SC_ROLE_CONFLICT)) {
 
-	    /* Role conclict response.
-	     *
-	     * 7.1.2.1.  Failure Cases:
-	     *
-	     * If the request had contained the ICE-CONTROLLED attribute, 
-	     * the agent MUST switch to the controlling role if it has not
-	     * already done so.  If the request had contained the 
-	     * ICE-CONTROLLING attribute, the agent MUST switch to the 
-	     * controlled role if it has not already done so.  Once it has
-	     * switched, the agent MUST immediately retry the request with
-	     * the ICE-CONTROLLING or ICE-CONTROLLED attribute reflecting 
-	     * its new role.
-	     */
-	    pj_ice_sess_role new_role = PJ_ICE_SESS_ROLE_UNKNOWN;
-	    pj_stun_msg *req = tdata->msg;
+            /* Role conclict response.
+             *
+             * 7.1.2.1.  Failure Cases:
+             *
+             * If the request had contained the ICE-CONTROLLED attribute, 
+             * the agent MUST switch to the controlling role if it has not
+             * already done so.  If the request had contained the
+             * ICE-CONTROLLING attribute, the agent MUST switch to the 
+             * controlled role if it has not already done so.  Once it has
+             * switched, the agent MUST immediately retry the request with
+             * the ICE-CONTROLLING or ICE-CONTROLLED attribute reflecting 
+             * its new role.
+             */
+            pj_ice_sess_role new_role = PJ_ICE_SESS_ROLE_UNKNOWN;
+            pj_stun_msg *req = tdata->msg;
 
-	    if (pj_stun_msg_find_attr(req, PJ_STUN_ATTR_ICE_CONTROLLING, 0)) {
-		new_role = PJ_ICE_SESS_ROLE_CONTROLLED;
-	    } else if (pj_stun_msg_find_attr(req, PJ_STUN_ATTR_ICE_CONTROLLED, 
-					     0)) {
-		new_role = PJ_ICE_SESS_ROLE_CONTROLLING;
-	    } else {
-		pj_assert(!"We should have put CONTROLLING/CONTROLLED attr!");
-		new_role = PJ_ICE_SESS_ROLE_CONTROLLED;
-	    }
+            if (pj_stun_msg_find_attr(req, PJ_STUN_ATTR_ICE_CONTROLLING, 0)) {
+                new_role = PJ_ICE_SESS_ROLE_CONTROLLED;
+            } else if (pj_stun_msg_find_attr(req, PJ_STUN_ATTR_ICE_CONTROLLED, 
+                                             0)) {
+                new_role = PJ_ICE_SESS_ROLE_CONTROLLING;
+            } else {
+                pj_assert(!"We should have put CONTROLLING/CONTROLLED attr!");
+                new_role = PJ_ICE_SESS_ROLE_CONTROLLED;
+            }
 
-	    if (new_role != ice->role) {
-		LOG4((ice->obj_name, 
-		      "Changing role because of role conflict response"));
-		pj_ice_sess_change_role(ice, new_role);
-	    }
+            if (new_role != ice->role) {
+                LOG4((ice->obj_name, 
+                      "Changing role because of role conflict response"));
+                pj_ice_sess_change_role(ice, new_role);
+            }
 
-	    /* Resend request */
-	    LOG4((ice->obj_name, "Resending check because of role conflict"));
-	    pj_log_push_indent();
-	    check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_WAITING, 0);
-	    perform_check(ice, clist, msg_data->data.req.ckid, 
-			  check->nominated || ice->is_nominating);
-	    pj_log_pop_indent();
-	    pj_grp_lock_release(ice->grp_lock);
-	    return;
-	}
+            /* Resend request */
+            LOG4((ice->obj_name, "Resending check because of role conflict"));
+            pj_log_push_indent();
+            check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_WAITING, 0);
+            perform_check(ice, clist, msg_data->data.req.ckid, 
+                          check->nominated || ice->is_nominating);
+            pj_log_pop_indent();
+            pj_grp_lock_release(ice->grp_lock);
+            return;
+        }
 
-	pj_strerror(status, errmsg, sizeof(errmsg));
-	LOG4((ice->obj_name, 
-	     "Check %s%s: connectivity check FAILED: %s",
-	     dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-			&ice->clist, check),
-	     (check->nominated ? " (nominated)" : " (not nominated)"),
-	     errmsg));
-	pj_log_push_indent();
-	check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
-	on_check_complete(ice, check);
-	pj_log_pop_indent();
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        pj_strerror(status, errmsg, sizeof(errmsg));
+        LOG4((ice->obj_name, 
+              "Check %s%s: connectivity check FAILED: %s",
+              dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                         &ice->clist, check),
+              (check->nominated ? " (nominated)" : " (not nominated)"),
+              errmsg));
+        pj_log_push_indent();
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+        on_check_complete(ice, check);
+        pj_log_pop_indent();
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
 
@@ -2307,29 +2709,29 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
          * is synthesized from IPv4).
          */
         pj_sockaddr synth_addr;
-    	
-    	status = pj_sockaddr_synthesize(pj_AF_INET6(), &synth_addr,
-    					&check->rcand->addr);
-    	if (status == PJ_SUCCESS &&
-    	    pj_sockaddr_cmp(&synth_addr, src_addr) == 0)
-    	{
-    	    source_addr = &check->rcand->addr;
-    	}
+
+        status = pj_sockaddr_synthesize(pj_AF_INET6(), &synth_addr,
+                                        &check->rcand->addr);
+        if (status == PJ_SUCCESS &&
+            pj_sockaddr_cmp(&synth_addr, src_addr) == 0)
+        {
+            source_addr = &check->rcand->addr;
+        }
     }
 
     if (pj_sockaddr_cmp(&check->rcand->addr, source_addr) != 0) {
-	status = PJNATH_EICEINSRCADDR;
-	LOG4((ice->obj_name, 
-	     "Check %s%s: connectivity check FAILED: source address mismatch",
-	     dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-			&ice->clist, check),
-	     (check->nominated ? " (nominated)" : " (not nominated)")));
-	pj_log_push_indent();
-	check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
-	on_check_complete(ice, check);
-	pj_log_pop_indent();
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        status = PJNATH_EICEINSRCADDR;
+        LOG4((ice->obj_name, 
+              "Check %s%s: connectivity check FAILED: source address mismatch",
+              dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                         &ice->clist, check),
+              (check->nominated ? " (nominated)" : " (not nominated)")));
+        pj_log_push_indent();
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, status);
+        on_check_complete(ice, check);
+        pj_log_pop_indent();
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
     /* 7.1.2.2.  Success Cases
@@ -2349,36 +2751,36 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
 
 
     LOG4((ice->obj_name, 
-	 "Check %s%s: connectivity check SUCCESS",
-	 dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-		    &ice->clist, check),
-	 (check->nominated ? " (nominated)" : " (not nominated)")));
+          "Check %s%s: connectivity check SUCCESS",
+          dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                     &ice->clist, check),
+          (check->nominated ? " (nominated)" : " (not nominated)")));
 
     /* Get the STUN XOR-MAPPED-ADDRESS attribute. */
     xaddr = (pj_stun_xor_mapped_addr_attr*)
-	    pj_stun_msg_find_attr(response, PJ_STUN_ATTR_XOR_MAPPED_ADDR,0);
+        pj_stun_msg_find_attr(response, PJ_STUN_ATTR_XOR_MAPPED_ADDR,0);
     if (!xaddr) {
-	check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, 
-			PJNATH_ESTUNNOMAPPEDADDR);
-	on_check_complete(ice, check);
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, 
+                        PJNATH_ESTUNNOMAPPEDADDR);
+        on_check_complete(ice, check);
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
     /* Find local candidate that matches the XOR-MAPPED-ADDRESS */
     pj_assert(lcand == NULL);
     for (i=0; i<ice->lcand_cnt; ++i) {
-	/* Ticket #1891: apply additional check as there may be a shared
-	 * mapped address for different base/local addresses.
-	 */
-	if (pj_sockaddr_cmp(&xaddr->sockaddr, &ice->lcand[i].addr) == 0 &&
-	    pj_sockaddr_cmp(&check->lcand->base_addr,
-			    &ice->lcand[i].base_addr) == 0)
-	{
-	    /* Match */
-	    lcand = &ice->lcand[i];
-	    break;
-	}
+        /* Ticket #1891: apply additional check as there may be a shared
+         * mapped address for different base/local addresses.
+         */
+        if (pj_sockaddr_cmp(&xaddr->sockaddr, &ice->lcand[i].addr) == 0 &&
+            pj_sockaddr_cmp(&check->lcand->base_addr,
+                            &ice->lcand[i].base_addr) == 0)
+        {
+            /* Match */
+            lcand = &ice->lcand[i];
+            break;
+        }
     }
 
     /* 7.1.2.2.1.  Discovering Peer Reflexive Candidates
@@ -2387,41 +2789,42 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
      * address represents a new candidate - a peer reflexive candidate.
      */
     if (lcand == NULL) {
-	unsigned cand_id;
-	pj_str_t foundation;
+        unsigned cand_id;
+        pj_str_t foundation;
 
-	pj_ice_calc_foundation(ice->pool, &foundation, PJ_ICE_CAND_TYPE_PRFLX,
-			       &check->lcand->base_addr);
+        pj_ice_calc_foundation(ice->pool, &foundation, PJ_ICE_CAND_TYPE_PRFLX,
+                               &check->lcand->base_addr);
 
-	/* Still in 7.1.2.2.1.  Discovering Peer Reflexive Candidates
-	 * Its priority is set equal to the value of the PRIORITY attribute
+        /* Still in 7.1.2.2.1.  Discovering Peer Reflexive Candidates
+         * Its priority is set equal to the value of the PRIORITY attribute
          * in the Binding Request.
-	 *
-	 * I think the priority calculated by add_cand() should be the same
-	 * as the one calculated in perform_check(), so there's no need to
-	 * get the priority from the PRIORITY attribute.
-	 */
+         *
+         * I think the priority calculated by add_cand() should be the same
+         * as the one calculated in perform_check(), so there's no need to
+         * get the priority from the PRIORITY attribute.
+         */
 
-	/* Add new peer reflexive candidate */
-	status = pj_ice_sess_add_cand(ice, check->lcand->comp_id, 
-				      msg_data->transport_id,
-				      PJ_ICE_CAND_TYPE_PRFLX,
-				      65535, &foundation,
-				      &xaddr->sockaddr, 
-				      &check->lcand->base_addr, 
-				      &check->lcand->base_addr,
-				      pj_sockaddr_get_len(&xaddr->sockaddr),
-				      &cand_id);
-	if (status != PJ_SUCCESS) {
-	    check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, 
-			    status);
-	    on_check_complete(ice, check);
-	    pj_grp_lock_release(ice->grp_lock);
-	    return;
-	}
+        /* Add new peer reflexive candidate */
+        status = pj_ice_sess_add_cand(ice, check->lcand->comp_id, 
+                                      msg_data->transport_id,
+                                      PJ_ICE_CAND_TYPE_PRFLX,
+                                      65535, &foundation,
+                                      &xaddr->sockaddr, 
+                                      &check->lcand->base_addr, 
+                                      &check->lcand->base_addr,
+                                      pj_sockaddr_get_len(&xaddr->sockaddr),
+                                      &cand_id,
+                                      check->rcand->transport == PJ_CAND_UDP ? PJ_CAND_UDP : PJ_CAND_TCP_PASSIVE);
+        if (status != PJ_SUCCESS) {
+            check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_FAILED, 
+                            status);
+            on_check_complete(ice, check);
+            pj_grp_lock_release(ice->grp_lock);
+            return;
+        }
 
-	/* Update local candidate */
-	lcand = &ice->lcand[cand_id];
+        /* Update local candidate */
+        lcand = &ice->lcand[cand_id];
 
     }
 
@@ -2435,23 +2838,23 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
      * nominated flag
      */
     for (i=0; i<ice->valid_list.count; ++i) {
-	if (ice->valid_list.checks[i].lcand == lcand &&
-	    ice->valid_list.checks[i].rcand == check->rcand)
-	    break;
+        if (ice->valid_list.checks[i].lcand == lcand &&
+            ice->valid_list.checks[i].rcand == check->rcand)
+            break;
     }
 
     if (i==ice->valid_list.count) {
-	pj_assert(ice->valid_list.count < PJ_ICE_MAX_CHECKS);
-	new_check = &ice->valid_list.checks[ice->valid_list.count++];
-	new_check->lcand = lcand;
-	new_check->rcand = check->rcand;
-	new_check->prio = CALC_CHECK_PRIO(ice, lcand, check->rcand);
-	new_check->state = PJ_ICE_SESS_CHECK_STATE_SUCCEEDED;
-	new_check->nominated = check->nominated;
-	new_check->err_code = PJ_SUCCESS;
+        pj_assert(ice->valid_list.count < PJ_ICE_MAX_CHECKS);
+        new_check = &ice->valid_list.checks[ice->valid_list.count++];
+        new_check->lcand = lcand;
+        new_check->rcand = check->rcand;
+        new_check->prio = CALC_CHECK_PRIO(ice, lcand, check->rcand);
+        new_check->state = PJ_ICE_SESS_CHECK_STATE_SUCCEEDED;
+        new_check->nominated = check->nominated;
+        new_check->err_code = PJ_SUCCESS;
     } else {
-	new_check = &ice->valid_list.checks[i];
-	ice->valid_list.checks[i].nominated = check->nominated;
+        new_check = &ice->valid_list.checks[i];
+        ice->valid_list.checks[i].nominated = check->nominated;
     }
 
     /* Update valid check and nominated check for the component */
@@ -2469,15 +2872,15 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
      * other checks to change as well.
      */
     check_set_state(ice, check, PJ_ICE_SESS_CHECK_STATE_SUCCEEDED, 
-		    PJ_SUCCESS);
+                    PJ_SUCCESS);
 
     /* Perform 7.1.2.2.2.  Updating Pair States.
      * This may terminate ICE processing.
      */
     if (on_check_complete(ice, check)) {
-	/* ICE complete! */
-	pj_grp_lock_release(ice->grp_lock);
-	return;
+        /* ICE complete! */
+        pj_grp_lock_release(ice->grp_lock);
+        return;
     }
 
     pj_grp_lock_release(ice->grp_lock);
@@ -2488,12 +2891,12 @@ static void on_stun_request_complete(pj_stun_session *stun_sess,
  * when it receives incoming request.
  */
 static pj_status_t on_stun_rx_request(pj_stun_session *sess,
-				      const pj_uint8_t *pkt,
-				      unsigned pkt_len,
-				      const pj_stun_rx_data *rdata,
-				      void *token,
-				      const pj_sockaddr_t *src_addr,
-				      unsigned src_addr_len)
+                                      const pj_uint8_t *pkt,
+                                      unsigned pkt_len,
+                                      const pj_stun_rx_data *rdata,
+                                      void *token,
+                                      const pj_sockaddr_t *src_addr,
+                                      unsigned src_addr_len)
 {
     stun_data *sd;
     const pj_stun_msg *msg = rdata->msg;
@@ -2510,13 +2913,13 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
 
     PJ_UNUSED_ARG(pkt);
     PJ_UNUSED_ARG(pkt_len);
-    
+
     /* Reject any requests except Binding request */
     if (msg->hdr.type != PJ_STUN_BINDING_REQUEST) {
-	pj_stun_session_respond(sess, rdata, PJ_STUN_SC_BAD_REQUEST, 
-				NULL, token, PJ_TRUE, 
-				src_addr, src_addr_len);
-	return PJ_SUCCESS;
+        pj_stun_session_respond(sess, rdata, PJ_STUN_SC_BAD_REQUEST, 
+                                NULL, token, PJ_TRUE, 
+                                src_addr, src_addr_len);
+        return PJ_SUCCESS;
     }
 
 
@@ -2526,8 +2929,8 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_EINVALIDOP;
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_EINVALIDOP;
     }
 
     /*
@@ -2540,24 +2943,24 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
 
     /* Get PRIORITY attribute */
     prio_attr = (pj_stun_priority_attr*)
-	        pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_PRIORITY, 0);
+        pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_PRIORITY, 0);
     if (prio_attr == NULL) {
-	LOG5((ice->obj_name, "Received Binding request with no PRIORITY"));
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_SUCCESS;
+        LOG5((ice->obj_name, "Received Binding request with no PRIORITY"));
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_SUCCESS;
     }
 
     /* Get USE-CANDIDATE attribute */
     uc_attr = (pj_stun_use_candidate_attr*)
-	      pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_USE_CANDIDATE, 0);
+        pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_USE_CANDIDATE, 0);
 
 
     /* Get ICE-CONTROLLING or ICE-CONTROLLED */
     role_attr = (pj_stun_uint64_attr*)
-	        pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_ICE_CONTROLLING, 0);
+        pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_ICE_CONTROLLING, 0);
     if (role_attr == NULL) {
-	role_attr = (pj_stun_uint64_attr*)
-	            pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_ICE_CONTROLLED, 0);
+        role_attr = (pj_stun_uint64_attr*)
+            pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_ICE_CONTROLLED, 0);
     }
 
     /* Handle the case when request comes before answer is received.
@@ -2565,49 +2968,49 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
      * got the response, copy the username from the request.
      */
     if (ice->rcand_cnt == 0) {
-	pj_stun_string_attr *uname_attr;
+        pj_stun_string_attr *uname_attr;
 
-	uname_attr = (pj_stun_string_attr*)
-		     pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_USERNAME, 0);
-	pj_assert(uname_attr != NULL);
-	pj_strdup(ice->pool, &ice->rx_uname, &uname_attr->value);
+        uname_attr = (pj_stun_string_attr*)
+            pj_stun_msg_find_attr(msg, PJ_STUN_ATTR_USERNAME, 0);
+        pj_assert(uname_attr != NULL);
+        pj_strdup(ice->pool, &ice->rx_uname, &uname_attr->value);
     }
 
     /* 7.2.1.1.  Detecting and Repairing Role Conflicts
-     */
+    */
     if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLING &&
-	role_attr && role_attr->hdr.type == PJ_STUN_ATTR_ICE_CONTROLLING)
+        role_attr && role_attr->hdr.type == PJ_STUN_ATTR_ICE_CONTROLLING)
     {
-	if (pj_cmp_timestamp(&ice->tie_breaker, &role_attr->value) < 0) {
-	    /* Switch role to controlled */
-	    LOG4((ice->obj_name, 
-		  "Changing role because of ICE-CONTROLLING attribute"));
-	    pj_ice_sess_change_role(ice, PJ_ICE_SESS_ROLE_CONTROLLED);
-	} else {
-	    /* Generate 487 response */
-	    pj_stun_session_respond(sess, rdata, PJ_STUN_SC_ROLE_CONFLICT, 
-				    NULL, token, PJ_TRUE, 
-				    src_addr, src_addr_len);
-	    pj_grp_lock_release(ice->grp_lock);
-	    return PJ_SUCCESS;
-	}
+        if (pj_cmp_timestamp(&ice->tie_breaker, &role_attr->value) < 0) {
+            /* Switch role to controlled */
+            LOG4((ice->obj_name, 
+                  "Changing role because of ICE-CONTROLLING attribute"));
+            pj_ice_sess_change_role(ice, PJ_ICE_SESS_ROLE_CONTROLLED);
+        } else {
+            /* Generate 487 response */
+            pj_stun_session_respond(sess, rdata, PJ_STUN_SC_ROLE_CONFLICT, 
+                                    NULL, token, PJ_TRUE, 
+                                    src_addr, src_addr_len);
+            pj_grp_lock_release(ice->grp_lock);
+            return PJ_SUCCESS;
+        }
 
     } else if (ice->role == PJ_ICE_SESS_ROLE_CONTROLLED &&
-	       role_attr && role_attr->hdr.type == PJ_STUN_ATTR_ICE_CONTROLLED)
+               role_attr && role_attr->hdr.type == PJ_STUN_ATTR_ICE_CONTROLLED)
     {
-	if (pj_cmp_timestamp(&ice->tie_breaker, &role_attr->value) < 0) {
-	    /* Generate 487 response */
-	    pj_stun_session_respond(sess, rdata, PJ_STUN_SC_ROLE_CONFLICT, 
-				    NULL, token, PJ_TRUE, 
-				    src_addr, src_addr_len);
-	    pj_grp_lock_release(ice->grp_lock);
-	    return PJ_SUCCESS;
-	} else {
-	    /* Switch role to controlled */
-	    LOG4((ice->obj_name, 
-		  "Changing role because of ICE-CONTROLLED attribute"));
-	    pj_ice_sess_change_role(ice, PJ_ICE_SESS_ROLE_CONTROLLING);
-	}
+        if (pj_cmp_timestamp(&ice->tie_breaker, &role_attr->value) < 0) {
+            /* Generate 487 response */
+            pj_stun_session_respond(sess, rdata, PJ_STUN_SC_ROLE_CONFLICT, 
+                                    NULL, token, PJ_TRUE, 
+                                    src_addr, src_addr_len);
+            pj_grp_lock_release(ice->grp_lock);
+            return PJ_SUCCESS;
+        } else {
+            /* Switch role to controlled */
+            LOG4((ice->obj_name, 
+                  "Changing role because of ICE-CONTROLLED attribute"));
+            pj_ice_sess_change_role(ice, PJ_ICE_SESS_ROLE_CONTROLLING);
+        }
     }
 
     /* 
@@ -2615,8 +3018,8 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
      */
     status = pj_stun_session_create_res(sess, rdata, 0, NULL, &tdata);
     if (status != PJ_SUCCESS) {
-	pj_grp_lock_release(ice->grp_lock);
-	return status;
+        pj_grp_lock_release(ice->grp_lock);
+        return status;
     }
 
     if (((pj_sockaddr *)src_addr)->addr.sa_family == pj_AF_INET6()) {
@@ -2624,38 +3027,38 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
         unsigned transport_id = ((pj_ice_msg_data*)token)->transport_id;
         pj_ice_sess_cand *lcand = NULL;
 
-    	for (i = 0; i < ice->clist.count; ++i) {
-	    pj_ice_sess_check *c = &ice->clist.checks[i];
-	    if (c->lcand->comp_id == sd->comp_id &&
-	        c->lcand->transport_id == transport_id) 
-	    {
-	    	lcand = c->lcand;
-	    	break;
-	    }
-    	}
+        for (i = 0; i < ice->clist.count; ++i) {
+            pj_ice_sess_check *c = &ice->clist.checks[i];
+            if (c->lcand->comp_id == sd->comp_id &&
+                c->lcand->transport_id == transport_id) 
+            {
+                lcand = c->lcand;
+                break;
+            }
+        }
 
-	if (lcand != NULL && lcand->addr.addr.sa_family == pj_AF_INET()) {
-	    /* We are behind NAT64, so src_addr is a synthesized IPv6
-	     * address. Instead of putting this synth IPv6 address as
+        if (lcand != NULL && lcand->addr.addr.sa_family == pj_AF_INET()) {
+            /* We are behind NAT64, so src_addr is a synthesized IPv6
+             * address. Instead of putting this synth IPv6 address as
              * the XOR-MAPPED-ADDRESS, we need to find its original
              * IPv4 address.
              */
             for (i = 0; i < ice->rcand_cnt; ++i) {
-            	pj_sockaddr synth_addr;
-            
-            	if (ice->rcand[i].addr.addr.sa_family != pj_AF_INET())
+                pj_sockaddr synth_addr;
+
+                if (ice->rcand[i].addr.addr.sa_family != pj_AF_INET())
                     continue;
 
-            	status = pj_sockaddr_synthesize(pj_AF_INET6(), &synth_addr,
-            				    	&ice->rcand[i].addr);
-	    	if (status == PJ_SUCCESS &&
-	            pj_sockaddr_cmp(src_addr, &synth_addr) == 0)
-	    	{
-	            /* We find the original IPv4 address. */
-	            source_addr = &ice->rcand[i].addr;
-	            source_addr_len = pj_sockaddr_get_len(source_addr);
-	            break;
-	    	}
+                status = pj_sockaddr_synthesize(pj_AF_INET6(), &synth_addr,
+                                                &ice->rcand[i].addr);
+                if (status == PJ_SUCCESS &&
+                    pj_sockaddr_cmp(src_addr, &synth_addr) == 0)
+                {
+                    /* We find the original IPv4 address. */
+                    source_addr = &ice->rcand[i].addr;
+                    source_addr_len = pj_sockaddr_get_len(source_addr);
+                    break;
+                }
             }
         }
     }
@@ -2663,9 +3066,9 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
 
     /* Add XOR-MAPPED-ADDRESS attribute */
     status = pj_stun_msg_add_sockaddr_attr(tdata->pool, tdata->msg, 
-					   PJ_STUN_ATTR_XOR_MAPPED_ADDR,
-					   PJ_TRUE, source_addr,
-					   source_addr_len);
+                                           PJ_STUN_ATTR_XOR_MAPPED_ADDR,
+                                           PJ_TRUE, source_addr,
+                                           source_addr_len);
 
     /* Create a msg_data to be associated with this response */
     msg_data = PJ_POOL_ZALLOC_T(tdata->pool, pj_ice_msg_data);
@@ -2673,8 +3076,9 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
     msg_data->has_req_data = PJ_FALSE;
 
     /* Send the response */
-    status = pj_stun_session_send_msg(sess, msg_data, PJ_TRUE, PJ_TRUE,
-				      src_addr, src_addr_len, tdata);
+    status = pj_stun_session_send_msg(sess, msg_data, PJ_TRUE,
+                                      pj_stun_session_tp_type(sess) == PJ_STUN_TP_UDP,
+                                      src_addr, src_addr_len, tdata);
 
 
     /* 
@@ -2686,9 +3090,9 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
      * triggered check array to be acted upon later.
      */
     if (ice->rcand_cnt == 0) {
-	rcheck = PJ_POOL_ZALLOC_T(ice->pool, pj_ice_rx_check);
+        rcheck = PJ_POOL_ZALLOC_T(ice->pool, pj_ice_rx_check);
     } else {
-	rcheck = &tmp_rcheck;
+        rcheck = &tmp_rcheck;
     }
 
     /* Init rcheck */
@@ -2701,13 +3105,13 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
     rcheck->role_attr = role_attr;
 
     if (ice->rcand_cnt == 0) {
-	/* We don't have answer yet, so keep this request for later */
-	LOG4((ice->obj_name, "Received an early check for comp %d",
-	      rcheck->comp_id));
-	pj_list_push_back(&ice->early_check, rcheck);
+        /* We don't have answer yet, so keep this request for later */
+        LOG4((ice->obj_name, "Received an early check for comp %d",
+              rcheck->comp_id));
+        pj_list_push_back(&ice->early_check, rcheck);
     } else {
-	/* Handle this check */
-	handle_incoming_check(ice, rcheck);
+        /* Handle this check */
+        handle_incoming_check(ice, rcheck);
     }
 
     pj_grp_lock_release(ice->grp_lock);
@@ -2720,7 +3124,7 @@ static pj_status_t on_stun_rx_request(pj_stun_session *sess,
  * SDP answer is received and we have received early checks.
  */
 static void handle_incoming_check(pj_ice_sess *ice,
-				  const pj_ice_rx_check *rcheck)
+                                  const pj_ice_rx_check *rcheck)
 {
     pj_ice_sess_comp *comp;
     pj_ice_sess_cand *lcand = NULL;
@@ -2733,8 +3137,8 @@ static void handle_incoming_check(pj_ice_sess *ice,
      * the request.
      */
     for (i=0; i<ice->rcand_cnt; ++i) {
-	if (pj_sockaddr_cmp(&rcheck->src_addr, &ice->rcand[i].addr)==0)
-	    break;
+        if (pj_sockaddr_cmp(&rcheck->src_addr, &ice->rcand[i].addr)==0)
+            break;
     }
 
     /* 7.2.1.3.  Learning Peer Reflexive Candidates
@@ -2743,35 +3147,35 @@ static void handle_incoming_check(pj_ice_sess *ice,
      * candidate.
      */
     if (i == ice->rcand_cnt) {
-	char raddr[PJ_INET6_ADDRSTRLEN];
-	void *p;
+        char raddr[PJ_INET6_ADDRSTRLEN];
+        void *p;
 
-	if (ice->rcand_cnt >= PJ_ICE_MAX_CAND) {
-	    LOG4((ice->obj_name, 
-	          "Unable to add new peer reflexive candidate: too many "
-		  "candidates already (%d)", PJ_ICE_MAX_CAND));
-	    return;
-	}
+        if (ice->rcand_cnt >= PJ_ICE_MAX_CAND) {
+            LOG4((ice->obj_name, 
+                  "Unable to add new peer reflexive candidate: too many "
+                  "candidates already (%d)", PJ_ICE_MAX_CAND));
+            return;
+        }
 
-	rcand = &ice->rcand[ice->rcand_cnt++];
-	rcand->comp_id = (pj_uint8_t)rcheck->comp_id;
-	rcand->type = PJ_ICE_CAND_TYPE_PRFLX;
-	rcand->prio = rcheck->priority;
-	pj_sockaddr_cp(&rcand->addr, &rcheck->src_addr);
+        rcand = &ice->rcand[ice->rcand_cnt++];
+        rcand->comp_id = (pj_uint8_t)rcheck->comp_id;
+        rcand->type = PJ_ICE_CAND_TYPE_PRFLX;
+        rcand->prio = rcheck->priority;
+        pj_sockaddr_cp(&rcand->addr, &rcheck->src_addr);
 
-	/* Foundation is random, unique from other foundation */
-	rcand->foundation.ptr = p = (char*) pj_pool_alloc(ice->pool, 36);
-	rcand->foundation.slen = pj_ansi_snprintf(rcand->foundation.ptr, 36,
-						  "f%p", p);
+        /* Foundation is random, unique from other foundation */
+        rcand->foundation.ptr = p = (char*) pj_pool_alloc(ice->pool, 36);
+        rcand->foundation.slen = pj_ansi_snprintf(rcand->foundation.ptr, 36,
+                                                  "f%p", p);
 
-	LOG4((ice->obj_name, 
-	      "Added new remote candidate from the request: %s:%d",
-	      pj_sockaddr_print(&rcand->addr, raddr, sizeof(raddr), 2),
-	      pj_sockaddr_get_port(&rcand->addr)));
+        LOG4((ice->obj_name, 
+              "Added new remote candidate from the request: %s:%d",
+              pj_sockaddr_print(&rcand->addr, raddr, sizeof(raddr), 2),
+              pj_sockaddr_get_port(&rcand->addr)));
 
     } else {
-	/* Remote candidate found */
-	rcand = &ice->rcand[i];
+        /* Remote candidate found */
+        rcand = &ice->rcand[i];
     }
 
 #if 0
@@ -2782,34 +3186,34 @@ static void handle_incoming_check(pj_ice_sess *ice,
      * and we will end up creating a new check unnecessarily.
      */
     for (i=0; i<ice->clist.count; ++i) {
-	pj_ice_sess_check *c = &ice->clist.checks[i];
-	if (/*c->lcand == lcand ||*/
-	    pj_sockaddr_cmp(&c->lcand->base_addr, &lcand->base_addr)==0)
-	{
-	    lcand = c->lcand;
-	    break;
-	}
+        pj_ice_sess_check *c = &ice->clist.checks[i];
+        if (/*c->lcand == lcand ||*/
+            pj_sockaddr_cmp(&c->lcand->base_addr, &lcand->base_addr)==0)
+        {
+            lcand = c->lcand;
+            break;
+        }
     }
 #else
     /* Just get candidate with the highest priority and same transport ID
      * for the specified  component ID in the checklist.
      */
-    for (i=0; i<ice->clist.count; ++i) {
-	pj_ice_sess_check *c = &ice->clist.checks[i];
-	if (c->lcand->comp_id == rcheck->comp_id &&
-	    c->lcand->transport_id == rcheck->transport_id) 
-	{
-	    lcand = c->lcand;
-	    break;
-	}
+    for (i=0; i<ice->lcand_cnt; ++i) {
+        pj_ice_sess_cand* lcand_tmp = &ice->lcand[i];
+        if (lcand_tmp->comp_id      == rcheck->comp_id &&
+            lcand_tmp->transport_id == rcheck->transport_id)
+        {
+            lcand = lcand_tmp;
+            break;
+        }
     }
     if (lcand == NULL) {
-	/* Should not happen, but just in case remote is sending a
-	 * Binding request for a component which it doesn't have.
-	 */
-	LOG4((ice->obj_name, 
-	     "Received Binding request but no local candidate is found!"));
-	return;
+        /* Should not happen, but just in case remote is sending a
+         * Binding request for a component which it doesn't have.
+         */
+        LOG4((ice->obj_name, 
+              "Received Binding request but no local candidate is found!"));
+        return;
     }
 #endif
 
@@ -2824,9 +3228,9 @@ static void handle_incoming_check(pj_ice_sess *ice,
      * have this pair in our checklist.
      */
     for (i=0; i<ice->clist.count; ++i) {
-	pj_ice_sess_check *c = &ice->clist.checks[i];
-	if (c->lcand == lcand && c->rcand == rcand)
-	    break;
+        pj_ice_sess_check *c = &ice->clist.checks[i];
+        if (c->lcand == lcand && c->rcand == rcand)
+            break;
     }
 
     /* If the pair is already on the check list:
@@ -2843,72 +3247,72 @@ static void handle_incoming_check(pj_ice_sess *ice,
      *   check is sent.
      */
     if (i != ice->clist.count) {
-	pj_ice_sess_check *c = &ice->clist.checks[i];
+        pj_ice_sess_check *c = &ice->clist.checks[i];
 
-	/* If USE-CANDIDATE is present, set nominated flag 
-	 * Note: DO NOT overwrite nominated flag if one is already set.
-	 */
-	c->nominated = ((rcheck->use_candidate) || c->nominated);
+        /* If USE-CANDIDATE is present, set nominated flag 
+         * Note: DO NOT overwrite nominated flag if one is already set.
+         */
+        c->nominated = ((rcheck->use_candidate) || c->nominated);
 
-	if (c->state == PJ_ICE_SESS_CHECK_STATE_FROZEN ||
-	    c->state == PJ_ICE_SESS_CHECK_STATE_WAITING)
-	{
-	    /* See if we shall nominate this check */
-	    pj_bool_t nominate = (c->nominated || ice->is_nominating);
+        if (c->state == PJ_ICE_SESS_CHECK_STATE_FROZEN ||
+            c->state == PJ_ICE_SESS_CHECK_STATE_WAITING)
+        {
+            /* See if we shall nominate this check */
+            pj_bool_t nominate = (c->nominated || ice->is_nominating);
 
-	    LOG5((ice->obj_name, "Performing triggered check for check %d",i));
-	    pj_log_push_indent();
-	    perform_check(ice, &ice->clist, i, nominate);
-	    pj_log_pop_indent();
+            LOG5((ice->obj_name, "Performing triggered check for check %d",i));
+            pj_log_push_indent();
+            perform_check(ice, &ice->clist, i, nominate);
+            pj_log_pop_indent();
 
-	} else if (c->state == PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS) {
-	    /* Should retransmit immediately
-	     */
-	    LOG5((ice->obj_name, "Triggered check for check %d not performed "
-		  "because it's in progress. Retransmitting", i));
-	    pj_log_push_indent();
-	    pj_stun_session_retransmit_req(comp->stun_sess, c->tdata, PJ_FALSE);
-	    pj_log_pop_indent();
+        } else if (c->state == PJ_ICE_SESS_CHECK_STATE_IN_PROGRESS) {
+            /* Should retransmit immediately
+            */
+            LOG5((ice->obj_name, "Triggered check for check %d not performed "
+                  "because it's in progress. Retransmitting", i));
+            pj_log_push_indent();
+            pj_stun_session_retransmit_req(comp->stun_sess, c->tdata, PJ_FALSE);
+            pj_log_pop_indent();
 
-	} else if (c->state == PJ_ICE_SESS_CHECK_STATE_SUCCEEDED) {
-	    /* Check complete for this component.
-	     * Note this may end ICE process.
-	     */
-	    pj_bool_t complete;
-	    unsigned j;
+        } else if (c->state == PJ_ICE_SESS_CHECK_STATE_SUCCEEDED) {
+            /* Check complete for this component.
+             * Note this may end ICE process.
+             */
+            pj_bool_t complete;
+            unsigned j;
 
-	    /* If this check is nominated, scan the valid_list for the
-	     * same check and update the nominated flag. A controlled 
-	     * agent might have finished the check earlier.
-	     */
-	    if (rcheck->use_candidate) {
-		for (j=0; j<ice->valid_list.count; ++j) {
-		    pj_ice_sess_check *vc = &ice->valid_list.checks[j];
-		    if (vc->lcand->transport_id == c->lcand->transport_id && 
-			vc->rcand == c->rcand) 
-		    {
-			/* Set nominated flag */
-			vc->nominated = PJ_TRUE;
+            /* If this check is nominated, scan the valid_list for the
+             * same check and update the nominated flag. A controlled 
+             * agent might have finished the check earlier.
+             */
+            if (rcheck->use_candidate) {
+                for (j=0; j<ice->valid_list.count; ++j) {
+                    pj_ice_sess_check *vc = &ice->valid_list.checks[j];
+                    if (vc->lcand->transport_id == c->lcand->transport_id && 
+                        vc->rcand == c->rcand) 
+                    {
+                        /* Set nominated flag */
+                        vc->nominated = PJ_TRUE;
 
-			/* Update valid check and nominated check for the component */
-			update_comp_check(ice, vc->lcand->comp_id, vc);
+                        /* Update valid check and nominated check for the component */
+                        update_comp_check(ice, vc->lcand->comp_id, vc);
 
-			LOG5((ice->obj_name, "Valid check %s is nominated", 
-			      dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
-					 &ice->valid_list, vc)));
-		    }
-		}
-	    }
+                        LOG5((ice->obj_name, "Valid check %s is nominated", 
+                              dump_check(ice->tmp.txt, sizeof(ice->tmp.txt), 
+                                         &ice->valid_list, vc)));
+                    }
+                }
+            }
 
-	    LOG5((ice->obj_name, "Triggered check for check %d not performed "
-				"because it's completed", i));
-	    pj_log_push_indent();
-	    complete = on_check_complete(ice, c);
-	    pj_log_pop_indent();
-	    if (complete) {
-		return;
-	    }
-	}
+            LOG5((ice->obj_name, "Triggered check for check %d not performed "
+                  "because it's completed", i));
+            pj_log_push_indent();
+            complete = on_check_complete(ice, c);
+            pj_log_pop_indent();
+            if (complete) {
+                return;
+            }
+        }
 
     }
     /* If the pair is not already on the check list:
@@ -2919,38 +3323,38 @@ static void handle_incoming_check(pj_ice_sess *ice,
     /* Note: only do this if we don't have too many checks in checklist */
     else if (ice->clist.count < PJ_ICE_MAX_CHECKS) {
 
-	pj_ice_sess_check *c = &ice->clist.checks[ice->clist.count];
-	pj_bool_t nominate;
+        pj_ice_sess_check *c = &ice->clist.checks[ice->clist.count];
+        pj_bool_t nominate;
 
-	c->lcand = lcand;
-	c->rcand = rcand;
-	c->prio = CALC_CHECK_PRIO(ice, lcand, rcand);
-	c->state = PJ_ICE_SESS_CHECK_STATE_WAITING;
-	c->nominated = rcheck->use_candidate;
-	c->err_code = PJ_SUCCESS;
+        c->lcand = lcand;
+        c->rcand = rcand;
+        c->prio = CALC_CHECK_PRIO(ice, lcand, rcand);
+        c->state = PJ_ICE_SESS_CHECK_STATE_WAITING;
+        c->nominated = rcheck->use_candidate;
+        c->err_code = PJ_SUCCESS;
 
-	nominate = (c->nominated || ice->is_nominating);
+        nominate = (c->nominated || ice->is_nominating);
 
-	LOG4((ice->obj_name, "New triggered check added: %d", 
-	     ice->clist.count));
-	pj_log_push_indent();
-	perform_check(ice, &ice->clist, ice->clist.count++, nominate);
-	pj_log_pop_indent();
+        LOG4((ice->obj_name, "New triggered check added: %d", 
+              ice->clist.count));
+        pj_log_push_indent();
+        perform_check(ice, &ice->clist, ice->clist.count++, nominate);
+        pj_log_pop_indent();
 
     } else {
-	LOG4((ice->obj_name, "Error: unable to perform triggered check: "
-	     "TOO MANY CHECKS IN CHECKLIST!"));
+        LOG4((ice->obj_name, "Error: unable to perform triggered check: "
+              "TOO MANY CHECKS IN CHECKLIST!"));
     }
 }
 
 
 static pj_status_t on_stun_rx_indication(pj_stun_session *sess,
-					 const pj_uint8_t *pkt,
-					 unsigned pkt_len,
-					 const pj_stun_msg *msg,
-					 void *token,
-					 const pj_sockaddr_t *src_addr,
-					 unsigned src_addr_len)
+                                         const pj_uint8_t *pkt,
+                                         unsigned pkt_len,
+                                         const pj_stun_msg *msg,
+                                         void *token,
+                                         const pj_sockaddr_t *src_addr,
+                                         unsigned src_addr_len)
 {
     struct stun_data *sd;
 
@@ -2967,12 +3371,12 @@ static pj_status_t on_stun_rx_indication(pj_stun_session *sess,
     pj_log_push_indent();
 
     if (msg->hdr.type == PJ_STUN_BINDING_INDICATION) {
-	LOG5((sd->ice->obj_name, "Received Binding Indication keep-alive "
-	      "for component %d", sd->comp_id));
+        LOG5((sd->ice->obj_name, "Received Binding Indication keep-alive "
+              "for component %d", sd->comp_id));
     } else {
-	LOG4((sd->ice->obj_name, "Received unexpected %s indication "
-	      "for component %d", pj_stun_get_method_name(msg->hdr.type), 
-	      sd->comp_id));
+        LOG4((sd->ice->obj_name, "Received unexpected %s indication "
+              "for component %d", pj_stun_get_method_name(msg->hdr.type), 
+              sd->comp_id));
     }
 
     pj_log_pop_indent();
@@ -2982,9 +3386,9 @@ static pj_status_t on_stun_rx_indication(pj_stun_session *sess,
 
 
 PJ_DEF(pj_status_t) pj_ice_sess_send_data(pj_ice_sess *ice,
-					  unsigned comp_id,
-					  const void *data,
-					  pj_size_t data_len)
+                                          unsigned comp_id,
+                                          const void *data,
+                                          pj_size_t data_len)
 {
     pj_status_t status = PJ_SUCCESS;
     pj_ice_sess_comp *comp;
@@ -2993,32 +3397,32 @@ PJ_DEF(pj_status_t) pj_ice_sess_send_data(pj_ice_sess *ice,
     pj_sockaddr addr;
 
     PJ_ASSERT_RETURN(ice && comp_id, PJ_EINVAL);
-    
+
     /* It is possible that comp_cnt is less than comp_id, when remote
      * doesn't support all the components that we have.
      */
     if (comp_id > ice->comp_cnt) {
-	return PJNATH_EICEINCOMPID;
+        return PJNATH_EICEINCOMPID;
     }
 
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_EINVALIDOP;
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_EINVALIDOP;
     }
 
     comp = find_comp(ice, comp_id);
     if (comp == NULL) {
-	status = PJNATH_EICEINCOMPID;
-	pj_grp_lock_release(ice->grp_lock);
-	goto on_return;
+        status = PJNATH_EICEINCOMPID;
+        pj_grp_lock_release(ice->grp_lock);
+        goto on_return;
     }
 
     if (comp->valid_check == NULL) {
-	status = PJNATH_EICEINPROGRESS;
-	pj_grp_lock_release(ice->grp_lock);
-	goto on_return;
+        status = PJNATH_EICEINPROGRESS;
+        pj_grp_lock_release(ice->grp_lock);
+        goto on_return;
     }
 
     cand = comp->valid_check->lcand;
@@ -3031,9 +3435,9 @@ PJ_DEF(pj_status_t) pj_ice_sess_send_data(pj_ice_sess *ice,
     PJ_RACE_ME(5);
 
     status = (*ice->cb.on_tx_pkt)(ice, comp_id, transport_id, 
-				  data, data_len, 
-				  &addr, 
-				  pj_sockaddr_get_len(&addr));
+                                  data, data_len, 
+                                  &addr, 
+                                  pj_sockaddr_get_len(&addr));
 
 on_return:
     return status;
@@ -3041,12 +3445,12 @@ on_return:
 
 
 PJ_DEF(pj_status_t) pj_ice_sess_on_rx_pkt(pj_ice_sess *ice,
-					  unsigned comp_id,
-					  unsigned transport_id,
-					  void *pkt,
-					  pj_size_t pkt_size,
-					  const pj_sockaddr_t *src_addr,
-					  int src_addr_len)
+                                          unsigned comp_id,
+                                          unsigned transport_id,
+                                          void *pkt,
+                                          pj_size_t pkt_size,
+                                          const pj_sockaddr_t *src_addr,
+                                          int src_addr_len)
 {
     pj_status_t status = PJ_SUCCESS;
     pj_ice_sess_comp *comp;
@@ -3058,27 +3462,27 @@ PJ_DEF(pj_status_t) pj_ice_sess_on_rx_pkt(pj_ice_sess *ice,
     pj_grp_lock_acquire(ice->grp_lock);
 
     if (ice->is_destroying) {
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_EINVALIDOP;
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_EINVALIDOP;
     }
 
     comp = find_comp(ice, comp_id);
     if (comp == NULL) {
-	pj_grp_lock_release(ice->grp_lock);
-	return PJNATH_EICEINCOMPID;
+        pj_grp_lock_release(ice->grp_lock);
+        return PJNATH_EICEINCOMPID;
     }
 
     /* Find transport */
     for (i=0; i<PJ_ARRAY_SIZE(ice->tp_data); ++i) {
-	if (ice->tp_data[i].transport_id == transport_id) {
-	    msg_data = &ice->tp_data[i];
-	    break;
-	}
+        if (ice->tp_data[i].transport_id == transport_id) {
+            msg_data = &ice->tp_data[i];
+            break;
+        }
     }
     if (msg_data == NULL) {
-	pj_assert(!"Invalid transport ID");
-	pj_grp_lock_release(ice->grp_lock);
-	return PJ_EINVAL;
+        pj_assert(!"Invalid transport ID");
+        pj_grp_lock_release(ice->grp_lock);
+        return PJ_EINVAL;
     }
 
     /* Don't check fingerprint. We only need to distinguish STUN and non-STUN
@@ -3086,29 +3490,29 @@ PJ_DEF(pj_status_t) pj_ice_sess_on_rx_pkt(pj_ice_sess *ice,
      * will be done by the user.
      */
     status = pj_stun_msg_check((const pj_uint8_t*)pkt, pkt_size, 
-    			       PJ_STUN_IS_DATAGRAM |
-    			         PJ_STUN_NO_FINGERPRINT_CHECK);
+                               PJ_STUN_IS_DATAGRAM |
+                               PJ_STUN_NO_FINGERPRINT_CHECK);
     if (status == PJ_SUCCESS) {
-	status = pj_stun_session_on_rx_pkt(comp->stun_sess, pkt, pkt_size,
-					   PJ_STUN_IS_DATAGRAM, msg_data,
-					   NULL, src_addr, src_addr_len);
-	if (status != PJ_SUCCESS) {
-	    pj_strerror(status, ice->tmp.errmsg, sizeof(ice->tmp.errmsg));
-	    LOG4((ice->obj_name, "Error processing incoming message: %s",
-		  ice->tmp.errmsg));
-	}
-	pj_grp_lock_release(ice->grp_lock);
+        status = pj_stun_session_on_rx_pkt(comp->stun_sess, pkt, pkt_size,
+                                           PJ_STUN_IS_DATAGRAM, msg_data,
+                                           NULL, src_addr, src_addr_len);
+        if (status != PJ_SUCCESS) {
+            pj_strerror(status, ice->tmp.errmsg, sizeof(ice->tmp.errmsg));
+            LOG4((ice->obj_name, "Error processing incoming message: %s",
+                  ice->tmp.errmsg));
+        }
+        pj_grp_lock_release(ice->grp_lock);
     } else {
-	/* Not a STUN packet. Call application's callback instead, but release
-	 * the mutex now or otherwise we may get deadlock.
-	 */
-	pj_grp_lock_release(ice->grp_lock);
+        /* Not a STUN packet. Call application's callback instead, but release
+         * the mutex now or otherwise we may get deadlock.
+         */
+        pj_grp_lock_release(ice->grp_lock);
 
-	PJ_RACE_ME(5);
+        PJ_RACE_ME(5);
 
-	(*ice->cb.on_rx_data)(ice, comp_id, transport_id, pkt, pkt_size, 
-			      src_addr, src_addr_len);
-	status = PJ_SUCCESS;
+        (*ice->cb.on_rx_data)(ice, comp_id, transport_id, pkt, pkt_size, 
+                              src_addr, src_addr_len);
+        status = PJ_SUCCESS;
     }
 
     return status;
diff --git a/pjnath/src/pjnath/ice_strans.c b/pjnath/src/pjnath/ice_strans.c
index 3cb350c2a..ef07be000 100644
--- a/pjnath/src/pjnath/ice_strans.c
+++ b/pjnath/src/pjnath/ice_strans.c
@@ -69,6 +69,7 @@ enum tp_type
 #   define RELAY_PREF  0
 #endif
 
+#define MAX_RTP_SIZE 65536
 
 /* The candidate type preference when STUN candidate is used */
 static pj_uint8_t srflx_pref_table[PJ_ICE_CAND_TYPE_MAX] =
@@ -87,6 +88,16 @@ static pj_uint8_t srflx_pref_table[PJ_ICE_CAND_TYPE_MAX] =
 #endif
 };
 
+//////////////////////////////////////////////////////////////////////////////
+
+static pj_uint16_t GETVAL16H(const pj_uint8_t *buf, unsigned pos)
+{
+    return (pj_uint16_t) ((buf[pos + 0] << 8) | \
+                          (buf[pos + 1] << 0));
+}
+
+//////////////////////////////////////////////////////////////////////////////
+
 
 /* ICE callbacks */
 static void	   on_ice_complete(pj_ice_sess *ice, pj_status_t status);
@@ -103,6 +114,23 @@ static void	   ice_rx_data(pj_ice_sess *ice,
 			       const pj_sockaddr_t *src_addr,
 			       unsigned src_addr_len);
 
+#if PJ_HAS_TCP
+static pj_status_t ice_wait_tcp_connection(pj_ice_sess *ice,
+                                           pj_ice_sess_checklist *clist,
+                                           unsigned check_id);
+
+static pj_status_t ice_select_turn_dataconn(pj_ice_sess *ice,
+                                            pj_ice_sess_checklist *clist,
+                                            unsigned check_id);
+
+static pj_status_t ice_reconnect_tcp_connection(pj_ice_sess *ice,
+                                                pj_ice_sess_checklist *clist,
+                                                unsigned check_id);
+
+static pj_status_t ice_close_tcp_connection(pj_ice_sess *ice,
+                                            pj_ice_sess_checklist *clist,
+                                            unsigned check_id);
+#endif
 
 /* STUN socket callbacks */
 /* Notification when incoming packet has been received. */
@@ -225,6 +253,12 @@ struct pj_ice_strans
     pj_bool_t		     destroy_req;/**< Destroy has been called?	*/
     pj_bool_t		     cb_called;	/**< Init error callback called?*/
     pj_bool_t		     call_send_cb;/**< Need to call send cb?	*/
+
+    pj_uint8_t          rtp_pkt[MAX_RTP_SIZE];
+    pj_uint8_t          rx_buffer[MAX_RTP_SIZE];
+    pj_uint16_t         rx_buffer_size;
+    pj_uint16_t         rx_wanted_size;
+
 };
 
 
@@ -261,6 +295,7 @@ PJ_DEF(void) pj_ice_strans_cfg_default(pj_ice_strans_cfg *cfg)
     pj_bzero(cfg, sizeof(*cfg));
 
     cfg->af = pj_AF_INET();
+    cfg->protocol = PJ_ICE_TP_UDP;
     pj_stun_config_init(&cfg->stun_cfg, NULL, 0, NULL, NULL);
     pj_ice_strans_stun_cfg_default(&cfg->stun);
     pj_ice_strans_turn_cfg_default(&cfg->turn);
@@ -278,6 +313,7 @@ PJ_DEF(void) pj_ice_strans_stun_cfg_default(pj_ice_strans_stun_cfg *cfg)
     pj_bzero(cfg, sizeof(*cfg));
 
     cfg->af = pj_AF_INET();
+    cfg->conn_type = PJ_TURN_TP_UDP;
     cfg->port = PJ_STUN_PORT;
     cfg->max_host_cands = 64;
     cfg->ignore_stun_error = PJ_FALSE;
@@ -414,13 +450,14 @@ static pj_status_t add_update_turn(pj_ice_strans *ice_st,
     if (cand == NULL) {
 	PJ_ASSERT_RETURN(max_cand_cnt > 0, PJ_ETOOSMALL);
 
-	cand = &comp->cand_list[comp->cand_cnt];
-	cand->type = PJ_ICE_CAND_TYPE_RELAYED;
-	cand->status = PJ_EPENDING;
-	cand->local_pref = RELAY_PREF;
-	cand->transport_id = tp_id;
-	cand->comp_id = (pj_uint8_t) comp->comp_id;
-	new_cand = PJ_TRUE;
+        cand = &comp->cand_list[comp->cand_cnt];
+        cand->type = PJ_ICE_CAND_TYPE_RELAYED;
+        cand->status = PJ_EPENDING;
+        cand->local_pref = RELAY_PREF;
+        cand->transport_id = tp_id;
+        cand->comp_id = (pj_uint8_t) comp->comp_id;
+        new_cand = PJ_TRUE;
+        cand->transport = turn_cfg->conn_type == PJ_TURN_TP_UDP ? PJ_CAND_UDP : PJ_CAND_TCP_PASSIVE;
     }
 
     /* Allocate and initialize TURN socket data */
@@ -428,6 +465,9 @@ static pj_status_t add_update_turn(pj_ice_strans *ice_st,
     data->comp = comp;
     data->transport_id = cand->transport_id;
 
+    if (turn_cfg->conn_type == PJ_TURN_TP_TCP)
+        turn_cfg->alloc_param.peer_conn_type = PJ_TURN_TP_TCP;
+
     /* Create the TURN transport */
     status = pj_turn_sock_create(&ice_st->cfg.stun_cfg, turn_cfg->af,
 				 turn_cfg->conn_type,
@@ -465,8 +505,8 @@ static pj_status_t add_update_turn(pj_ice_strans *ice_st,
     return PJ_SUCCESS;
 }
 
-static pj_bool_t ice_cand_equals(pj_ice_sess_cand *lcand, 
-		    	         pj_ice_sess_cand *rcand)
+static pj_bool_t ice_cand_equals(pj_ice_sess_cand *lcand,
+                                 pj_ice_sess_cand *rcand)
 {
     if (lcand == NULL && rcand == NULL){
         return PJ_TRUE;
@@ -474,267 +514,305 @@ static pj_bool_t ice_cand_equals(pj_ice_sess_cand *lcand,
     if (lcand == NULL || rcand == NULL){
         return PJ_FALSE;
     }
-    
+
     if (lcand->type != rcand->type
         || lcand->status != rcand->status
         || lcand->comp_id != rcand->comp_id
         || lcand->transport_id != rcand->transport_id
         || lcand->local_pref != rcand->local_pref
         || lcand->prio != rcand->prio
+        || lcand->transport != rcand->transport
         || pj_sockaddr_cmp(&lcand->addr, &rcand->addr) != 0
         || pj_sockaddr_cmp(&lcand->base_addr, &rcand->base_addr) != 0)
     {
         return PJ_FALSE;
     }
-    
+
+    return PJ_TRUE;
+}
+
+static pj_bool_t add_local_candidate(pj_ice_sess_cand *cand,
+                                     unsigned idx, unsigned i,
+                                     pj_stun_sock_info stun_sock_info,
+                                     pj_ice_strans *ice_st,
+                                     pj_ice_strans_comp *comp,
+                                     pj_ice_cand_transport transport)
+{
+    pj_ice_strans_stun_cfg *stun_cfg = &ice_st->cfg.stun_tp[idx];
+    unsigned j;
+    char addrinfo[PJ_INET6_ADDRSTRLEN+10];
+
+    pj_bool_t cand_duplicate = PJ_FALSE;
+    const pj_sockaddr *addr  = &stun_sock_info.aliases[i];
+
+    /* Leave one candidate for relay */
+    if (comp->cand_cnt >= PJ_ICE_ST_MAX_CAND-1) {
+        PJ_LOG(4,(ice_st->obj_name, "Too many host candidates"));
+        return PJ_FALSE;
+    }
+
+    /* Ignore loopback addresses if cfg->stun.loop_addr is unset */
+    if (stun_cfg->loop_addr == PJ_FALSE) {
+        if (stun_cfg->af == pj_AF_INET() &&
+            (pj_ntohl(addr->ipv4.sin_addr.s_addr)>>24)==127)
+        {
+            return PJ_TRUE;
+        }
+        else if (stun_cfg->af == pj_AF_INET6()) {
+            pj_in6_addr in6addr = {{0}};
+            in6addr.s6_addr[15] = 1;
+            if (pj_memcmp(&in6addr, &addr->ipv6.sin6_addr, sizeof(in6addr))==0)
+            {
+                return PJ_TRUE;
+            }
+        }
+    }
+    pj_sockaddr_print(addr, addrinfo, sizeof(addrinfo), 3);
+
+    /* Ignore IPv6 link-local address */
+    if (stun_cfg->af == pj_AF_INET6()) {
+        const pj_in6_addr *a = &addr->ipv6.sin6_addr;
+        if (a->s6_addr[0] == 0xFE && (a->s6_addr[1] & 0xC0) == 0x80)
+            return PJ_TRUE;
+    }
+
+    cand = &comp->cand_list[comp->cand_cnt];
+
+    cand->type         = PJ_ICE_CAND_TYPE_HOST;
+    cand->status       = PJ_SUCCESS;
+    cand->local_pref   = HOST_PREF;
+    cand->transport_id = CREATE_TP_ID(TP_STUN, idx);
+    cand->comp_id      = (pj_uint8_t) comp->comp_id;
+    cand->transport    = transport;
+
+    char addstr[PJ_INET6_ADDRSTRLEN+10];
+    pj_sockaddr_print(addr, addstr,
+                      sizeof(addstr), 3);
+    pj_sockaddr_cp(&cand->addr, addr);
+    pj_sockaddr_cp(&cand->base_addr, addr);
+    pj_bzero(&cand->rel_addr, sizeof(cand->rel_addr));
+
+    /* Check if not already in list */
+    for (j=0; j<comp->cand_cnt; j++) {
+        if (ice_cand_equals(cand, &comp->cand_list[j])) {
+            cand_duplicate = PJ_TRUE;
+            return PJ_FALSE;
+        }
+    }
+
+    if (cand_duplicate) {
+        PJ_LOG(4, (ice_st->obj_name,
+                   "Comp %d: host candidate %s (tpid=%d) is a duplicate",
+                   comp->comp_id,
+                   pj_sockaddr_print(&cand->addr, addrinfo, sizeof(addrinfo), 3),
+                   cand->transport_id));
+
+        pj_bzero(&cand->addr, sizeof(cand->addr));
+        pj_bzero(&cand->base_addr, sizeof(cand->base_addr));
+        return PJ_TRUE;
+    } else {
+        comp->cand_cnt+=1;
+    }
+
+    pj_ice_calc_foundation(ice_st->pool, &cand->foundation,
+                           cand->type, &cand->base_addr);
+
+    /* Set default candidate with the preferred default
+     * address family
+     */
+    if (comp->ice_st->cfg.af != pj_AF_UNSPEC() &&
+        addr->addr.sa_family == comp->ice_st->cfg.af &&
+        comp->cand_list[comp->default_cand].base_addr.addr.sa_family !=
+        ice_st->cfg.af)
+    {
+        comp->default_cand = (unsigned)(cand - comp->cand_list);
+    }
+
+    if (transport == PJ_CAND_TCP_ACTIVE) {
+        // Use the port 9 (DISCARD Protocol) for TCP active candidates.
+        pj_sockaddr_set_port(&cand->addr, 9);
+    }
+
+    PJ_LOG(4,(ice_st->obj_name,
+              "Comp %d/%d: host candidate %s (tpid=%d) added",
+              comp->comp_id, comp->cand_cnt-1,
+              pj_sockaddr_print(&cand->addr, addrinfo,
+                                sizeof(addrinfo), 3),
+              cand->transport_id));
     return PJ_TRUE;
 }
 
 
 static pj_status_t add_stun_and_host(pj_ice_strans *ice_st,
-				     pj_ice_strans_comp *comp,
-				     unsigned idx,
-				     unsigned max_cand_cnt)
+                                     pj_ice_strans_comp *comp,
+                                     unsigned idx,
+                                     unsigned max_cand_cnt)
 {
     pj_ice_sess_cand *cand;
+    pj_stun_sock_cb  stun_sock_cb;
+    sock_user_data   *data;
+    pj_status_t      status;
+
     pj_ice_strans_stun_cfg *stun_cfg = &ice_st->cfg.stun_tp[idx];
-    pj_stun_sock_cfg *sock_cfg  = &stun_cfg->cfg;
-    unsigned comp_idx = comp->comp_id - 1;
-    pj_stun_sock_cb stun_sock_cb;
-    sock_user_data *data;
-    pj_status_t status;
+    pj_stun_sock_cfg *sock_cfg       = &stun_cfg->cfg;
+    unsigned comp_idx                = comp->comp_id - 1;
 
     PJ_ASSERT_RETURN(max_cand_cnt > 0, PJ_ETOOSMALL);
 
     /* Check if STUN transport or host candidate is configured */
     if (stun_cfg->server.slen == 0 && stun_cfg->max_host_cands == 0)
-	return PJ_SUCCESS;
+        return PJ_SUCCESS;
 
     /* Initialize STUN socket callback */
     pj_bzero(&stun_sock_cb, sizeof(stun_sock_cb));
-    stun_sock_cb.on_rx_data = &stun_on_rx_data;
-    stun_sock_cb.on_status = &stun_on_status;
+    stun_sock_cb.on_rx_data   = &stun_on_rx_data;
+    stun_sock_cb.on_status    = &stun_on_status;
     stun_sock_cb.on_data_sent = &stun_on_data_sent;
 
     /* Override component specific QoS settings, if any */
     if (ice_st->cfg.comp[comp_idx].qos_type) {
-	sock_cfg->qos_type = ice_st->cfg.comp[comp_idx].qos_type;
+        sock_cfg->qos_type = ice_st->cfg.comp[comp_idx].qos_type;
     }
     if (ice_st->cfg.comp[comp_idx].qos_params.flags) {
-	pj_memcpy(&sock_cfg->qos_params,
-		  &ice_st->cfg.comp[comp_idx].qos_params,
-		  sizeof(sock_cfg->qos_params));
+        pj_memcpy(&sock_cfg->qos_params,
+                  &ice_st->cfg.comp[comp_idx].qos_params,
+                  sizeof(sock_cfg->qos_params));
     }
 
     /* Override component specific socket buffer size settings, if any */
-    if (ice_st->cfg.comp[comp_idx].so_rcvbuf_size > 0) {
-	sock_cfg->so_rcvbuf_size = ice_st->cfg.comp[comp_idx].so_rcvbuf_size;
-    }
-    if (ice_st->cfg.comp[comp_idx].so_sndbuf_size > 0) {
-	sock_cfg->so_sndbuf_size = ice_st->cfg.comp[comp_idx].so_sndbuf_size;
-    }
+    if (ice_st->cfg.comp[comp_idx].so_rcvbuf_size > 0)
+        sock_cfg->so_rcvbuf_size = ice_st->cfg.comp[comp_idx].so_rcvbuf_size;
+    if (ice_st->cfg.comp[comp_idx].so_sndbuf_size > 0)
+        sock_cfg->so_sndbuf_size = ice_st->cfg.comp[comp_idx].so_sndbuf_size;
 
     /* Prepare srflx candidate with pending status. */
-    cand = &comp->cand_list[comp->cand_cnt];
-    cand->type = PJ_ICE_CAND_TYPE_SRFLX;
-    cand->status = PJ_EPENDING;
-    cand->local_pref = SRFLX_PREF;
-    cand->transport_id = CREATE_TP_ID(TP_STUN, idx);
-    cand->comp_id = (pj_uint8_t) comp->comp_id;
+    cand                = &comp->cand_list[comp->cand_cnt];
+    cand->type          = PJ_ICE_CAND_TYPE_SRFLX;
+    cand->status        = PJ_EPENDING;
+    cand->local_pref    = SRFLX_PREF;
+    cand->transport_id  = CREATE_TP_ID(TP_STUN, idx);
+    cand->comp_id       = (pj_uint8_t) comp->comp_id;
+    cand->transport     = stun_cfg->conn_type == \
+                          PJ_STUN_TP_UDP ? PJ_CAND_UDP : PJ_CAND_TCP_PASSIVE;
 
     /* Allocate and initialize STUN socket data */
-    data = PJ_POOL_ZALLOC_T(ice_st->pool, sock_user_data);
-    data->comp = comp;
+    data               = PJ_POOL_ZALLOC_T(ice_st->pool, sock_user_data);
+    data->comp         = comp;
     data->transport_id = cand->transport_id;
 
     /* Create the STUN transport */
     status = pj_stun_sock_create(&ice_st->cfg.stun_cfg, NULL,
-				 stun_cfg->af, &stun_sock_cb,
-				 sock_cfg, data, &comp->stun[idx].sock);
+                                 stun_cfg->af, stun_cfg->conn_type,
+                                 &stun_sock_cb, sock_cfg, data,
+                                 &comp->stun[idx].sock);
     if (status != PJ_SUCCESS)
-	return status;
+        return status;
 
     /* Start STUN Binding resolution and add srflx candidate only if server
      * is set. When any error occur during STUN Binding resolution, let's
      * just skip it and generate host candidates.
      */
     while (stun_cfg->server.slen) {
-	pj_stun_sock_info stun_sock_info;
-
-	/* Add pending job */
-	///sess_add_ref(ice_st);
-
-	PJ_LOG(4,(ice_st->obj_name,
-		  "Comp %d: srflx candidate (tpid=%d) starts "
-		  "Binding discovery",
-		  comp->comp_id, cand->transport_id));
-
-	pj_log_push_indent();
-
-	/* Start Binding resolution */
-	status = pj_stun_sock_start(comp->stun[idx].sock, &stun_cfg->server,
-				    stun_cfg->port, ice_st->cfg.resolver);
-	if (status != PJ_SUCCESS) {
-	    ///sess_dec_ref(ice_st);
-	    PJ_PERROR(5,(ice_st->obj_name, status,
-			 "Comp %d: srflx candidate (tpid=%d) failed in "
-			 "pj_stun_sock_start()",
-			 comp->comp_id, cand->transport_id));
-	    pj_log_pop_indent();
-	    break;
-	}
-
-	/* Enumerate addresses */
-	status = pj_stun_sock_get_info(comp->stun[idx].sock, &stun_sock_info);
-	if (status != PJ_SUCCESS) {
-	    ///sess_dec_ref(ice_st);
-	    PJ_PERROR(5,(ice_st->obj_name, status,
-			 "Comp %d: srflx candidate (tpid=%d) failed in "
-			 "pj_stun_sock_get_info()",
-			 comp->comp_id, cand->transport_id));
-	    pj_log_pop_indent();
-	    break;
-	}
-
-	/* Update and commit the srflx candidate. */
-	pj_sockaddr_cp(&cand->base_addr, &stun_sock_info.aliases[0]);
-	pj_sockaddr_cp(&cand->rel_addr, &cand->base_addr);
-	pj_ice_calc_foundation(ice_st->pool, &cand->foundation,
-			       cand->type, &cand->base_addr);
-	comp->cand_cnt++;
-	max_cand_cnt--;
-
-	/* Set default candidate to srflx */
-	if (comp->cand_list[comp->default_cand].type != PJ_ICE_CAND_TYPE_SRFLX
-	    || (ice_st->cfg.af != pj_AF_UNSPEC() &&
-	        comp->cand_list[comp->default_cand].base_addr.addr.sa_family
-	        != ice_st->cfg.af))
-	{
-	    comp->default_cand = (unsigned)(cand - comp->cand_list);
-	}
-
-	pj_log_pop_indent();
-
-	/* Not really a loop, just trying to avoid complex 'if' blocks */
-	break;
+        pj_stun_sock_info stun_sock_info;
+
+        /* Add pending job */
+        ///sess_add_ref(ice_st);
+
+        PJ_LOG(4,(ice_st->obj_name,
+                  "Comp %d: srflx candidate (tpid=%d) starts "
+                  "Binding discovery",
+                  comp->comp_id, cand->transport_id));
+
+        pj_log_push_indent();
+
+        /* Start Binding resolution */
+        status = pj_stun_sock_start(comp->stun[idx].sock, &stun_cfg->server,
+                                    stun_cfg->port, ice_st->cfg.resolver);
+        if (status != PJ_SUCCESS) {
+            ///sess_dec_ref(ice_st);
+            PJ_PERROR(5,(ice_st->obj_name, status,
+                         "Comp %d: srflx candidate (tpid=%d) failed in "
+                         "pj_stun_sock_start()",
+                         comp->comp_id, cand->transport_id));
+            pj_log_pop_indent();
+            break;
+        }
+
+        /* Enumerate addresses */
+        status = pj_stun_sock_get_info(comp->stun[idx].sock, &stun_sock_info);
+        if (status != PJ_SUCCESS) {
+            ///sess_dec_ref(ice_st);
+            PJ_PERROR(5,(ice_st->obj_name, status,
+                         "Comp %d: srflx candidate (tpid=%d) failed in "
+                         "pj_stun_sock_get_info()",
+                         comp->comp_id, cand->transport_id));
+            pj_log_pop_indent();
+            break;
+        }
+
+        /* Update and commit the srflx candidate. */
+        pj_sockaddr_cp(&cand->base_addr, &stun_sock_info.aliases[0]);
+        pj_sockaddr_cp(&cand->rel_addr, &cand->base_addr);
+        pj_ice_calc_foundation(ice_st->pool, &cand->foundation,
+                               cand->type, &cand->base_addr);
+        comp->cand_cnt++;
+        max_cand_cnt--;
+
+        /* Set default candidate to srflx */
+        if (comp->cand_list[comp->default_cand].type != PJ_ICE_CAND_TYPE_SRFLX
+            || (ice_st->cfg.af != pj_AF_UNSPEC()
+                && comp->cand_list[comp->default_cand].base_addr.addr.sa_family != ice_st->cfg.af))
+        {
+            comp->default_cand = (unsigned)(cand - comp->cand_list);
+        }
+
+        pj_log_pop_indent();
+
+        /* Not really a loop, just trying to avoid complex 'if' blocks */
+        break;
     }
 
     /* Add local addresses to host candidates, unless max_host_cands
      * is set to zero.
      */
+
     if (stun_cfg->max_host_cands) {
-	pj_stun_sock_info stun_sock_info;
-	unsigned i, cand_cnt = 0;
-
-	/* Enumerate addresses */
-	status = pj_stun_sock_get_info(comp->stun[idx].sock, &stun_sock_info);
-	if (status != PJ_SUCCESS) {
-	    PJ_PERROR(4,(ice_st->obj_name, status,
-			 "Failed in querying STUN socket info"));
-	    return status;
-	}
-
-	for (i = 0; i < stun_sock_info.alias_cnt &&
-		    cand_cnt < stun_cfg->max_host_cands; ++i)
-	{
-	    unsigned j;
-	    pj_bool_t cand_duplicate = PJ_FALSE;
-	    char addrinfo[PJ_INET6_ADDRSTRLEN+10];
-	    const pj_sockaddr *addr = &stun_sock_info.aliases[i];
-
-	    if (max_cand_cnt==0) {
-		PJ_LOG(4,(ice_st->obj_name, "Too many host candidates"));
-		break;
-	    }
-
-	    /* Ignore loopback addresses if cfg->stun.loop_addr is unset */
-	    if (stun_cfg->loop_addr==PJ_FALSE) {
-		if (stun_cfg->af == pj_AF_INET() && 
-		    (pj_ntohl(addr->ipv4.sin_addr.s_addr)>>24)==127)
-		{
-		    continue;
-		}
-		else if (stun_cfg->af == pj_AF_INET6()) {
-		    pj_in6_addr in6addr = {{0}};
-		    in6addr.s6_addr[15] = 1;
-		    if (pj_memcmp(&in6addr, &addr->ipv6.sin6_addr,
-				  sizeof(in6addr))==0)
-		    {
-			continue;
-		    }
-		}
-	    }
-
-	    /* Ignore IPv6 link-local address, unless it is the default
-	     * address (first alias).
-	     */
-	    if (stun_cfg->af == pj_AF_INET6() && i != 0) {
-		const pj_in6_addr *a = &addr->ipv6.sin6_addr;
-		if (a->s6_addr[0] == 0xFE && (a->s6_addr[1] & 0xC0) == 0x80)
-		    continue;
-	    }
-
-	    cand = &comp->cand_list[comp->cand_cnt];
-
-	    cand->type = PJ_ICE_CAND_TYPE_HOST;
-	    cand->status = PJ_SUCCESS;
-	    cand->local_pref = HOST_PREF;
-	    cand->transport_id = CREATE_TP_ID(TP_STUN, idx);
-	    cand->comp_id = (pj_uint8_t) comp->comp_id;
-	    pj_sockaddr_cp(&cand->addr, addr);
-	    pj_sockaddr_cp(&cand->base_addr, addr);
-	    pj_bzero(&cand->rel_addr, sizeof(cand->rel_addr));
-            
-	    /* Check if not already in list */
-	    for (j=0; j<comp->cand_cnt; j++) {
-		if (ice_cand_equals(cand, &comp->cand_list[j])) {
-		    cand_duplicate = PJ_TRUE;
-		    break;
-		}
-	    }
-
-	    if (cand_duplicate) {
-		PJ_LOG(4, (ice_st->obj_name,
-		       "Comp %d: host candidate %s (tpid=%d) is a duplicate",
-		       comp->comp_id, pj_sockaddr_print(&cand->addr, addrinfo,
-		       sizeof(addrinfo), 3), cand->transport_id));
-
-		pj_bzero(&cand->addr, sizeof(cand->addr));
-		pj_bzero(&cand->base_addr, sizeof(cand->base_addr));
-		continue;
-	    } else {
-		comp->cand_cnt+=1;
-		cand_cnt++;
-		max_cand_cnt--;
-	    }
-            
-	    pj_ice_calc_foundation(ice_st->pool, &cand->foundation,
-				   cand->type, &cand->base_addr);
-
-	    /* Set default candidate with the preferred default
-	     * address family
-	     */
-	    if (comp->ice_st->cfg.af != pj_AF_UNSPEC() &&
-	        addr->addr.sa_family == comp->ice_st->cfg.af &&
-	        comp->cand_list[comp->default_cand].base_addr.addr.sa_family !=
-	        ice_st->cfg.af)
-	    {
-	        comp->default_cand = (unsigned)(cand - comp->cand_list);
-	    }
-
-	    PJ_LOG(4,(ice_st->obj_name,
-		      "Comp %d/%d: host candidate %s (tpid=%d) added",
-		      comp->comp_id, comp->cand_cnt-1, 
-		      pj_sockaddr_print(&cand->addr, addrinfo,
-					sizeof(addrinfo), 3),
-					cand->transport_id));
-	}
+        pj_stun_sock_info stun_sock_info;
+        unsigned i = 0;
+        pj_bool_t add_tcp_active_cand;
+        /* Enumerate addresses */
+        status = pj_stun_sock_get_info(comp->stun[idx].sock, &stun_sock_info);
+        if (status != PJ_SUCCESS) {
+            PJ_PERROR(4,(ice_st->obj_name, status,
+                         "Failed in querying STUN socket info"));
+            return status;
+        }
+
+        add_tcp_active_cand = stun_sock_info.conn_type != PJ_STUN_TP_UDP;
+        for (i=0; i<stun_sock_info.alias_cnt && i<stun_cfg->max_host_cands; ++i)
+            if (!add_tcp_active_cand) {
+                add_local_candidate(cand, idx, i, stun_sock_info,
+                                    ice_st, comp, PJ_CAND_UDP);
+            } else {
+                add_local_candidate(cand, idx, i, stun_sock_info,
+                                    ice_st, comp, PJ_CAND_TCP_PASSIVE);
+                /** RFC 6544, Section 4.1:
+                 * First, agents SHOULD obtain host candidates as described in
+                 * Section 5.1.  Then, each agent SHOULD "obtain" (allocate a
+                 * placeholder for) an active host candidate for each component of
+                 * each TCP-capable media stream on each interface that the host
+                 * has.  The agent does not yet have to actually allocate a port for
+                 * these candidates, but they are used for the creation of the check
+                 * lists.
+                 */
+                add_local_candidate(cand, idx, i, stun_sock_info,
+                                    ice_st, comp, PJ_CAND_TCP_ACTIVE);
+            }
     }
 
     return status;
 }
 
-
 /*
  * Create the component.
  */
@@ -751,9 +829,9 @@ static pj_status_t create_comp(pj_ice_strans *ice_st, unsigned comp_id)
     PJ_ASSERT_RETURN(comp_id <= ice_st->comp_cnt, PJNATH_EICEINCOMPID);
 
     /* Create component */
-    comp = PJ_POOL_ZALLOC_T(ice_st->pool, pj_ice_strans_comp);
-    comp->ice_st = ice_st;
-    comp->comp_id = comp_id;
+    comp           = PJ_POOL_ZALLOC_T(ice_st->pool, pj_ice_strans_comp);
+    comp->ice_st   = ice_st;
+    comp->comp_id  = comp_id;
     comp->creating = PJ_TRUE;
 
     ice_st->comp[comp_id-1] = comp;
@@ -763,20 +841,17 @@ static pj_status_t create_comp(pj_ice_strans *ice_st, unsigned comp_id)
 
     /* Create STUN transport if configured */
     for (i=0; i<ice_st->cfg.stun_tp_cnt; ++i) {
-	unsigned max_cand_cnt = PJ_ICE_ST_MAX_CAND - comp->cand_cnt -
-				ice_st->cfg.turn_tp_cnt;
+        unsigned max_cand_cnt = PJ_ICE_ST_MAX_CAND - comp->cand_cnt - ice_st->cfg.turn_tp_cnt;
 
-	status = PJ_ETOOSMALL;
+        status = PJ_ETOOSMALL;
 
-	if ((max_cand_cnt > 0) && (max_cand_cnt <= PJ_ICE_ST_MAX_CAND))
-	    status = add_stun_and_host(ice_st, comp, i, max_cand_cnt);
+        if ((max_cand_cnt > 0) && (max_cand_cnt <= PJ_ICE_ST_MAX_CAND))
+            status = add_stun_and_host(ice_st, comp, i, max_cand_cnt);
 
-	if (status != PJ_SUCCESS) {
-	    PJ_PERROR(3,(ice_st->obj_name, status,
-			 "Failed creating STUN transport #%d for comp %d",
-			 i, comp->comp_id));
-	    //return status;
-	}
+        if (status != PJ_SUCCESS)
+            PJ_PERROR(3,(ice_st->obj_name, status,
+                         "Failed creating STUN transport #%d for comp %d",
+                         i, comp->comp_id));
     }
 
     /* Create TURN relay if configured. */
@@ -816,30 +891,31 @@ static pj_status_t alloc_send_buf(pj_ice_strans *ice_st, unsigned buf_size)
 {
     if (buf_size > ice_st->buf_size) {
         unsigned i;
-        
+
         if (ice_st->is_pending) {
             /* The current buffer is insufficient, but still currently used.*/
             return PJ_EBUSY;
         }
 
-    	pj_pool_safe_release(&ice_st->buf_pool);
+	pj_pool_safe_release(&ice_st->buf_pool);
 
-    	ice_st->buf_pool = pj_pool_create(ice_st->pf, "ice_buf",
-    			       (buf_size + sizeof(pending_send)) *
-    			       ice_st->num_buf, 512, NULL);
+        ice_st->buf_pool = pj_pool_create(ice_st->pf, "ice_buf",
+                                          (buf_size + sizeof(pending_send)) * ice_st->num_buf,
+                                          512, NULL);
 	if (!ice_st->buf_pool)
 	    return PJ_ENOMEM;
 
 	ice_st->buf_size = buf_size;
 	ice_st->send_buf = pj_pool_calloc(ice_st->buf_pool, ice_st->num_buf,
-			       		  sizeof(pending_send));
-	for (i = 0; i < ice_st->num_buf; i++) {
+					  sizeof(pending_send));
+
+	for (i = 0; i < ice_st->num_buf; i++)
 	    ice_st->send_buf[i].buffer = pj_pool_alloc(ice_st->buf_pool,
-	    					       buf_size);
-	}
+						       buf_size);
+
 	ice_st->buf_idx = ice_st->empty_idx = 0;
     }
-    
+
     return PJ_SUCCESS;
 }
 
@@ -1204,9 +1280,15 @@ PJ_DEF(pj_status_t) pj_ice_strans_init_ice(pj_ice_strans *ice_st,
 
     /* Init callback */
     pj_bzero(&ice_cb, sizeof(ice_cb));
-    ice_cb.on_ice_complete = &on_ice_complete;
-    ice_cb.on_rx_data = &ice_rx_data;
-    ice_cb.on_tx_pkt = &ice_tx_pkt;
+    ice_cb.on_ice_complete          = &on_ice_complete;
+    ice_cb.on_rx_data               = &ice_rx_data;
+    ice_cb.on_tx_pkt                = &ice_tx_pkt;
+#if PJ_HAS_TCP
+    ice_cb.wait_tcp_connection      = &ice_wait_tcp_connection;
+    ice_cb.select_turn_dataconn     = &ice_select_turn_dataconn;
+    ice_cb.reconnect_tcp_connection = &ice_reconnect_tcp_connection;
+    ice_cb.close_tcp_connection     = &ice_close_tcp_connection;
+#endif
 
     /* Create! */
     status = pj_ice_sess_create(&ice_st->cfg.stun_cfg, ice_st->obj_name, role,
@@ -1272,17 +1354,18 @@ PJ_DEF(pj_status_t) pj_ice_strans_init_ice(pj_ice_strans *ice_st,
 	    if (comp->ipv4_mapped &&
 	        cand->addr.addr.sa_family != pj_AF_INET())
 	    {
-	    	continue;
+		continue;
 	    }
 
 	    /* Add the candidate */
 	    status = pj_ice_sess_add_cand(ice_st->ice, comp->comp_id,
-					  cand->transport_id, cand->type,
-					  cand->local_pref,
-					  &cand->foundation, &cand->addr,
-					  &cand->base_addr,  &cand->rel_addr,
-					  pj_sockaddr_get_len(&cand->addr),
-					  (unsigned*)&ice_cand_id);
+                                          cand->transport_id, cand->type,
+                                          cand->local_pref,
+                                          &cand->foundation, &cand->addr,
+                                          &cand->base_addr,  &cand->rel_addr,
+                                          pj_sockaddr_get_len(&cand->addr),
+                                          (unsigned*)&ice_cand_id,
+                                          cand->transport);
 	    if (status != PJ_SUCCESS)
 		goto on_error;
 	}
@@ -1703,33 +1786,34 @@ static pj_status_t send_data(pj_ice_strans *ice_st,
 					 dst_addr, dst_addr_len);
 	    goto on_return;
 	} else {
-    	    const pj_sockaddr_t *dest_addr;
-    	    unsigned dest_addr_len;
+            const pj_sockaddr_t *dest_addr;
+            unsigned dest_addr_len;
 
-    	    if (comp->ipv4_mapped) {
-    	    	if (comp->synth_addr_len == 0 ||
-    	    	    pj_sockaddr_cmp(&comp->dst_addr, dst_addr) != 0)
-    	    	{
-    	    	    status = pj_sockaddr_synthesize(pj_AF_INET6(),
-    	    					    &comp->synth_addr,
-    	    					    dst_addr);
-    	    	    if (status != PJ_SUCCESS)
-    	            	goto on_return;
+            if (comp->ipv4_mapped) {
+                if (comp->synth_addr_len == 0 ||
+                    pj_sockaddr_cmp(&comp->dst_addr, dst_addr) != 0)
+                {
+                    status = pj_sockaddr_synthesize(pj_AF_INET6(),
+                                                    &comp->synth_addr,
+                                                    dst_addr);
+                    if (status != PJ_SUCCESS)
+                        goto on_return;
 
-    	    	    pj_sockaddr_cp(&comp->dst_addr, dst_addr);
-    	    	    comp->synth_addr_len = pj_sockaddr_get_len(
-    	    	    			       &comp->synth_addr);
-    	    	}
-	    	dest_addr = &comp->synth_addr;
-    	    	dest_addr_len = comp->synth_addr_len;
-    	    } else {
-    		dest_addr = dst_addr;
-    		dest_addr_len = dst_addr_len;
-    	    }
+                    pj_sockaddr_cp(&comp->dst_addr, dst_addr);
+                    comp->synth_addr_len = pj_sockaddr_get_len(
+                                                               &comp->synth_addr);
+                }
+                dest_addr = &comp->synth_addr;
+                dest_addr_len = comp->synth_addr_len;
+            } else {
+                dest_addr = dst_addr;
+                dest_addr_len = dst_addr_len;
+            }
 
+            pj_ssize_t size;
 	    status = pj_stun_sock_sendto(comp->stun[tp_idx].sock, NULL, buf,
 					 (unsigned)data_len, 0, dest_addr,
-					 dest_addr_len);
+					 dest_addr_len, &size);
 	    goto on_return;
 	}
 
@@ -1739,12 +1823,12 @@ static pj_status_t send_data(pj_ice_strans *ice_st,
 on_return:
     /* We continue later in on_data_sent() callback. */
     if (status == PJ_EPENDING)
-    	return status;
+        return status;
 
     if (call_cb) {
-    	on_data_sent(ice_st, (status == PJ_SUCCESS? data_len: -status));
+        on_data_sent(ice_st, (status == PJ_SUCCESS? data_len: -status));
     } else {
-    	check_pending_send(ice_st);
+        check_pending_send(ice_st);
     }
 
     return status;
@@ -1842,7 +1926,6 @@ static void on_ice_complete(pj_ice_sess *ice, pj_status_t status)
 				      sizeof(lip), 3);
 		    pj_sockaddr_print(&check->rcand->addr, rip,
 				      sizeof(rip), 3);
-
 		    if (tp_typ == TP_TURN) {
 			/* Activate channel binding for the remote address
 			 * for more efficient data transfer using TURN.
@@ -1893,11 +1976,11 @@ static void on_ice_complete(pj_ice_sess *ice, pj_status_t status)
  * Callback called by ICE session when it wants to send outgoing packet.
  */
 static pj_status_t ice_tx_pkt(pj_ice_sess *ice,
-			      unsigned comp_id,
-			      unsigned transport_id,
-			      const void *pkt, pj_size_t size,
-			      const pj_sockaddr_t *dst_addr,
-			      unsigned dst_addr_len)
+                              unsigned comp_id,
+                              unsigned transport_id,
+                              const void *pkt, pj_size_t size,
+                              const pj_sockaddr_t *dst_addr,
+                              unsigned dst_addr_len)
 {
     pj_ice_strans *ice_st = (pj_ice_strans*)ice->user_data;
     pj_ice_strans_comp *comp;
@@ -1918,23 +2001,53 @@ static pj_status_t ice_tx_pkt(pj_ice_sess *ice,
          ice_st->send_buf[ice_st->buf_idx].buffer != pkt))
     {
         use_buf = PJ_TRUE;
-    	status = use_buffer(ice_st, comp_id, pkt, size, dst_addr,
-    			    dst_addr_len, &buf);
-    	if (status == PJ_EPENDING || status != PJ_SUCCESS) {
-    	    pj_grp_lock_release(ice_st->grp_lock);
-    	    return status;
-    	}
+        status = use_buffer(ice_st, comp_id, pkt, size, dst_addr,
+                            dst_addr_len, &buf);
+        if (status == PJ_EPENDING || status != PJ_SUCCESS) {
+            pj_grp_lock_release(ice_st->grp_lock);
+            return status;
+        }
     }
     pj_grp_lock_release(ice_st->grp_lock);
 
     comp = ice_st->comp[comp_id-1];
 
     TRACE_PKT((comp->ice_st->obj_name,
-	       "Component %d TX packet to %s:%d with transport %d",
-	       comp_id,
-	       pj_sockaddr_print(dst_addr, daddr, sizeof(addr), 2),
-	       pj_sockaddr_get_port(dst_addr),
-	       tp_typ));
+               "Component %d TX packet to %s:%d with transport %d",
+               comp_id,
+               pj_sockaddr_print(dst_addr, daddr, sizeof(daddr), 2),
+               pj_sockaddr_get_port(dst_addr),
+               tp_typ));
+
+
+    pj_ssize_t sent_size;
+
+    unsigned final_len    = size;
+    pj_bool_t add_header  = PJ_FALSE;
+    if (comp->ice_st->cfg.stun_tp->conn_type == PJ_STUN_TP_TCP)
+	add_header = PJ_TRUE;
+
+    if (add_header) {
+	// TCP
+	/*
+	 * RFC6544 ICE requires an agent to demultiplex STUN and
+	 * application-layer traffic, since they appear on the same port.  This
+	 * demultiplexing is described in [RFC5245] and is done using the magic
+	 * cookie and other fields of the message.  Stream-oriented transports
+	 * introduce another wrinkle, since they require a way to frame the
+	 * connection so that the application and STUN packets can be extracted
+	 * in order to differentiate STUN packets from application-layer
+	 * traffic.  For this reason, TCP media streams utilizing ICE use the
+	 * basic framing provided in RFC 4571 [RFC4571], even if the application
+	 * layer protocol is not RTP.
+	 */
+	pj_uint8_t header_1 = size % 256;
+	pj_uint8_t header_0 = size >> 8;
+	final_len = 2 + size;
+	memcpy(&ice_st->rtp_pkt, &(header_0), sizeof(pj_uint8_t));
+	memcpy(&ice_st->rtp_pkt[1], &(header_1), sizeof(pj_uint8_t));
+	memcpy(&ice_st->rtp_pkt[2], (unsigned char *)pkt, size);
+    }
 
     if (tp_typ == TP_TURN) {
 	if (comp->turn[tp_idx].sock) {
@@ -1942,36 +2055,39 @@ static pj_status_t ice_tx_pkt(pj_ice_sess *ice,
 					 (const pj_uint8_t*)buf,
 					 (unsigned)size,
 					 dst_addr, dst_addr_len);
+	    ice_st->is_pending = (status == PJ_EPENDING ||
+	                          (unsigned)sent_size != final_len);
 	} else {
 	    status = PJ_EINVALIDOP;
 	}
     } else if (tp_typ == TP_STUN) {
-    	const pj_sockaddr_t *dest_addr;
-    	unsigned dest_addr_len;
+	const pj_sockaddr_t *dest_addr;
+	unsigned dest_addr_len;
 
-    	if (comp->ipv4_mapped) {
-    	    if (comp->synth_addr_len == 0 ||
-    	    	pj_sockaddr_cmp(&comp->dst_addr, dst_addr) != 0)
-    	    {
-    	    	status = pj_sockaddr_synthesize(pj_AF_INET6(),
-    	    					&comp->synth_addr, dst_addr);
-    	    	if (status != PJ_SUCCESS) {
-    	    	    goto on_return;
-    	    	}
-    	    
-    	    	pj_sockaddr_cp(&comp->dst_addr, dst_addr);
-    	    	comp->synth_addr_len = pj_sockaddr_get_len(&comp->synth_addr);
-    	    }
+	if (comp->ipv4_mapped) {
+	    if (comp->synth_addr_len == 0 ||
+		pj_sockaddr_cmp(&comp->dst_addr, dst_addr) != 0)
+	    {
+		status = pj_sockaddr_synthesize(pj_AF_INET6(),
+						&comp->synth_addr, dst_addr);
+		if (status != PJ_SUCCESS) {
+		    goto on_return;
+		}
+
+		pj_sockaddr_cp(&comp->dst_addr, dst_addr);
+		comp->synth_addr_len = pj_sockaddr_get_len(&comp->synth_addr);
+	    }
 	    dest_addr = &comp->synth_addr;
-    	    dest_addr_len = comp->synth_addr_len;
-    	} else {
-    	    dest_addr = dst_addr;
-    	    dest_addr_len = dst_addr_len;
-    	}
+	    dest_addr_len = comp->synth_addr_len;
+	} else {
+	    dest_addr = dst_addr;
+	    dest_addr_len = dst_addr_len;
+	}
 
+        pj_ssize_t size;
 	status = pj_stun_sock_sendto(comp->stun[tp_idx].sock, NULL,
 				     buf, (unsigned)size, 0,
-				     dest_addr, dest_addr_len);
+				     dest_addr, dest_addr_len, &size);
     } else {
 	pj_assert(!"Invalid transport ID");
 	status = PJ_EINVALIDOP;
@@ -1980,12 +2096,12 @@ static pj_status_t ice_tx_pkt(pj_ice_sess *ice,
 on_return:
     if (use_buf && status != PJ_EPENDING) {
         pj_grp_lock_acquire(ice_st->grp_lock);
-    	if (ice_st->num_buf > 0) {
-    	    ice_st->buf_idx = (ice_st->buf_idx + 1) % ice_st->num_buf;
-    	    pj_assert(ice_st->buf_idx == ice_st->empty_idx);
-    	}
-    	ice_st->is_pending = PJ_FALSE;
-    	pj_grp_lock_release(ice_st->grp_lock);
+	if (ice_st->num_buf > 0) {
+	    ice_st->buf_idx = (ice_st->buf_idx + 1) % ice_st->num_buf;
+	    pj_assert(ice_st->buf_idx == ice_st->empty_idx);
+	}
+	ice_st->is_pending = PJ_FALSE;
+	pj_grp_lock_release(ice_st->grp_lock);
     }
 
     return status;
@@ -2011,23 +2127,246 @@ static void ice_rx_data(pj_ice_sess *ice,
     }
 }
 
+static void on_peer_connection(pj_stun_session* sess,
+                               pj_status_t status,
+                               pj_sockaddr_t* remote_addr)
+{
+
+    pj_stun_sock       *stun_sock;
+    sock_user_data     *data;
+    pj_ice_strans_comp *comp;
+    pj_ice_strans      *ice_st;
+
+    stun_sock = (pj_stun_sock *)pj_stun_session_get_user_data(sess);
+    /* We have disassociated ourselves from the STUN session */
+    if (!stun_sock)
+        return;
+
+    data = (sock_user_data *)pj_stun_sock_get_user_data(stun_sock);
+    /* We have disassociated ourselves from the STUN socket */
+    if (!data)
+        return;
+
+    comp   = data->comp;
+    ice_st = comp->ice_st;
+
+    /* Incorrect ICE */
+    if (!ice_st || !ice_st->ice)
+        return;
+
+    ice_st->is_pending = PJ_FALSE;
+    ice_sess_on_peer_connection(ice_st->ice,
+                                data->transport_id, status, remote_addr);
+}
+
+static void on_peer_reset_connection(pj_stun_session* sess,
+                                     pj_sockaddr_t* remote_addr)
+{
+    pj_stun_sock       *stun_sock;
+    sock_user_data     *data;
+    pj_ice_strans_comp *comp;
+    pj_ice_strans      *ice_st;
+
+    stun_sock = (pj_stun_sock *)pj_stun_session_get_user_data(sess);
+    /* We have disassociated ourselves from the STUN session */
+    if (!stun_sock)
+        return;
+
+    data = (sock_user_data *)pj_stun_sock_get_user_data(stun_sock);
+    /* We have disassociated ourselves from the STUN socket */
+    if (!data)
+        return;
+
+    comp   = data->comp;
+    ice_st = comp->ice_st;
+
+    /* Incorrect ICE */
+    if (!ice_st || !ice_st->ice)
+        return;
+
+    ice_sess_on_peer_reset_connection(ice_st->ice,
+                                      data->transport_id, remote_addr);
+}
+
+static void on_peer_packet(pj_stun_session* sess, pj_sockaddr_t* remote_addr) {
+
+    if (!sess || !remote_addr)
+        return;
+
+    pj_stun_sock       *stun_sock;
+    sock_user_data     *data;
+    pj_ice_strans_comp *comp;
+    pj_ice_strans      *ice_st;
+
+    stun_sock = (pj_stun_sock *)pj_stun_session_get_user_data(sess);
+    /* We have disassociated ourselves from the STUN session */
+    if (!stun_sock)
+        return;
+
+    data = (sock_user_data *)pj_stun_sock_get_user_data(stun_sock);
+    /* We have disassociated ourselves from the STUN socket */
+    if (!data)
+        return;
+
+    comp = data->comp;
+    if (!comp)
+        return;
+
+    ice_st = comp->ice_st;
+    /* Incorrect ICE */
+    if (!ice_st || !ice_st->ice)
+        return;
+
+    ice_sess_on_peer_packet(ice_st->ice, data->transport_id, remote_addr);
+}
+
+#if PJ_HAS_TCP
+static pj_status_t ice_wait_tcp_connection(pj_ice_sess *ice,
+                                           pj_ice_sess_checklist *clist,
+                                           unsigned check_id)
+{
+    pj_ice_sess_check      *check   = &clist->checks[check_id];
+    const pj_ice_sess_cand *lcand   = check->lcand;
+    const pj_ice_sess_cand *rcand   = check->rcand;
+    pj_ice_strans          *ice_st  = (pj_ice_strans *)ice->user_data;
+    pj_ice_strans_comp     *st_comp = ice_st->comp[lcand->comp_id - 1];
+
+    int idx = -1;
+    for (int i=0; i<ice_st->cfg.stun_tp_cnt; ++i)
+        if (ice_st->cfg.stun_tp[i].af == rcand->addr.addr.sa_family) {
+            idx = i;
+            break;
+        }
+
+    if (idx == -1) {
+        PJ_LOG(4, (ice_st->obj_name, "Comp %d: No STUN sock found.",
+                   st_comp->comp_id));
+        return PJ_EINVAL;
+    }
+    if (st_comp->stun[idx].sock) {
+        pj_stun_session *sess = pj_stun_sock_get_session(st_comp->stun[idx].sock);
+        if (!sess) {
+            PJ_LOG(4, (ice_st->obj_name, "Comp %d: No STUN session.",
+                       st_comp->comp_id));
+            return PJ_EINVAL;
+        }
+        pj_stun_session_callback(sess)->on_peer_connection = &on_peer_connection;
+        pj_stun_session_callback(sess)->on_peer_reset_connection = &on_peer_reset_connection;
+        pj_stun_session_callback(sess)->on_peer_packet = &on_peer_packet;
+        return pj_stun_sock_connect_active(st_comp->stun[idx].sock, &rcand->addr,
+                                           rcand->addr.addr.sa_family);
+    }
+
+    return PJ_EINVAL;
+}
+
+static pj_status_t ice_select_turn_dataconn(pj_ice_sess *ice,
+                                            pj_ice_sess_checklist *clist,
+                                            unsigned check_id)
+{
+    pj_ice_sess_check      *check   = &clist->checks[check_id];
+    const pj_ice_sess_cand *lcand   = check->lcand;
+    const pj_ice_sess_cand *rcand   = check->rcand;
+    pj_ice_strans          *ice_st  = (pj_ice_strans *)ice->user_data;
+    pj_ice_strans_comp     *st_comp = ice_st->comp[lcand->comp_id - 1];
+
+    for (int i=0; i<ice_st->cfg.turn_tp_cnt; ++i) {
+        pj_turn_session_info info;
+        pj_turn_sock_get_info(st_comp->turn[i].sock, &info);
+        if (st_comp->turn[i].sock
+            && pj_turn_sock_has_dataconn(st_comp->turn[i].sock, &rcand->addr)) {
+            ice_select_incoming_turn(ice, clist, check_id);
+            return PJ_SUCCESS; // Already connected via TURN
+        }
+    }
+
+    return PJ_EINVAL;
+}
+
+static pj_status_t ice_reconnect_tcp_connection(pj_ice_sess *ice,
+                                                pj_ice_sess_checklist *clist,
+                                                unsigned check_id)
+{
+    pj_ice_sess_check      *check   = &clist->checks[check_id];
+    const pj_ice_sess_cand *lcand   = check->lcand;
+    const pj_ice_sess_cand *rcand   = check->rcand;
+    pj_ice_strans          *ice_st  = (pj_ice_strans *)ice->user_data;
+    pj_ice_strans_comp     *st_comp = ice_st->comp[lcand->comp_id - 1];
+
+    int idx = -1;
+    for (int i=0; i<ice_st->cfg.stun_tp_cnt; ++i)
+        if (ice_st->cfg.stun_tp[i].af == rcand->addr.addr.sa_family) {
+            idx = i;
+            break;
+        }
+
+    if (idx == -1) {
+        PJ_LOG(4, (ice_st->obj_name, "Comp %d: No STUN sock found.",
+                   st_comp->comp_id));
+        return PJ_EINVAL;
+    }
+
+    if (st_comp->stun[idx].sock) {
+        pj_stun_session *sess = pj_stun_sock_get_session(st_comp->stun[idx].sock);
+        if (!sess) {
+            PJ_LOG(4, (ice_st->obj_name, "Comp %d: No STUN session.",
+                       st_comp->comp_id));
+            return PJ_EINVAL;
+        }
+        pj_stun_session_callback(sess)->on_peer_connection = &on_peer_connection;
+        pj_stun_session_callback(sess)->on_peer_reset_connection = &on_peer_reset_connection;
+        pj_stun_session_callback(sess)->on_peer_packet = &on_peer_packet;
+        return pj_stun_sock_reconnect_active(st_comp->stun[idx].sock, &rcand->addr,
+                                             rcand->addr.addr.sa_family);
+    }
+
+    return PJ_EINVAL;
+}
+
+static pj_status_t ice_close_tcp_connection(pj_ice_sess *ice,
+                                            pj_ice_sess_checklist *clist,
+                                            unsigned check_id)
+{
+    pj_ice_sess_check      *check   = &clist->checks[check_id];
+    const pj_ice_sess_cand *lcand   = check->lcand;
+    const pj_ice_sess_cand *rcand   = check->rcand;
+    pj_ice_strans          *ice_st  = (pj_ice_strans *)ice->user_data;
+    pj_ice_strans_comp     *st_comp = ice_st->comp[lcand->comp_id - 1];
+
+    int idx = -1;
+    for (int i=0; i<ice_st->cfg.stun_tp_cnt; ++i)
+        if (ice_st->cfg.stun_tp[i].af == rcand->addr.addr.sa_family) {
+            idx = i;
+            break;
+        }
+
+    if (idx != -1 && st_comp->stun[idx].sock) {
+        const pj_ice_sess_cand *rcand = check->rcand;
+        ice_st->is_pending = PJ_FALSE;
+        return pj_stun_sock_close(st_comp->stun[idx].sock, &rcand->addr);
+    }
+
+    return PJ_EINVAL;
+}
+#endif
+
 static void check_pending_send(pj_ice_strans *ice_st)
 {
     pj_grp_lock_acquire(ice_st->grp_lock);
 
     if (ice_st->num_buf > 0)
         ice_st->buf_idx = (ice_st->buf_idx + 1) % ice_st->num_buf;
-    
+
     if (ice_st->num_buf > 0 && ice_st->buf_idx != ice_st->empty_idx) {
-	/* There's some pending send. Send it one by one. */
+        /* There's some pending send. Send it one by one. */
         pending_send *ps = &ice_st->send_buf[ice_st->buf_idx];
 
-	pj_grp_lock_release(ice_st->grp_lock);
-    	send_data(ice_st, ps->comp_id, ps->buffer, ps->data_len,
-    	    	  &ps->dst_addr, ps->dst_addr_len, PJ_FALSE, PJ_TRUE);
+        pj_grp_lock_release(ice_st->grp_lock);
+        send_data(ice_st, ps->comp_id, ps->buffer, ps->data_len,
+                  &ps->dst_addr, ps->dst_addr_len, PJ_FALSE, PJ_TRUE);
     } else {
-    	ice_st->is_pending = PJ_FALSE;
-    	pj_grp_lock_release(ice_st->grp_lock);
+        ice_st->is_pending = PJ_FALSE;
+        pj_grp_lock_release(ice_st->grp_lock);
     }
 }
 
@@ -2112,7 +2451,8 @@ static pj_bool_t stun_on_data_sent(pj_stun_sock *stun_sock,
     PJ_UNUSED_ARG(send_key);
 
     data = (sock_user_data *)pj_stun_sock_get_user_data(stun_sock);
-    if (!data || !data->comp || !data->comp->ice_st) return PJ_TRUE;
+    if (!data || !data->comp || !data->comp->ice_st)
+        return PJ_TRUE;
 
     return on_data_sent(data->comp->ice_st, sent);
 }
@@ -2317,7 +2657,11 @@ static pj_bool_t stun_on_status(pj_stun_sock *stun_sock,
 		PJ_LOG(4,(ice_st->obj_name, "STUN error is ignored"));
 	    }
 	}
-	break;
+        break;
+    case PJ_STUN_SESS_DESTROYED:
+    case PJ_STUN_TCP_CONNECT_ERROR:
+    default:
+        break;
     }
 
     return pj_grp_lock_dec_ref(ice_st->grp_lock)? PJ_FALSE : PJ_TRUE;
@@ -2325,10 +2669,10 @@ static pj_bool_t stun_on_status(pj_stun_sock *stun_sock,
 
 /* Callback when TURN socket has received a packet */
 static void turn_on_rx_data(pj_turn_sock *turn_sock,
-			    void *pkt,
-			    unsigned pkt_len,
-			    const pj_sockaddr_t *peer_addr,
-			    unsigned addr_len)
+                            void *pkt,
+                            unsigned size,
+                            const pj_sockaddr_t *peer_addr,
+                            unsigned addr_len)
 {
     pj_ice_strans_comp *comp;
     sock_user_data *data;
@@ -2352,21 +2696,102 @@ static void turn_on_rx_data(pj_turn_sock *turn_sock,
 	 */
 	if (comp->ice_st->cb.on_rx_data) {
 	    (*comp->ice_st->cb.on_rx_data)(comp->ice_st, comp->comp_id, pkt,
-					   pkt_len, peer_addr, addr_len);
+					   size, peer_addr, addr_len);
 	}
 
     } else {
 
 	/* Hand over the packet to ICE */
-	status = pj_ice_sess_on_rx_pkt(comp->ice_st->ice, comp->comp_id,
-				       data->transport_id, pkt, pkt_len,
-				       peer_addr, addr_len);
-
-	if (status != PJ_SUCCESS) {
-	    ice_st_perror(comp->ice_st,
-			  "Error processing packet from TURN relay",
-			  status);
-	}
+        if (comp->ice_st->cfg.turn_tp->conn_type == PJ_TURN_TP_TCP && size > 0) {
+            unsigned parsed = 0;
+            pj_status_t status;
+
+            do {
+                pj_uint16_t leftover = size - parsed;
+                pj_uint8_t *current_packet = ((pj_uint8_t *)(pkt)) + parsed;
+
+                /* RFC6544, the packet is wrapped into a packet following the RFC4571 */
+                pj_bool_t store_remaining = PJ_TRUE;
+                if (comp->ice_st->rx_buffer_size || comp->ice_st->rx_wanted_size) {
+                    /* a single packet left to process */
+                    if (comp->ice_st->rx_buffer_size == 1) {
+                        /* get last frame's lenght from its header */
+                        leftover = (pj_uint16_t) ((comp->ice_st->rx_buffer[0] << 8)
+                                                  | (current_packet[0] << 0));
+                        /* adjust counters accordingly */
+                        comp->ice_st->rx_buffer_size--;
+                        current_packet++;
+                        parsed++;
+
+                        if (leftover + parsed <= size) {
+                            /* we didn't get what we were promissed in the
+                             * header. furthermore, this was the last frame and
+                             * therefore we're done.
+                             */
+                            store_remaining  = PJ_FALSE;
+                            parsed          += leftover;
+                        } else {
+                            comp->ice_st->rx_wanted_size = leftover;
+                        }
+                    } else if (leftover + comp->ice_st->rx_buffer_size >=
+                               comp->ice_st->rx_wanted_size)
+                    {
+                        /* We have enough leftover bytes in buffer to build a new
+                         * packet and parse it
+                         */
+                        store_remaining = PJ_FALSE;
+                        pj_uint16_t eaten_bytes = comp->ice_st->rx_wanted_size - \
+                                                  comp->ice_st->rx_buffer_size;
+                        memcpy(comp->ice_st->rx_buffer + \
+                               comp->ice_st->rx_buffer_size,
+                               current_packet, eaten_bytes);
+
+                        leftover        = comp->ice_st->rx_wanted_size;
+                        current_packet  = comp->ice_st->rx_buffer;
+                        parsed         += eaten_bytes;
+
+                        comp->ice_st->rx_buffer_size  = 0;
+                        comp->ice_st->rx_wanted_size  = 0;
+                    }
+                } else if (leftover > 1) {
+                    leftover        = GETVAL16H(current_packet, 0);
+                    current_packet += 2;
+                    parsed         += 2;
+                    if (leftover + parsed <= size) {
+                        store_remaining  = PJ_FALSE;
+                        parsed          += leftover;
+                    } else {
+                        comp->ice_st->rx_wanted_size = leftover;
+                    }
+                }
+                if (store_remaining) {
+                    leftover = size - parsed;
+                    memcpy(comp->ice_st->rx_buffer + comp->ice_st->rx_buffer_size,
+                           current_packet, leftover);
+                    comp->ice_st->rx_buffer_size += leftover;
+                    status = PJ_SUCCESS;
+                    break;
+                }
+
+                status = pj_ice_sess_on_rx_pkt(comp->ice_st->ice, comp->comp_id,
+                                               data->transport_id,
+                                               current_packet, leftover,
+                                               peer_addr, addr_len);
+                if (status != PJ_SUCCESS) {
+                    ice_st_perror(comp->ice_st,
+                                  "Error processing packet from TURN relay",
+                                  status);
+                }
+            } while (parsed < size);
+        } else {
+            status = pj_ice_sess_on_rx_pkt(comp->ice_st->ice, comp->comp_id,
+                                           data->transport_id, pkt, size,
+                                           peer_addr, addr_len);
+            if (status != PJ_SUCCESS)
+                ice_st_perror(comp->ice_st,
+                              "Error processing packet from TURN relay",
+                              status);
+        }
     }
 
     pj_grp_lock_dec_ref(comp->ice_st->grp_lock);
@@ -2388,7 +2813,7 @@ static pj_bool_t turn_on_data_sent(pj_turn_sock *turn_sock,
 
 /* Callback when TURN client state has changed */
 static void turn_on_state(pj_turn_sock *turn_sock, pj_turn_state_t old_state,
-			  pj_turn_state_t new_state)
+                          pj_turn_state_t new_state)
 {
     pj_ice_strans_comp *comp;
     sock_user_data *data;
diff --git a/pjnath/src/pjnath/nat_detect.c b/pjnath/src/pjnath/nat_detect.c
index db0de10bc..da056cc20 100644
--- a/pjnath/src/pjnath/nat_detect.c
+++ b/pjnath/src/pjnath/nat_detect.c
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #include <pjnath/nat_detect.h>
 #include <pjnath/errno.h>
@@ -110,8 +110,8 @@ typedef struct nat_detect_session
 } nat_detect_session;
 
 
-static void on_read_complete(pj_ioqueue_key_t *key, 
-                             pj_ioqueue_op_key_t *op_key, 
+static void on_read_complete(pj_ioqueue_key_t *key,
+                             pj_ioqueue_op_key_t *op_key,
                              pj_ssize_t bytes_read);
 static void on_request_complete(pj_stun_session *sess,
 			        pj_status_t status,
@@ -201,7 +201,7 @@ static pj_status_t get_local_interface(const pj_sockaddr *server,
     }
 
     pj_sockaddr_cp(local_addr, &tmp);
-    
+
     pj_sock_close(sock);
     return PJ_SUCCESS;
 }
@@ -240,7 +240,7 @@ PJ_DEF(pj_status_t) pj_stun_detect_nat_type2(const pj_sockaddr *server,
     /*
      * Init NAT detection session.
      */
-    pool = pj_pool_create(stun_cfg->pf, "natck%p", PJNATH_POOL_LEN_NATCK, 
+    pool = pj_pool_create(stun_cfg->pf, "natck%p", PJNATH_POOL_LEN_NATCK,
 			  PJNATH_POOL_INC_NATCK, NULL);
     if (!pool)
 	return PJ_ENOMEM;
@@ -316,7 +316,7 @@ PJ_DEF(pj_status_t) pj_stun_detect_nat_type2(const pj_sockaddr *server,
     pj_bzero(&ioqueue_cb, sizeof(ioqueue_cb));
     ioqueue_cb.on_read_complete = &on_read_complete;
 
-    status = pj_ioqueue_register_sock2(sess->pool, stun_cfg->ioqueue, 
+    status = pj_ioqueue_register_sock2(sess->pool, stun_cfg->ioqueue,
 				       sess->sock, sess->grp_lock, sess,
 				       &ioqueue_cb, &sess->key);
     if (status != PJ_SUCCESS)
@@ -329,7 +329,8 @@ PJ_DEF(pj_status_t) pj_stun_detect_nat_type2(const pj_sockaddr *server,
     sess_cb.on_request_complete = &on_request_complete;
     sess_cb.on_send_msg = &on_send_msg;
     status = pj_stun_session_create(stun_cfg, pool->obj_name, &sess_cb,
-				    PJ_FALSE, sess->grp_lock, &sess->stun_sess);
+                                    PJ_FALSE, sess->grp_lock, &sess->stun_sess,
+                                    PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS)
 	goto on_error;
 
@@ -358,7 +359,7 @@ on_error:
 
 static void sess_destroy(nat_detect_session *sess)
 {
-    if (sess->stun_sess) { 
+    if (sess->stun_sess) {
 	pj_stun_session_destroy(sess->stun_sess);
 	sess->stun_sess = NULL;
     }
@@ -421,8 +422,8 @@ static void end_session(nat_detect_session *sess,
 /*
  * Callback upon receiving packet from network.
  */
-static void on_read_complete(pj_ioqueue_key_t *key, 
-                             pj_ioqueue_op_key_t *op_key, 
+static void on_read_complete(pj_ioqueue_key_t *key,
+                             pj_ioqueue_op_key_t *op_key,
                              pj_ssize_t bytes_read)
 {
     nat_detect_session *sess;
@@ -439,19 +440,19 @@ static void on_read_complete(pj_ioqueue_key_t *key,
 
     if (bytes_read < 0) {
 	if (-bytes_read != PJ_STATUS_FROM_OS(OSERR_EWOULDBLOCK) &&
-	    -bytes_read != PJ_STATUS_FROM_OS(OSERR_EINPROGRESS) && 
-	    -bytes_read != PJ_STATUS_FROM_OS(OSERR_ECONNRESET)) 
+	    -bytes_read != PJ_STATUS_FROM_OS(OSERR_EINPROGRESS) &&
+	    -bytes_read != PJ_STATUS_FROM_OS(OSERR_ECONNRESET))
 	{
 	    /* Permanent error */
-	    end_session(sess, (pj_status_t)-bytes_read, 
+	    end_session(sess, (pj_status_t)-bytes_read,
 			PJ_STUN_NAT_TYPE_ERR_UNKNOWN);
 	    goto on_return;
 	}
 
     } else if (bytes_read > 0) {
 	pj_stun_session_on_rx_pkt(sess->stun_sess, sess->rx_pkt, bytes_read,
-				  PJ_STUN_IS_DATAGRAM|PJ_STUN_CHECK_PACKET, 
-				  NULL, NULL, 
+				  PJ_STUN_IS_DATAGRAM|PJ_STUN_CHECK_PACKET,
+				  NULL, NULL,
 				  &sess->src_addr, sess->src_addr_len);
     }
 
@@ -459,7 +460,7 @@ static void on_read_complete(pj_ioqueue_key_t *key,
     sess->rx_pkt_len = sizeof(sess->rx_pkt);
     sess->src_addr_len = sizeof(sess->src_addr);
     status = pj_ioqueue_recvfrom(key, op_key, sess->rx_pkt, &sess->rx_pkt_len,
-				 PJ_IOQUEUE_ALWAYS_ASYNC, 
+				 PJ_IOQUEUE_ALWAYS_ASYNC,
 				 &sess->src_addr, &sess->src_addr_len);
 
     if (status != PJ_EPENDING) {
@@ -594,11 +595,11 @@ static void on_request_complete(pj_stun_session *stun_sess,
     /* Send Test 1B only when Test 2 completes. Must not send Test 1B
      * before Test 2 completes to avoid creating mapping on the NAT.
      */
-    if (!sess->result[ST_TEST_1B].executed && 
+    if (!sess->result[ST_TEST_1B].executed &&
 	sess->result[ST_TEST_2].complete &&
 	sess->result[ST_TEST_2].status != PJ_SUCCESS &&
 	sess->result[ST_TEST_1].complete &&
-	sess->result[ST_TEST_1].status == PJ_SUCCESS) 
+	sess->result[ST_TEST_1].status == PJ_SUCCESS)
     {
 	cmp = pj_sockaddr_cmp(&sess->local_addr, &sess->result[ST_TEST_1].ma);
 	if (cmp != 0)
@@ -660,7 +661,7 @@ static void on_request_complete(pj_stun_session *stun_sess,
     switch (sess->result[ST_TEST_1].status) {
     case PJNATH_ESTUNTIMEDOUT:
 	/*
-	 * Test 1 has timed-out. Conclude with NAT_TYPE_BLOCKED. 
+	 * Test 1 has timed-out. Conclude with NAT_TYPE_BLOCKED.
 	 */
 	end_session(sess, PJ_SUCCESS, PJ_STUN_NAT_TYPE_BLOCKED);
 	break;
@@ -693,7 +694,7 @@ static void on_request_complete(pj_stun_session *stun_sess,
 		/*
 		 * We've got other error with Test 2.
 		 */
-		end_session(sess, sess->result[ST_TEST_2].status, 
+		end_session(sess, sess->result[ST_TEST_2].status,
 			    PJ_STUN_NAT_TYPE_ERR_UNKNOWN);
 		break;
 	    }
@@ -773,14 +774,14 @@ static void on_request_complete(pj_stun_session *stun_sess,
 			 * It could be that port 3489 is blocked, while the
 			 * NAT itself looks to be a Restricted one.
 			 */
-			end_session(sess, PJ_SUCCESS, 
+			end_session(sess, PJ_SUCCESS,
 				    PJ_STUN_NAT_TYPE_RESTRICTED);
 			break;
 		    default:
 			/* Can't distinguish between Symmetric and Port
 			 * Restricted, so set the type to Unknown
 			 */
-			end_session(sess, PJ_SUCCESS, 
+			end_session(sess, PJ_SUCCESS,
 				    PJ_STUN_NAT_TYPE_ERR_UNKNOWN);
 			break;
 		    }
@@ -798,7 +799,7 @@ static void on_request_complete(pj_stun_session *stun_sess,
 		/*
 		 * We've got other error with Test 2.
 		 */
-		end_session(sess, sess->result[ST_TEST_2].status, 
+		end_session(sess, sess->result[ST_TEST_2].status,
 			    PJ_STUN_NAT_TYPE_ERR_UNKNOWN);
 		break;
 	    }
@@ -808,7 +809,7 @@ static void on_request_complete(pj_stun_session *stun_sess,
 	/*
 	 * We've got other error with Test 1.
 	 */
-	end_session(sess, sess->result[ST_TEST_1].status, 
+	end_session(sess, sess->result[ST_TEST_1].status,
 		    PJ_STUN_NAT_TYPE_ERR_UNKNOWN);
 	break;
     }
@@ -840,15 +841,15 @@ static pj_status_t send_test(nat_detect_session *sess,
     tsx_id[2] = test_id;
 
     /* Create BIND request */
-    status = pj_stun_session_create_req(sess->stun_sess, 
+    status = pj_stun_session_create_req(sess->stun_sess,
 					PJ_STUN_BINDING_REQUEST, magic,
-					(pj_uint8_t*)tsx_id, 
+					(pj_uint8_t*)tsx_id,
 					&sess->result[test_id].tdata);
     if (status != PJ_SUCCESS)
 	goto on_error;
 
     /* Add CHANGE-REQUEST attribute */
-    status = pj_stun_msg_add_uint_attr(sess->pool, 
+    status = pj_stun_msg_add_uint_attr(sess->pool,
 				       sess->result[test_id].tdata->msg,
 				       PJ_STUN_ATTR_CHANGE_REQUEST,
 				       change_flag);
@@ -867,15 +868,16 @@ static pj_status_t send_test(nat_detect_session *sess,
 	sess->cur_server = &sess->server;
     }
 
-    PJ_LOG(5,(sess->pool->obj_name, 
-              "Performing %s to %s:%d", 
+    PJ_LOG(5,(sess->pool->obj_name,
+              "Performing %s to %s:%d",
 	      test_names[test_id],
 	      pj_sockaddr_print(sess->cur_server, addr, sizeof(addr), 2),
 	      pj_sockaddr_get_port(sess->cur_server)));
 
     /* Send the request */
     status = pj_stun_session_send_msg(sess->stun_sess, NULL, PJ_TRUE,
-				      PJ_TRUE, sess->cur_server, 
+				      (pj_stun_session_tp_type(sess->stun_sess) == PJ_STUN_TP_UDP),
+				      sess->cur_server,
 				      pj_sockaddr_get_len(sess->cur_server),
 				      sess->result[test_id].tdata);
     if (status != PJ_SUCCESS)
@@ -944,4 +946,3 @@ static void on_sess_timer(pj_timer_heap_t *th,
 	pj_assert(!"Invalid timer ID");
     }
 }
-
diff --git a/pjnath/src/pjnath/stun_session.c b/pjnath/src/pjnath/stun_session.c
index f2b4f7058..e91adecbb 100644
--- a/pjnath/src/pjnath/stun_session.c
+++ b/pjnath/src/pjnath/stun_session.c
@@ -49,6 +49,8 @@ struct pj_stun_session
 
     pj_stun_tx_data	 pending_request_list;
     pj_stun_tx_data	 cached_response_list;
+
+    pj_stun_tp_type	 conn_type;
 };
 
 #define SNAME(s_)		    ((s_)->pool->obj_name)
@@ -523,8 +525,9 @@ PJ_DEF(pj_status_t) pj_stun_session_create( pj_stun_config *cfg,
 					    const char *name,
 					    const pj_stun_session_cb *cb,
 					    pj_bool_t fingerprint,
-					    pj_grp_lock_t *grp_lock,
-					    pj_stun_session **p_sess)
+                                            pj_grp_lock_t *grp_lock,
+                                            pj_stun_session **p_sess,
+                                            pj_stun_tp_type conn_type)
 {
     pj_pool_t	*pool;
     pj_stun_session *sess;
@@ -1538,3 +1541,12 @@ on_return:
     return status;
 }
 
+PJ_DECL(pj_stun_session_cb *) pj_stun_session_callback(pj_stun_session *sess)
+{
+  return sess ? &sess->cb : NULL;
+}
+PJ_DECL(pj_stun_tp_type) pj_stun_session_tp_type(pj_stun_session *sess)
+{
+  return sess ? sess->conn_type : PJ_STUN_TP_UDP;
+}
+
diff --git a/pjnath/src/pjnath/stun_sock.c b/pjnath/src/pjnath/stun_sock.c
index 5fe825cf5..cc8e5038e 100644
--- a/pjnath/src/pjnath/stun_sock.c
+++ b/pjnath/src/pjnath/stun_sock.c
@@ -40,6 +40,36 @@
 
 enum { MAX_BIND_RETRY = 100 };
 
+#if PJ_HAS_TCP
+// The head of a RTP packet is stored in a 16 bits header, so the max size of a
+// packet is 65536
+#define MAX_RTP_SIZE 65536
+#endif
+
+// TODO (sblin) The incoming socks are a bit HACKY for now.
+// Need a better approach
+typedef struct outgoing_sock {
+    pj_sock_t       fd;
+    pj_activesock_t *sock;
+    pj_sockaddr_t   *addr;
+} outgoing_sock;
+
+typedef struct incoming_sock {
+    pj_sock_t       fd;
+    pj_activesock_t *sock;
+    pj_sockaddr     addr;
+    int             addr_len;
+} incoming_sock;
+
+typedef struct rx_buf {
+    pj_activesock_t *asock;
+    pj_uint8_t      rx_buffer[MAX_RTP_SIZE];
+    pj_uint16_t     rx_buffer_size;
+    pj_uint16_t     rx_wanted_size;
+    struct          rx_buf *next;
+    struct          rx_buf *prev;
+} rx_buf;
+
 struct pj_stun_sock
 {
     char		*obj_name;	/* Log identification	    */
@@ -47,6 +77,8 @@ struct pj_stun_sock
     void		*user_data;	/* Application user data    */
     pj_bool_t		 is_destroying; /* Destroy already called   */
     int			 af;		/* Address family	    */
+    pj_stun_tp_type	 conn_type;
+    pj_stun_sock_cfg	 setting;
     pj_stun_config	 stun_cfg;	/* STUN config (ioqueue etc)*/
     pj_stun_sock_cb	 cb;		/* Application callbacks    */
 
@@ -59,6 +91,13 @@ struct pj_stun_sock
     pj_dns_srv_async_query *q;		/* Pending DNS query	    */
     pj_sock_t		 sock_fd;	/* Socket descriptor	    */
     pj_activesock_t	*active_sock;	/* Active socket object	    */
+#if PJ_HAS_TCP
+    int	 outgoing_nb;
+    outgoing_sock	 outgoing_socks[PJ_ICE_MAX_CHECKS];
+    int	 incoming_nb;
+    incoming_sock	 incoming_socks[PJ_ICE_MAX_CHECKS];
+    rx_buf		*rx_buffers;
+#endif
     pj_ioqueue_op_key_t	 send_key;	/* Default send key for app */
     pj_ioqueue_op_key_t	 int_send_key;	/* Send key for internal    */
     pj_status_t		 last_err;	/* Last error status	    */
@@ -71,6 +110,12 @@ struct pj_stun_sock
 /* 
  * Prototypes for static functions 
  */
+static pj_bool_t on_stun_sock_ready(pj_activesock_t *asock, pj_status_t status);
+static pj_bool_t on_stun_sock_accept(pj_activesock_t *asock,
+                                     pj_sock_t newsock,
+                                     const pj_sockaddr_t *src_addr,
+                                     int src_addr_len);
+static pj_bool_t on_connect_complete(pj_activesock_t *asock, pj_status_t status);
 
 /* Destructor for group lock */
 static void stun_sock_destructor(void *obj);
@@ -83,6 +128,10 @@ static pj_status_t sess_on_send_msg(pj_stun_session *sess,
 				    const pj_sockaddr_t *dst_addr,
 				    unsigned addr_len);
 
+static pj_bool_t sess_fail(pj_stun_sock *stun_sock,
+                           pj_stun_sock_op op,
+                           pj_status_t status);
+
 /* This callback is called by the STUN session when outgoing transaction 
  * is complete
  */
@@ -122,6 +171,15 @@ static void ka_timer_cb(pj_timer_heap_t *th, pj_timer_entry *te);
 
 #define INTERNAL_MSG_TOKEN  (void*)(pj_ssize_t)1
 
+//////////////////////////////////////////////////////////////////////////////
+
+static pj_uint16_t GETVAL16H(const pj_uint8_t *buf, unsigned pos)
+{
+    return (pj_uint16_t) ((buf[pos + 0] << 8) | \
+                          (buf[pos + 1] << 0));
+}
+
+//////////////////////////////////////////////////////////////////////////////
 
 /*
  * Retrieve the name representing the specified operation.
@@ -160,36 +218,211 @@ static pj_bool_t pj_stun_sock_cfg_is_valid(const pj_stun_sock_cfg *cfg)
     return cfg->max_pkt_size > 1 && cfg->async_cnt >= 1;
 }
 
+/*
+ * Initialize.
+ */
+PJ_DEF(pj_status_t) pj_stun_sock_alloc(pj_stun_sock *stun_sock)
+{
+    pj_status_t status;
+    pj_sockaddr bound_addr;
+    pj_uint16_t max_bind_retry;
+    int         sock_type;
+
+    pj_grp_lock_acquire(stun_sock->grp_lock);
+
+    if (stun_sock->conn_type == PJ_STUN_TP_UDP)
+        sock_type = pj_SOCK_DGRAM();
+    else
+        sock_type = pj_SOCK_STREAM();
+
+    stun_sock->ka_interval = stun_sock->setting.ka_interval;
+    if (stun_sock->ka_interval == 0)
+        stun_sock->ka_interval = PJ_STUN_KEEP_ALIVE_SEC;
+    /* Create socket and bind socket */
+    status = pj_sock_socket(stun_sock->af, sock_type, 0, &stun_sock->sock_fd);
+    if (status != PJ_SUCCESS) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Apply QoS, if specified */
+    status = pj_sock_apply_qos2(stun_sock->sock_fd, stun_sock->setting.qos_type,
+                                &stun_sock->setting.qos_params, 2,
+                                stun_sock->obj_name, NULL);
+    if (status != PJ_SUCCESS && !stun_sock->setting.qos_ignore_error) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Apply socket buffer size */
+    if (stun_sock->setting.so_rcvbuf_size > 0) {
+        unsigned sobuf_size = stun_sock->setting.so_rcvbuf_size;
+        status = pj_sock_setsockopt_sobuf(stun_sock->sock_fd, pj_SO_RCVBUF(),
+                                          PJ_TRUE, &sobuf_size);
+        if (status != PJ_SUCCESS) {
+            pj_perror(3, stun_sock->obj_name, status, "Failed setting SO_RCVBUF");
+        } else {
+            if (sobuf_size < stun_sock->setting.so_rcvbuf_size) {
+                PJ_LOG(4, (stun_sock->obj_name,
+                           "Warning! Cannot set SO_RCVBUF as configured, "
+                           "now=%d, configured=%d",
+                           sobuf_size, stun_sock->setting.so_rcvbuf_size));
+            } else {
+                PJ_LOG(5, (stun_sock->obj_name, "SO_RCVBUF set to %d", sobuf_size));
+            }
+        }
+    }
+    if (stun_sock->setting.so_sndbuf_size > 0) {
+        unsigned sobuf_size = stun_sock->setting.so_sndbuf_size;
+        status = pj_sock_setsockopt_sobuf(stun_sock->sock_fd, pj_SO_SNDBUF(),
+                                          PJ_TRUE, &sobuf_size);
+        if (status != PJ_SUCCESS) {
+            pj_perror(3, stun_sock->obj_name, status, "Failed setting SO_SNDBUF");
+        } else {
+            if (sobuf_size < stun_sock->setting.so_sndbuf_size) {
+                PJ_LOG(4, (stun_sock->obj_name,
+                           "Warning! Cannot set SO_SNDBUF as configured, "
+                           "now=%d, configured=%d",
+                           sobuf_size, stun_sock->setting.so_sndbuf_size));
+            } else {
+                PJ_LOG(5, (stun_sock->obj_name, "SO_SNDBUF set to %d", sobuf_size));
+            }
+        }
+    }
+
+    /* Bind socket */
+    max_bind_retry = MAX_BIND_RETRY;
+    if (stun_sock->setting.port_range &&
+        stun_sock->setting.port_range < max_bind_retry)
+        max_bind_retry = stun_sock->setting.port_range;
+
+    pj_sockaddr_init(stun_sock->af, &bound_addr, NULL, 0);
+    if (stun_sock->setting.bound_addr.addr.sa_family == pj_AF_INET() ||
+        stun_sock->setting.bound_addr.addr.sa_family == pj_AF_INET6())
+    {
+        pj_sockaddr_cp(&bound_addr, &stun_sock->setting.bound_addr);
+    }
+
+    status = pj_sock_bind_random(stun_sock->sock_fd, &bound_addr,
+                                 stun_sock->setting.port_range, max_bind_retry);
+    if (status != PJ_SUCCESS) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Init active socket configuration */
+    {
+        pj_activesock_cfg activesock_cfg;
+        pj_activesock_cb activesock_cb;
+
+        pj_activesock_cfg_default(&activesock_cfg);
+        activesock_cfg.grp_lock    = stun_sock->grp_lock;
+        activesock_cfg.async_cnt   = stun_sock->setting.async_cnt;
+        activesock_cfg.concurrency = 0;
+
+        /* Create the active socket */
+        pj_bzero(&activesock_cb, sizeof(activesock_cb));
+        activesock_cb.on_data_sent     = &on_data_sent;
+        activesock_cb.on_data_recvfrom = &on_data_recvfrom;
+
+#if PJ_HAS_TCP
+        if (stun_sock->conn_type != PJ_STUN_TP_UDP) {
+            activesock_cb.on_accept_complete = &on_stun_sock_accept;
+            // Will be ready to accept incoming connections from the external world
+            status = pj_sock_listen(stun_sock->sock_fd, PJ_SOMAXCONN);
+            if (status != PJ_SUCCESS) {
+                pj_stun_sock_destroy(stun_sock);
+                pj_grp_lock_release(stun_sock->grp_lock);
+                return status;
+            }
+        } else {
+            activesock_cb.on_connect_complete = &on_stun_sock_ready;
+        }
+#else
+        activesock_cb.on_connect_complete = &on_stun_sock_ready;
+#endif
+
+        status = pj_activesock_create(stun_sock->pool, stun_sock->sock_fd,
+                                      sock_type, &activesock_cfg,
+                                      stun_sock->stun_cfg.ioqueue,
+                                      &activesock_cb, stun_sock,
+                                      &stun_sock->active_sock);
+        if (status != PJ_SUCCESS) {
+            pj_stun_sock_destroy(stun_sock);
+            pj_grp_lock_release(stun_sock->grp_lock);
+            return status;
+        }
+
+#if PJ_HAS_TCP
+        if (stun_sock->conn_type != PJ_STUN_TP_UDP) {
+            status = pj_activesock_start_accept(stun_sock->active_sock,
+                                                stun_sock->pool);
+        } else {
+            status = PJ_SUCCESS;
+        }
+        if (status == PJ_SUCCESS) {
+            on_stun_sock_ready(stun_sock->active_sock, PJ_SUCCESS);
+        } else if (status != PJ_EPENDING) {
+            char addrinfo[PJ_INET6_ADDRSTRLEN + 10];
+            pj_perror(3, stun_sock->pool->obj_name, status, "Failed to connect to %s",
+                      pj_sockaddr_print(&bound_addr, addrinfo, sizeof(addrinfo), 3));
+            pj_stun_sock_destroy(stun_sock);
+            pj_grp_lock_release(stun_sock->grp_lock);
+            return status;
+        }
+#else
+        on_stun_sock_ready(stun_sock->active_sock, PJ_SUCCESS);
+#endif
+    }
+
+    pj_grp_lock_release(stun_sock->grp_lock);
+    return status;
+}
+
 /*
  * Create the STUN transport using the specified configuration.
  */
 PJ_DEF(pj_status_t) pj_stun_sock_create( pj_stun_config *stun_cfg,
-					 const char *name,
-					 int af,
-					 const pj_stun_sock_cb *cb,
-					 const pj_stun_sock_cfg *cfg,
-					 void *user_data,
-					 pj_stun_sock **p_stun_sock)
+                                         const char *name,
+                                         int af,
+                                         pj_stun_tp_type conn_type,
+                                         const pj_stun_sock_cb *cb,
+                                         const pj_stun_sock_cfg *cfg,
+                                         void *user_data,
+                                         pj_stun_sock **p_stun_sock)
 {
     pj_pool_t *pool;
     pj_stun_sock *stun_sock;
     pj_stun_sock_cfg default_cfg;
-    pj_sockaddr bound_addr;
-    unsigned i;
-    pj_uint16_t max_bind_retry;
     pj_status_t status;
 
     PJ_ASSERT_RETURN(stun_cfg && cb && p_stun_sock, PJ_EINVAL);
     PJ_ASSERT_RETURN(af==pj_AF_INET()||af==pj_AF_INET6(), PJ_EAFNOTSUP);
     PJ_ASSERT_RETURN(!cfg || pj_stun_sock_cfg_is_valid(cfg), PJ_EINVAL);
     PJ_ASSERT_RETURN(cb->on_status, PJ_EINVAL);
+    PJ_ASSERT_RETURN(conn_type != PJ_STUN_TP_TCP || PJ_HAS_TCP, PJ_EINVAL);
 
     status = pj_stun_config_check_valid(stun_cfg);
     if (status != PJ_SUCCESS)
 	return status;
 
-    if (name == NULL)
-	name = "stuntp%p";
+    if (name == NULL) {
+        switch (conn_type) {
+        case PJ_STUN_TP_UDP:
+            name = "udpstun%p";
+            break;
+        case PJ_STUN_TP_TCP:
+            name = "tcpstun%p";
+            break;
+        default:
+            PJ_ASSERT_RETURN(!"Invalid STUN conn_type", PJ_EINVAL);
+            name = "tcpstun%p";
+            break;
+        }
+    }
 
     if (cfg == NULL) {
 	pj_stun_sock_cfg_default(&default_cfg);
@@ -198,15 +431,22 @@ PJ_DEF(pj_status_t) pj_stun_sock_create( pj_stun_config *stun_cfg,
 
 
     /* Create structure */
-    pool = pj_pool_create(stun_cfg->pf, name, 256, 512, NULL);
-    stun_sock = PJ_POOL_ZALLOC_T(pool, pj_stun_sock);
-    stun_sock->pool = pool;
-    stun_sock->obj_name = pool->obj_name;
-    stun_sock->user_data = user_data;
-    stun_sock->af = af;
-    stun_sock->sock_fd = PJ_INVALID_SOCKET;
+    pool                   = pj_pool_create(stun_cfg->pf, name, 256, 512, NULL);
+    stun_sock              = PJ_POOL_ZALLOC_T(pool, pj_stun_sock);
+    stun_sock->pool        = pool;
+    stun_sock->obj_name    = pool->obj_name;
+    stun_sock->user_data   = user_data;
+    stun_sock->af          = af;
+    stun_sock->conn_type   = conn_type;
+    stun_sock->sock_fd     = PJ_INVALID_SOCKET;
+#if PJ_HAS_TCP
+    stun_sock->outgoing_nb = -1;
+    stun_sock->incoming_nb = -1;
+#endif
     pj_memcpy(&stun_sock->stun_cfg, stun_cfg, sizeof(*stun_cfg));
     pj_memcpy(&stun_sock->cb, cb, sizeof(*cb));
+    /* Copy setting (QoS parameters etc */
+    pj_memcpy(&stun_sock->stun_cfg, cfg, sizeof(*cfg));
 
     stun_sock->ka_interval = cfg->ka_interval;
     if (stun_sock->ka_interval == 0)
@@ -226,141 +466,67 @@ PJ_DEF(pj_status_t) pj_stun_sock_create( pj_stun_config *stun_cfg,
     pj_grp_lock_add_handler(stun_sock->grp_lock, pool, stun_sock,
 			    &stun_sock_destructor);
 
-    /* Create socket and bind socket */
-    status = pj_sock_socket(af, pj_SOCK_DGRAM(), 0, &stun_sock->sock_fd);
-    if (status != PJ_SUCCESS)
-	goto on_error;
-
-    /* Apply QoS, if specified */
-    status = pj_sock_apply_qos2(stun_sock->sock_fd, cfg->qos_type,
-				&cfg->qos_params, 2, stun_sock->obj_name,
-				NULL);
-    if (status != PJ_SUCCESS && !cfg->qos_ignore_error)
-	goto on_error;
-
-    /* Apply socket buffer size */
-    if (cfg->so_rcvbuf_size > 0) {
-	unsigned sobuf_size = cfg->so_rcvbuf_size;
-	status = pj_sock_setsockopt_sobuf(stun_sock->sock_fd, pj_SO_RCVBUF(),
-					  PJ_TRUE, &sobuf_size);
-	if (status != PJ_SUCCESS) {
-	    PJ_PERROR(3, (stun_sock->obj_name, status,
-			  "Failed setting SO_RCVBUF"));
-	} else {
-	    if (sobuf_size < cfg->so_rcvbuf_size) {
-		PJ_LOG(4, (stun_sock->obj_name, 
-			   "Warning! Cannot set SO_RCVBUF as configured, "
-			   "now=%d, configured=%d",
-			   sobuf_size, cfg->so_rcvbuf_size));
-	    } else {
-		PJ_LOG(5, (stun_sock->obj_name, "SO_RCVBUF set to %d",
-			   sobuf_size));
-	    }
-	}
-    }
-    if (cfg->so_sndbuf_size > 0) {
-	unsigned sobuf_size = cfg->so_sndbuf_size;
-	status = pj_sock_setsockopt_sobuf(stun_sock->sock_fd, pj_SO_SNDBUF(),
-					  PJ_TRUE, &sobuf_size);
-	if (status != PJ_SUCCESS) {
-	    PJ_PERROR(3, (stun_sock->obj_name, status,
-			  "Failed setting SO_SNDBUF"));
-	} else {
-	    if (sobuf_size < cfg->so_sndbuf_size) {
-		PJ_LOG(4, (stun_sock->obj_name, 
-			   "Warning! Cannot set SO_SNDBUF as configured, "
-			   "now=%d, configured=%d",
-			   sobuf_size, cfg->so_sndbuf_size));
-	    } else {
-		PJ_LOG(5, (stun_sock->obj_name, "SO_SNDBUF set to %d",
-			   sobuf_size));
-	    }
-	}
-    }
-
-    /* Bind socket */
-    max_bind_retry = MAX_BIND_RETRY;
-    if (cfg->port_range && cfg->port_range < max_bind_retry)
-	max_bind_retry = cfg->port_range;
-    pj_sockaddr_init(af, &bound_addr, NULL, 0);
-    if (cfg->bound_addr.addr.sa_family == pj_AF_INET() || 
-	cfg->bound_addr.addr.sa_family == pj_AF_INET6())
-    {
-	pj_sockaddr_cp(&bound_addr, &cfg->bound_addr);
-    }
-    status = pj_sock_bind_random(stun_sock->sock_fd, &bound_addr,
-				 cfg->port_range, max_bind_retry);
-    if (status != PJ_SUCCESS)
-	goto on_error;
-
-    /* Create more useful information string about this transport */
-#if 0
-    {
-	pj_sockaddr bound_addr;
-	int addr_len = sizeof(bound_addr);
-
-	status = pj_sock_getsockname(stun_sock->sock_fd, &bound_addr, 
-				     &addr_len);
-	if (status != PJ_SUCCESS)
-	    goto on_error;
-
-	stun_sock->info = pj_pool_alloc(pool, PJ_INET6_ADDRSTRLEN+10);
-	pj_sockaddr_print(&bound_addr, stun_sock->info, 
-			  PJ_INET6_ADDRSTRLEN, 3);
-    }
-#endif
-
-    /* Init active socket configuration */
-    {
-	pj_activesock_cfg activesock_cfg;
-	pj_activesock_cb activesock_cb;
-
-	pj_activesock_cfg_default(&activesock_cfg);
-	activesock_cfg.grp_lock = stun_sock->grp_lock;
-	activesock_cfg.async_cnt = cfg->async_cnt;
-	activesock_cfg.concurrency = 0;
-
-	/* Create the active socket */
-	pj_bzero(&activesock_cb, sizeof(activesock_cb));
-	activesock_cb.on_data_recvfrom = &on_data_recvfrom;
-	activesock_cb.on_data_sent = &on_data_sent;
-	status = pj_activesock_create(pool, stun_sock->sock_fd, 
-				      pj_SOCK_DGRAM(), 
-				      &activesock_cfg, stun_cfg->ioqueue,
-				      &activesock_cb, stun_sock,
-				      &stun_sock->active_sock);
-	if (status != PJ_SUCCESS)
-	    goto on_error;
-
-	/* Start asynchronous read operations */
-	status = pj_activesock_start_recvfrom(stun_sock->active_sock, pool,
-					      cfg->max_pkt_size, 0);
-	if (status != PJ_SUCCESS)
-	    goto on_error;
-
-	/* Init send keys */
-	pj_ioqueue_op_key_init(&stun_sock->send_key, 
-			       sizeof(stun_sock->send_key));
-	pj_ioqueue_op_key_init(&stun_sock->int_send_key,
-			       sizeof(stun_sock->int_send_key));
-    }
-
     /* Create STUN session */
     {
-	pj_stun_session_cb sess_cb;
-
-	pj_bzero(&sess_cb, sizeof(sess_cb));
-	sess_cb.on_request_complete = &sess_on_request_complete;
-	sess_cb.on_send_msg = &sess_on_send_msg;
-	status = pj_stun_session_create(&stun_sock->stun_cfg, 
-					stun_sock->obj_name,
-					&sess_cb, PJ_FALSE, 
-					stun_sock->grp_lock,
-					&stun_sock->stun_sess);
-	if (status != PJ_SUCCESS)
-	    goto on_error;
+        pj_stun_session_cb sess_cb;
+
+        pj_bzero(&sess_cb, sizeof(sess_cb));
+        sess_cb.on_request_complete = &sess_on_request_complete;
+        sess_cb.on_send_msg = &sess_on_send_msg;
+        status = pj_stun_session_create(&stun_sock->stun_cfg,
+                                        stun_sock->obj_name,
+                                        &sess_cb, PJ_FALSE, stun_sock->grp_lock,
+                                        &stun_sock->stun_sess, conn_type);
+        if (status != PJ_SUCCESS) {
+            pj_stun_sock_destroy(stun_sock);
+            return status;
+        }
     }
 
+    pj_stun_sock_alloc(stun_sock);
+
+    /* Done */
+    *p_stun_sock = stun_sock;
+    return PJ_SUCCESS;
+}
+
+/*
+ * Notification when outgoing TCP socket has been connected.
+ */
+static pj_bool_t on_stun_sock_ready(pj_activesock_t *asock, pj_status_t status)
+{
+    pj_stun_sock *stun_sock;
+    stun_sock = (pj_stun_sock *)pj_activesock_get_user_data(asock);
+    if (!stun_sock)
+        return PJ_FALSE;
+
+    pj_grp_lock_acquire(stun_sock->grp_lock);
+
+    /* TURN session may have already been destroyed here.
+     * See ticket #1557 (http://trac.pjsip.org/repos/ticket/1557).
+     */
+    if (!stun_sock->stun_sess) {
+        sess_fail(stun_sock, PJ_STUN_SESS_DESTROYED, status);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return PJ_FALSE;
+    }
+
+    if (status != PJ_SUCCESS) {
+        sess_fail(stun_sock, PJ_STUN_TCP_CONNECT_ERROR, status);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return PJ_FALSE;
+    }
+
+    if (stun_sock->conn_type != PJ_STUN_TP_UDP)
+        PJ_LOG(5,(stun_sock->obj_name, "TCP connected"));
+
+    /* Start asynchronous read operations */
+    pj_status_t result;
+    result = pj_activesock_start_recvfrom(asock, stun_sock->pool,
+                                          stun_sock->setting.max_pkt_size, 0);
+    if (result != PJ_SUCCESS)
+        return PJ_FALSE;
+
     /* Associate us with the STUN session */
     pj_stun_session_set_user_data(stun_sock->stun_sess, stun_sock);
 
@@ -369,30 +535,310 @@ PJ_DEF(pj_status_t) pj_stun_sock_create( pj_stun_config *stun_cfg,
      * STUN messages we sent with STUN messages that the application sends.
      * The last 16bit value in the array is a counter.
      */
-    for (i=0; i<PJ_ARRAY_SIZE(stun_sock->tsx_id); ++i) {
-	stun_sock->tsx_id[i] = (pj_uint16_t) pj_rand();
-    }
+    unsigned i;
+    for (i=0; i<PJ_ARRAY_SIZE(stun_sock->tsx_id); ++i)
+        stun_sock->tsx_id[i] = (pj_uint16_t) pj_rand();
+    /* FIXME: no magic numbers please */
     stun_sock->tsx_id[5] = 0;
 
-
     /* Init timer entry */
-    stun_sock->ka_timer.cb = &ka_timer_cb;
+    stun_sock->ka_timer.cb        = &ka_timer_cb;
     stun_sock->ka_timer.user_data = stun_sock;
 
-    /* Done */
-    *p_stun_sock = stun_sock;
-    return PJ_SUCCESS;
+    if (status != PJ_SUCCESS) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
 
-on_error:
-    pj_stun_sock_destroy(stun_sock);
-    return status;
+    /* Init send keys */
+    pj_ioqueue_op_key_init(&stun_sock->send_key, sizeof(stun_sock->send_key));
+    pj_ioqueue_op_key_init(&stun_sock->int_send_key,
+                           sizeof(stun_sock->int_send_key));
+
+    pj_grp_lock_release(stun_sock->grp_lock);
+    return PJ_TRUE;
+}
+
+static pj_bool_t parse_rx_packet(pj_activesock_t *asock,
+                                 void *data,
+                                 pj_size_t size,
+                                 const pj_sockaddr_t *rx_addr,
+                                 unsigned sock_addr_len)
+{
+
+    pj_stun_sock *stun_sock = (pj_stun_sock*) pj_activesock_get_user_data(asock);
+    if (!stun_sock)
+        return PJ_FALSE;
+
+    pj_grp_lock_acquire(stun_sock->grp_lock);
+    pj_uint16_t parsed = 0;
+    pj_status_t result = PJ_TRUE;
+    pj_status_t status;
+
+#if PJ_HAS_TCP
+    // Search current rx_buf
+    rx_buf* buf           = NULL;
+    rx_buf* stun_sock_buf = stun_sock->rx_buffers;
+    while (stun_sock_buf) {
+        if (stun_sock_buf->asock == asock) {
+            buf = stun_sock_buf;
+            break;
+        }
+        stun_sock_buf = stun_sock_buf->next;
+    }
+    if (!buf) {
+        // Create rx_buf, this buf will be released when the pool is released
+        buf = (rx_buf*)pj_pool_calloc(stun_sock->pool, 1, sizeof(rx_buf));
+        if (!buf) {
+            PJ_LOG(5, (stun_sock->obj_name, "Cannot allocate memory for rx_buf"));
+            status = pj_grp_lock_release(stun_sock->grp_lock);
+            return PJ_FALSE;
+        }
+        buf->asock = asock;
+        buf->next = stun_sock->rx_buffers;
+        if (stun_sock->rx_buffers)
+            stun_sock->rx_buffers->prev = buf;
+        stun_sock->rx_buffers = buf;
+    }
+#endif
+
+    do {
+        pj_uint16_t leftover = size - parsed;
+        pj_uint8_t *current_packet = ((pj_uint8_t *)(data)) + parsed;
+
+#if PJ_HAS_TCP
+        if (stun_sock->conn_type != PJ_STUN_TP_UDP) {
+            /* RFC6544, the packet is wrapped into a packet following the RFC4571 */
+            pj_bool_t store_remaining = PJ_TRUE;
+            if (buf->rx_buffer_size != 0 || buf->rx_wanted_size != 0) {
+                if (buf->rx_buffer_size == 1) {
+                    leftover = (pj_uint16_t) ((buf->rx_buffer[0] << 8) | \
+                                              (current_packet[0] << 0));
+
+                    buf->rx_buffer_size--;
+                    current_packet++;
+                    parsed++;
+
+                    if (leftover + parsed <= size) {
+                        store_remaining  = PJ_FALSE;
+                        parsed          += leftover;
+                    } else {
+                        buf->rx_wanted_size = leftover;
+                    }
+
+                } else if (leftover + buf->rx_buffer_size >= buf->rx_wanted_size) {
+                    // We have enough data Build new packet to parse
+                    store_remaining = PJ_FALSE;
+                    pj_uint16_t eaten_bytes = buf->rx_wanted_size - buf->rx_buffer_size;
+                    memcpy(buf->rx_buffer + buf->rx_buffer_size,
+                           current_packet, eaten_bytes);
+
+                    leftover        = buf->rx_wanted_size;
+                    current_packet  = buf->rx_buffer;
+                    parsed         += eaten_bytes;
+
+                    buf->rx_buffer_size  = 0;
+                    buf->rx_wanted_size  = 0;
+                }
+            } else if (leftover > 1) {
+                leftover        = GETVAL16H(current_packet, 0);
+                current_packet += 2;
+                parsed         += 2;
+                if (leftover + parsed <= size) {
+                    store_remaining  = PJ_FALSE;
+                    parsed          += leftover;
+                } else {
+                    buf->rx_wanted_size = leftover;
+                }
+            }
+            if (store_remaining) {
+                leftover = size - parsed;
+                memcpy(buf->rx_buffer + buf->rx_buffer_size,
+                       current_packet, leftover);
+                buf->rx_buffer_size += leftover;
+                break;
+            }
+        } else {
+#endif
+            parsed = size;
+#if PJ_HAS_TCP
+        }
+#endif
+        /* Check that this is STUN message */
+        status = pj_stun_msg_check((const pj_uint8_t *)current_packet, leftover,
+                                   PJ_STUN_IS_DATAGRAM | PJ_STUN_CHECK_PACKET);
+        if (status != PJ_SUCCESS) {
+            /* Not STUN -- give it to application */
+            goto process_app_data;
+        }
+
+        /* Treat packet as STUN header and copy the STUN message type.
+         * We don't want to access the type directly from the header
+         * since it may not be properly aligned.
+         */
+        pj_stun_msg_hdr *hdr = (pj_stun_msg_hdr *)current_packet;
+        pj_uint16_t type;
+        pj_memcpy(&type, &hdr->type, 2);
+        type = pj_ntohs(type);
+
+        /* If the packet is a STUN Binding response and part of the
+         * transaction ID matches our internal ID, then this is
+         * our internal STUN message (Binding request or keep alive).
+         * Give it to our STUN session.
+         */
+        if (!PJ_STUN_IS_RESPONSE(type) ||
+            PJ_STUN_GET_METHOD(type) != PJ_STUN_BINDING_METHOD ||
+            pj_memcmp(hdr->tsx_id, stun_sock->tsx_id, 10) != 0)
+        {
+            /* Not STUN Binding response, or STUN transaction ID mismatch.
+             * This is not our message too -- give it to application.
+             */
+            goto process_app_data;
+        }
+
+        /* This is our STUN Binding response. Give it to the STUN session */
+        status = pj_stun_session_on_rx_pkt(stun_sock->stun_sess, current_packet,
+                                           leftover, PJ_STUN_IS_DATAGRAM, NULL,
+                                           NULL, rx_addr, sock_addr_len);
+
+        result &= status != PJ_EGONE ? PJ_TRUE : PJ_FALSE;
+        continue;
+
+process_app_data:
+        if (stun_sock->cb.on_rx_data)
+            (*stun_sock->cb.on_rx_data)(stun_sock, current_packet,
+                                        (unsigned)leftover, rx_addr, sock_addr_len);
+
+        result &= status != PJ_EGONE ? PJ_TRUE : PJ_FALSE;
+    } while (parsed < size && result);
+
+    status = pj_grp_lock_release(stun_sock->grp_lock);
+    return result;
+}
+
+static pj_bool_t on_data_read(pj_activesock_t *asock,
+                              void *data,
+                              pj_size_t size,
+                              pj_status_t status,
+                              pj_size_t *remainder)
+{
+
+    pj_stun_sock *stun_sock;
+
+    if (!(stun_sock = (pj_stun_sock *)pj_activesock_get_user_data(asock)))
+        return PJ_FALSE;
+
+    pj_stun_session_cb *cb = pj_stun_session_callback(stun_sock->stun_sess);
+    /* Log socket error or disconnection */
+    if (status != PJ_SUCCESS) {
+        if (stun_sock->conn_type == PJ_STUN_TP_UDP
+            || (status != PJ_EEOF && status != 120104 && status != 130054))
+        {
+            PJ_PERROR(2, (stun_sock->obj_name, status, "read() error"));
+        } else if (status == 120104
+                   || status == 130054 /* RESET BY PEER */)
+        {
+            for (int i = 0; i <= stun_sock->outgoing_nb; ++i)
+                if (stun_sock->outgoing_socks[i].sock == asock
+                    && cb
+                    && (cb->on_peer_reset_connection))
+                {
+                    (cb->on_peer_reset_connection)(stun_sock->stun_sess,
+                                                   stun_sock->outgoing_socks[i].addr);
+                }
+        }
+        return PJ_FALSE;
+    }
+#if PJ_HAS_TCP
+    pj_sockaddr_t *rx_addr = NULL;
+    unsigned sock_addr_len = 0;
+    for (int i = 0; i <= stun_sock->outgoing_nb; ++i)
+        if (stun_sock->outgoing_socks[i].sock == asock) {
+            rx_addr       = stun_sock->outgoing_socks[i].addr;
+            sock_addr_len = pj_sockaddr_get_len(rx_addr);
+            if (cb && (cb->on_peer_packet))
+                (cb->on_peer_packet)(stun_sock->stun_sess,
+                                     stun_sock->outgoing_socks[i].addr);
+        }
+
+    if (rx_addr == NULL && stun_sock->incoming_nb != -1) {
+        // It's an incoming message
+        for (int i = 0; i <= stun_sock->incoming_nb; ++i)
+            if (stun_sock->incoming_socks[i].sock == asock) {
+                rx_addr       = &stun_sock->incoming_socks[i].addr;
+                sock_addr_len = stun_sock->incoming_socks[i].addr_len;
+            }
+    }
+    return parse_rx_packet(asock, data, size, rx_addr, sock_addr_len);
+#else
+    pj_grp_lock_release(stun_sock->grp_lock);
+    return PJ_FALSE;
+#endif
+}
+
+#if PJ_HAS_TCP
+/*
+ * Notification when incoming TCP socket has been connected.
+ * NOTE: cf https://www.pjsip.org/docs/latest/pjlib/docs/html//structpj__activesock__cb.htm if status needed
+ */
+static pj_bool_t on_stun_sock_accept(pj_activesock_t *active_sock,
+                                     pj_sock_t sock,
+                                     const pj_sockaddr_t *src_addr,
+                                     int src_addr_len)
+{
+    pj_status_t  status;
+    pj_stun_sock *stun_sock;
+    int sock_type = pj_SOCK_STREAM();
+    stun_sock     = (pj_stun_sock *)pj_activesock_get_user_data(active_sock);
+
+    stun_sock->incoming_nb += 1;
+    int nb_check            = stun_sock->incoming_nb;
+    pj_sock_t *fd           = &stun_sock->incoming_socks[nb_check].fd;
+    pj_activesock_t **asock = &stun_sock->incoming_socks[nb_check].sock;
+
+    pj_sockaddr_cp(&stun_sock->incoming_socks[nb_check].addr, src_addr);
+    stun_sock->incoming_socks[nb_check].addr_len = src_addr_len;
+    *fd = sock;
+
+    pj_activesock_cfg activesock_cfg;
+    pj_activesock_cb activesock_cb;
+
+    pj_activesock_cfg_default(&activesock_cfg);
+    activesock_cfg.grp_lock    = stun_sock->grp_lock;
+    activesock_cfg.async_cnt   = stun_sock->setting.async_cnt;
+    activesock_cfg.concurrency = 0;
+
+    /* Create the active socket */
+    pj_bzero(&activesock_cb, sizeof(activesock_cb));
+    activesock_cb.on_data_read = &on_data_read;
+    activesock_cb.on_data_sent = &on_data_sent;
+
+    status = pj_activesock_create(stun_sock->pool, *fd, sock_type,
+                                  &activesock_cfg, stun_sock->stun_cfg.ioqueue,
+                                  &activesock_cb, stun_sock, asock);
+    if (status != PJ_SUCCESS) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Start asynchronous read operations */
+    pj_status_t result;
+    result = pj_activesock_start_read(*asock, stun_sock->pool,
+                                      stun_sock->setting.max_pkt_size, 0);
+    if (result != PJ_SUCCESS)
+        return PJ_FALSE;
+
+    return PJ_TRUE;
 }
+#endif
 
 /* Start socket. */
-PJ_DEF(pj_status_t) pj_stun_sock_start( pj_stun_sock *stun_sock,
-				        const pj_str_t *domain,
-				        pj_uint16_t default_port,
-				        pj_dns_resolver *resolver)
+PJ_DEF(pj_status_t) pj_stun_sock_start(pj_stun_sock *stun_sock,
+                                       const pj_str_t *domain,
+                                       pj_uint16_t default_port,
+                                       pj_dns_resolver *resolver)
 {
     pj_status_t status;
 
@@ -402,11 +848,10 @@ PJ_DEF(pj_status_t) pj_stun_sock_start( pj_stun_sock *stun_sock,
 
     /* Check whether the domain contains IP address */
     stun_sock->srv_addr.addr.sa_family = (pj_uint16_t)stun_sock->af;
-    status = pj_inet_pton(stun_sock->af, domain, 
-			  pj_sockaddr_get_addr(&stun_sock->srv_addr));
-    if (status != PJ_SUCCESS) {
+    status = pj_inet_pton(stun_sock->af, domain,
+                          pj_sockaddr_get_addr(&stun_sock->srv_addr));
+    if (status != PJ_SUCCESS)
 	stun_sock->srv_addr.addr.sa_family = (pj_uint16_t)0;
-    }
 
     /* If resolver is set, try to resolve with DNS SRV first. It
      * will fallback to DNS A/AAAA when no SRV record is found.
@@ -424,9 +869,9 @@ PJ_DEF(pj_status_t) pj_stun_sock_start( pj_stun_sock *stun_sock,
 	    opt = PJ_DNS_SRV_FALLBACK_A;
 
 	stun_sock->last_err = PJ_SUCCESS;
-	status = pj_dns_srv_resolve(domain, &res_name, default_port, 
-				    stun_sock->pool, resolver, opt,
-				    stun_sock, &dns_srv_resolver_cb, 
+	status = pj_dns_srv_resolve(domain, &res_name, default_port,
+	                            stun_sock->pool, resolver, opt,
+				    stun_sock, &dns_srv_resolver_cb,
 				    &stun_sock->q);
 	if (status != PJ_SUCCESS) {
 	    PJ_PERROR(4,(stun_sock->obj_name, status,
@@ -439,8 +884,8 @@ PJ_DEF(pj_status_t) pj_stun_sock_start( pj_stun_sock *stun_sock,
 	     */
 	    status = stun_sock->last_err;
 	    if (stun_sock->last_err != PJ_SUCCESS) {
-	    	PJ_PERROR(4,(stun_sock->obj_name, status,
-			     "Failed in sending Binding request (2)"));
+	        PJ_PERROR(4,(stun_sock->obj_name, status,
+	                     "Failed in sending Binding request (2)"));
 	    }
 	}
 
@@ -526,17 +971,35 @@ PJ_DEF(pj_status_t) pj_stun_sock_destroy(pj_stun_sock *stun_sock)
 	stun_sock->sock_fd = PJ_INVALID_SOCKET;
     }
 
-    if (stun_sock->stun_sess) {
+    for (int i = 0; i < stun_sock->incoming_nb ; ++i)
+        if (stun_sock->incoming_socks[i].sock != NULL) {
+            stun_sock->incoming_socks[i].fd = PJ_INVALID_SOCKET;
+            pj_activesock_close(stun_sock->incoming_socks[i].sock);
+        } else if (stun_sock->incoming_socks[i].fd != PJ_INVALID_SOCKET) {
+            pj_sock_close(stun_sock->incoming_socks[i].fd);
+            stun_sock->incoming_socks[i].fd = PJ_INVALID_SOCKET;
+        }
+
+    for (int i = 0; i < stun_sock->outgoing_nb ; ++i)
+        if (stun_sock->outgoing_socks[i].sock != NULL) {
+            stun_sock->outgoing_socks[i].fd = PJ_INVALID_SOCKET;
+            pj_activesock_close(stun_sock->outgoing_socks[i].sock);
+        } else if (stun_sock->outgoing_socks[i].fd != PJ_INVALID_SOCKET) {
+            pj_sock_close(stun_sock->outgoing_socks[i].fd);
+            stun_sock->outgoing_socks[i].fd = PJ_INVALID_SOCKET;
+        }
+
+    if (stun_sock->stun_sess)
 	pj_stun_session_destroy(stun_sock->stun_sess);
-    }
+
     pj_grp_lock_dec_ref(stun_sock->grp_lock);
     pj_grp_lock_release(stun_sock->grp_lock);
     return PJ_SUCCESS;
 }
 
 /* Associate user data */
-PJ_DEF(pj_status_t) pj_stun_sock_set_user_data( pj_stun_sock *stun_sock,
-					        void *user_data)
+PJ_DEF(pj_status_t) pj_stun_sock_set_user_data(pj_stun_sock *stun_sock,
+                                               void *user_data)
 {
     PJ_ASSERT_RETURN(stun_sock, PJ_EINVAL);
     stun_sock->user_data = user_data;
@@ -559,14 +1022,14 @@ PJ_DECL(pj_grp_lock_t *) pj_stun_sock_get_grp_lock(pj_stun_sock *stun_sock)
 }
 
 /* Notify application that session has failed */
-static pj_bool_t sess_fail(pj_stun_sock *stun_sock, 
-			   pj_stun_sock_op op,
+static pj_bool_t sess_fail(pj_stun_sock *stun_sock,
+                           pj_stun_sock_op op,
 			   pj_status_t status)
 {
     pj_bool_t ret;
 
-    PJ_PERROR(4,(stun_sock->obj_name, status, 
-	         "Session failed because %s failed",
+    PJ_PERROR(4,(stun_sock->obj_name, status,
+                 "Session failed because %s failed",
 		 pj_stun_sock_op_name(op)));
 
     ret = (*stun_sock->cb.on_status)(stun_sock, op, status);
@@ -626,18 +1089,20 @@ static pj_status_t get_mapped_addr(pj_stun_sock *stun_sock)
     ++stun_sock->tsx_id[5];
     status = pj_stun_session_create_req(stun_sock->stun_sess,
 					PJ_STUN_BINDING_REQUEST,
-					PJ_STUN_MAGIC, 
-					(const pj_uint8_t*)stun_sock->tsx_id, 
+					PJ_STUN_MAGIC,
+					(const pj_uint8_t*)stun_sock->tsx_id,
 					&tdata);
     if (status != PJ_SUCCESS)
 	goto on_error;
-    
+
     /* Send request */
-    status=pj_stun_session_send_msg(stun_sock->stun_sess, INTERNAL_MSG_TOKEN,
-				    PJ_FALSE, PJ_TRUE, &stun_sock->srv_addr,
-				    pj_sockaddr_get_len(&stun_sock->srv_addr),
-				    tdata);
-    if (status != PJ_SUCCESS)
+    status = pj_stun_session_send_msg(stun_sock->stun_sess, INTERNAL_MSG_TOKEN,
+                                      PJ_FALSE,
+                                      (stun_sock->conn_type == PJ_STUN_TP_UDP),
+                                      &stun_sock->srv_addr,
+                                      pj_sockaddr_get_len(&stun_sock->srv_addr),
+                                      tdata);
+    if (status != PJ_SUCCESS && status != PJ_EPENDING)
 	goto on_error;
 
     return PJ_SUCCESS;
@@ -744,65 +1209,312 @@ PJ_DEF(pj_status_t) pj_stun_sock_get_info( pj_stun_sock *stun_sock,
 
 /* Send application data */
 PJ_DEF(pj_status_t) pj_stun_sock_sendto( pj_stun_sock *stun_sock,
-					 pj_ioqueue_op_key_t *send_key,
-					 const void *pkt,
-					 unsigned pkt_len,
-					 unsigned flag,
-					 const pj_sockaddr_t *dst_addr,
-					 unsigned addr_len)
+                                         pj_ioqueue_op_key_t *send_key,
+                                         const void *pkt,
+                                         unsigned pkt_len,
+                                         unsigned flag,
+                                         const pj_sockaddr_t *dst_addr,
+                                         unsigned addr_len,
+                                         pj_ssize_t* size)
 {
-    pj_ssize_t size;
     pj_status_t status;
 
     PJ_ASSERT_RETURN(stun_sock && pkt && dst_addr && addr_len, PJ_EINVAL);
-    
+
     pj_grp_lock_acquire(stun_sock->grp_lock);
 
     if (!stun_sock->active_sock) {
-	/* We have been shutdown, but this callback may still get called
-	 * by retransmit timer.
-	 */
-	pj_grp_lock_release(stun_sock->grp_lock);
-	return PJ_EINVALIDOP;
+        /* We have been shutdown, but this callback may still get called
+         * by retransmit timer.
+         */
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return PJ_EINVALIDOP;
     }
 
     if (send_key==NULL)
-	send_key = &stun_sock->send_key;
+        send_key = &stun_sock->send_key;
 
-    size = pkt_len;
-    status = pj_activesock_sendto(stun_sock->active_sock, send_key,
-                                  pkt, &size, flag, dst_addr, addr_len);
+    *size = pkt_len;
+    if (stun_sock->conn_type == PJ_STUN_TP_UDP) {
+        status = pj_activesock_sendto(stun_sock->active_sock, send_key,
+                                      pkt, size, flag, dst_addr, addr_len);
+    } else {
+#if PJ_HAS_TCP
+        pj_bool_t is_outgoing = PJ_FALSE;
+        pj_bool_t is_incoming = PJ_FALSE;
+        for (int i = 0; i <= stun_sock->outgoing_nb; ++i) {
+            if (pj_sockaddr_cmp(stun_sock->outgoing_socks[i].addr, dst_addr) == 0) {
+                is_outgoing = PJ_TRUE;
+                status = pj_activesock_send(stun_sock->outgoing_socks[i].sock,
+                                            send_key, pkt, size, flag);
+                break;
+            }
+        }
+        if (is_outgoing == PJ_FALSE) {
+            for (int i = 0 ; i <= stun_sock->incoming_nb; ++i) {
+                if (pj_sockaddr_cmp(&stun_sock->incoming_socks[i].addr,
+                                    dst_addr) == 0) {
+                    status = pj_activesock_send(stun_sock->incoming_socks[i].sock,
+                                                send_key, pkt, size, flag);
+                    is_incoming = PJ_TRUE;
+                    break;
+                }
+            }
+        }
+        if (is_outgoing == PJ_FALSE && is_incoming == PJ_FALSE) {
+            status = pj_activesock_send(stun_sock->active_sock, send_key, pkt,
+                                        size, flag);
+        }
+
+#endif
+    }
+
+    pj_grp_lock_release(stun_sock->grp_lock);
+    return status;
+}
+
+#if PJ_HAS_TCP
+
+PJ_DECL(pj_status_t) pj_stun_sock_connect(pj_stun_sock *stun_sock,
+                                          const pj_sockaddr_t *remote_addr,
+                                          int af,
+                                          int nb_check)
+{
+
+    pj_grp_lock_acquire(stun_sock->grp_lock);
+    int sock_type = pj_SOCK_STREAM();
+
+    pj_sock_t *fd = &stun_sock->outgoing_socks[nb_check].fd;
+    pj_activesock_t **asock = &stun_sock->outgoing_socks[nb_check].sock;
+    pj_sockaddr_t **addr = &stun_sock->outgoing_socks[nb_check].addr;
+
+    pj_status_t status = pj_sock_socket(af, sock_type, 0, fd);
+    if (status != PJ_SUCCESS) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Apply QoS, if specified */
+    status = pj_sock_apply_qos2(*fd, stun_sock->setting.qos_type,
+                                &stun_sock->setting.qos_params, 2, stun_sock->obj_name, NULL);
+    if (status != PJ_SUCCESS && !stun_sock->setting.qos_ignore_error) {
+        pj_stun_sock_destroy(stun_sock);
+        pj_grp_lock_release(stun_sock->grp_lock);
+        return status;
+    }
+
+    /* Apply socket buffer size */
+    if (stun_sock->setting.so_rcvbuf_size > 0) {
+        unsigned sobuf_size = stun_sock->setting.so_rcvbuf_size;
+        status = pj_sock_setsockopt_sobuf(*fd, pj_SO_RCVBUF(), PJ_TRUE, &sobuf_size);
+        if (status != PJ_SUCCESS) {
+            pj_perror(3, stun_sock->obj_name, status, "Failed setting SO_RCVBUF");
+        } else {
+            if (sobuf_size < stun_sock->setting.so_rcvbuf_size) {
+                PJ_LOG(4, (stun_sock->obj_name,
+                           "Warning! Cannot set SO_RCVBUF as configured, "
+                           "now=%d, configured=%d",
+                           sobuf_size, stun_sock->setting.so_rcvbuf_size));
+            } else {
+                PJ_LOG(5, (stun_sock->obj_name, "SO_RCVBUF set to %d", sobuf_size));
+            }
+        }
+    }
+
+    if (stun_sock->setting.so_sndbuf_size > 0) {
+        unsigned sobuf_size = stun_sock->setting.so_sndbuf_size;
+        status = pj_sock_setsockopt_sobuf(*fd, pj_SO_SNDBUF(), PJ_TRUE, &sobuf_size);
+        if (status != PJ_SUCCESS) {
+            pj_perror(3, stun_sock->obj_name, status, "Failed setting SO_SNDBUF");
+        } else {
+            if (sobuf_size < stun_sock->setting.so_sndbuf_size) {
+                PJ_LOG(4, (stun_sock->obj_name,
+                           "Warning! Cannot set SO_SNDBUF as configured, "
+                           "now=%d, configured=%d",
+                           sobuf_size, stun_sock->setting.so_sndbuf_size));
+            } else {
+                PJ_LOG(5, (stun_sock->obj_name, "SO_SNDBUF set to %d", sobuf_size));
+            }
+        }
+    }
+
+    /* Init active socket configuration */
+    {
+        pj_activesock_cfg activesock_cfg;
+        pj_activesock_cb activesock_cb;
+
+        pj_activesock_cfg_default(&activesock_cfg);
+        activesock_cfg.grp_lock = stun_sock->grp_lock;
+        activesock_cfg.async_cnt = stun_sock->setting.async_cnt;
+        activesock_cfg.concurrency = 0;
+
+        /* Create the active socket */
+        pj_bzero(&activesock_cb, sizeof(activesock_cb));
+        activesock_cb.on_data_read = &on_data_read;
+        activesock_cb.on_data_sent = &on_data_sent;
+        activesock_cb.on_connect_complete = &on_connect_complete;
+
+        status = pj_activesock_create(stun_sock->pool, *fd,
+                                      sock_type, &activesock_cfg,
+                                      stun_sock->stun_cfg.ioqueue, &activesock_cb,
+                                      stun_sock, asock);
+
+        if (status != PJ_SUCCESS) {
+            pj_grp_lock_release(stun_sock->grp_lock);
+            return status;
+        }
+
+        *addr = remote_addr;
+
+        status = pj_activesock_start_connect(
+                                             *asock, stun_sock->pool, *addr,
+                                             pj_sockaddr_get_len(*addr));
+        if (status == PJ_SUCCESS) {
+            on_connect_complete(*asock, status);
+        } else if (status != PJ_EPENDING) {
+            char addrinfo[PJ_INET6_ADDRSTRLEN+8];
+            pj_perror(3, stun_sock->pool->obj_name, status, "Failed to connect to %s",
+                      pj_sockaddr_print(*addr, addrinfo, sizeof(addrinfo), 3));
+            pj_grp_lock_release(stun_sock->grp_lock);
+            return status;
+        }
+    }
 
     pj_grp_lock_release(stun_sock->grp_lock);
     return status;
 }
 
+PJ_DECL(pj_status_t) pj_stun_sock_connect_active(pj_stun_sock *stun_sock,
+                                                 const pj_sockaddr_t *remote_addr,
+                                                 int af)
+{
+
+    if (stun_sock->incoming_nb != -1) {
+        // Check if not incoming, if so, already connected (mainly for PRFLX candidates)
+        for (int i = 0 ; i <= stun_sock->incoming_nb; ++i) {
+            if (pj_sockaddr_cmp(&stun_sock->incoming_socks[i].addr, remote_addr) == 0) {
+                pj_stun_session_cb *cb = pj_stun_session_callback(stun_sock->stun_sess);
+                (cb->on_peer_connection)(stun_sock->stun_sess, PJ_SUCCESS, remote_addr);
+                return PJ_SUCCESS;
+            }
+        }
+    }
+
+    /* Create socket and bind socket */
+    stun_sock->outgoing_nb += 1;
+    int nb_check = stun_sock->outgoing_nb;
+    return pj_stun_sock_connect(stun_sock, remote_addr, af, nb_check);
+
+}
+
+PJ_DECL(pj_status_t) pj_stun_sock_reconnect_active(pj_stun_sock *stun_sock,
+                                                   const pj_sockaddr_t *remote_addr,
+                                                   int af)
+{
+    for (int i = 0; i <= stun_sock->outgoing_nb; ++i) {
+        if (pj_sockaddr_cmp(stun_sock->outgoing_socks[i].addr, remote_addr) == 0) {
+            pj_activesock_close(stun_sock->outgoing_socks[i].sock);
+            return pj_stun_sock_connect(stun_sock, remote_addr, af, i);
+        }
+    }
+    return PJ_EINVAL;
+}
+
+PJ_DECL(pj_status_t) pj_stun_sock_close(pj_stun_sock *stun_sock,
+                                        const pj_sockaddr_t *remote_addr)
+{
+    for (int i = 0; i <= stun_sock->outgoing_nb; ++i) {
+        if (pj_sockaddr_cmp(stun_sock->outgoing_socks[i].addr, remote_addr) == 0) {
+            return pj_activesock_close(stun_sock->outgoing_socks[i].sock);
+        }
+    }
+
+    for (int i = 0; i <= stun_sock->incoming_nb; ++i) {
+        if (pj_sockaddr_cmp(&stun_sock->incoming_socks[i].addr, remote_addr) == 0) {
+            return pj_activesock_close(stun_sock->incoming_socks[i].sock);
+        }
+    }
+    return PJ_EINVAL;
+}
+
+static pj_bool_t on_connect_complete(pj_activesock_t *asock, pj_status_t status)
+{
+    pj_stun_sock *stun_sock;
+    stun_sock = (pj_stun_sock *)pj_activesock_get_user_data(asock);
+
+    pj_status_t result = pj_activesock_start_read(asock, stun_sock->pool,
+                                                  stun_sock->setting.max_pkt_size, 0);
+    if (result != PJ_SUCCESS) {
+        return PJ_FALSE;
+    };
+
+    pj_stun_session_cb *cb = pj_stun_session_callback(stun_sock->stun_sess);
+    if (!cb->on_peer_connection) {
+        return PJ_FALSE;
+    }
+
+    // Get remote connected address
+    pj_sockaddr_t* remote_addr = NULL;
+    for (int i = 0 ; i <= stun_sock->outgoing_nb ; ++i) {
+        if (stun_sock->outgoing_socks[i].sock == asock) {
+            remote_addr = stun_sock->outgoing_socks[i].addr;
+        }
+    }
+    if (!remote_addr) return PJ_FALSE;
+    (cb->on_peer_connection)(stun_sock->stun_sess, status, remote_addr);
+    return PJ_TRUE;
+}
+
+#endif
+
 /* This callback is called by the STUN session to send packet */
 static pj_status_t sess_on_send_msg(pj_stun_session *sess,
-				    void *token,
-				    const void *pkt,
-				    pj_size_t pkt_size,
-				    const pj_sockaddr_t *dst_addr,
-				    unsigned addr_len)
+                                    void *token,
+                                    const void *pkt,
+                                    pj_size_t pkt_size,
+                                    const pj_sockaddr_t *dst_addr,
+                                    unsigned addr_len)
 {
     pj_stun_sock *stun_sock;
-    pj_ssize_t size;
+    pj_ssize_t   size;
+    pj_status_t  status;
 
     stun_sock = (pj_stun_sock *) pj_stun_session_get_user_data(sess);
     if (!stun_sock || !stun_sock->active_sock) {
-	/* We have been shutdown, but this callback may still get called
-	 * by retransmit timer.
-	 */
-	return PJ_EINVALIDOP;
+        /* We have been shutdown, but this callback may still get called
+         * by retransmit timer.
+         */
+        return PJ_EINVALIDOP;
     }
 
     pj_assert(token==INTERNAL_MSG_TOKEN);
     PJ_UNUSED_ARG(token);
 
     size = pkt_size;
-    return pj_activesock_sendto(stun_sock->active_sock,
-				&stun_sock->int_send_key,
-				pkt, &size, 0, dst_addr, addr_len);
+    if (stun_sock->conn_type == PJ_STUN_TP_UDP) {
+        status = pj_activesock_sendto(stun_sock->active_sock,
+                                      &stun_sock->int_send_key,pkt, &size, 0,
+                                      dst_addr, addr_len);
+    }
+#if PJ_HAS_TCP
+    else {
+        for (int i = 0 ; i <= stun_sock->incoming_nb; ++i) {
+            if (pj_sockaddr_cmp(&stun_sock->incoming_socks[i].addr, dst_addr) == 0) {
+                status = pj_activesock_send(stun_sock->incoming_socks[i].sock,
+                                            &stun_sock->int_send_key,
+                                            pkt, &size, 0);
+                if (status != PJ_SUCCESS && status != PJ_EPENDING)
+                    PJ_PERROR(4,(stun_sock->obj_name, status,
+                                 "Error sending answer on incoming_sock(s)"));
+            }
+        }
+        /* last attempt */
+        status = pj_activesock_send(stun_sock->active_sock,
+                                    &stun_sock->int_send_key, pkt, &size, 0);
+    }
+#endif
+    return status;
 }
 
 /* This callback is called by the STUN session when outgoing transaction 
@@ -942,71 +1654,18 @@ static pj_bool_t on_data_recvfrom(pj_activesock_t *asock,
 				  pj_status_t status)
 {
     pj_stun_sock *stun_sock;
-    pj_stun_msg_hdr *hdr;
-    pj_uint16_t type;
 
     stun_sock = (pj_stun_sock*) pj_activesock_get_user_data(asock);
     if (!stun_sock)
-	return PJ_FALSE;
+        return PJ_FALSE;
 
     /* Log socket error */
     if (status != PJ_SUCCESS) {
-	PJ_PERROR(2,(stun_sock->obj_name, status, "recvfrom() error"));
-	return PJ_TRUE;
+        PJ_PERROR(2,(stun_sock->obj_name, status, "recvfrom() error"));
+        return PJ_TRUE;
     }
 
-    pj_grp_lock_acquire(stun_sock->grp_lock);
-
-    /* Check that this is STUN message */
-    status = pj_stun_msg_check((const pj_uint8_t*)data, size, 
-    			       PJ_STUN_IS_DATAGRAM | PJ_STUN_CHECK_PACKET);
-    if (status != PJ_SUCCESS) {
-	/* Not STUN -- give it to application */
-	goto process_app_data;
-    }
-
-    /* Treat packet as STUN header and copy the STUN message type.
-     * We don't want to access the type directly from the header
-     * since it may not be properly aligned.
-     */
-    hdr = (pj_stun_msg_hdr*) data;
-    pj_memcpy(&type, &hdr->type, 2);
-    type = pj_ntohs(type);
-
-    /* If the packet is a STUN Binding response and part of the
-     * transaction ID matches our internal ID, then this is
-     * our internal STUN message (Binding request or keep alive).
-     * Give it to our STUN session.
-     */
-    if (!PJ_STUN_IS_RESPONSE(type) ||
-	PJ_STUN_GET_METHOD(type) != PJ_STUN_BINDING_METHOD ||
-	pj_memcmp(hdr->tsx_id, stun_sock->tsx_id, 10) != 0) 
-    {
-	/* Not STUN Binding response, or STUN transaction ID mismatch.
-	 * This is not our message too -- give it to application.
-	 */
-	goto process_app_data;
-    }
-
-    /* This is our STUN Binding response. Give it to the STUN session */
-    status = pj_stun_session_on_rx_pkt(stun_sock->stun_sess, data, size,
-				       PJ_STUN_IS_DATAGRAM, NULL, NULL,
-				       src_addr, addr_len);
-
-    status = pj_grp_lock_release(stun_sock->grp_lock);
-
-    return status!=PJ_EGONE ? PJ_TRUE : PJ_FALSE;
-
-process_app_data:
-    if (stun_sock->cb.on_rx_data) {
-	(*stun_sock->cb.on_rx_data)(stun_sock, data, (unsigned)size,
-				    src_addr, addr_len);
-	status = pj_grp_lock_release(stun_sock->grp_lock);
-	return status!=PJ_EGONE ? PJ_TRUE : PJ_FALSE;
-    }
-
-    status = pj_grp_lock_release(stun_sock->grp_lock);
-    return status!=PJ_EGONE ? PJ_TRUE : PJ_FALSE;
+    return parse_rx_packet(asock, data, size, src_addr, addr_len);
 }
 
 /* Callback from active socket about send status */
@@ -1047,3 +1706,7 @@ static pj_bool_t on_data_sent(pj_activesock_t *asock,
     return PJ_TRUE;
 }
 
+pj_stun_session* pj_stun_sock_get_session(pj_stun_sock *stun_sock)
+{
+    return stun_sock ? stun_sock->stun_sess : NULL;
+}
diff --git a/pjnath/src/pjnath/turn_session.c b/pjnath/src/pjnath/turn_session.c
index a378b8672..5393300f6 100644
--- a/pjnath/src/pjnath/turn_session.c
+++ b/pjnath/src/pjnath/turn_session.c
@@ -311,7 +311,8 @@ PJ_DEF(pj_status_t) pj_turn_session_create( const pj_stun_config *cfg,
     stun_cb.on_request_complete = &stun_on_request_complete;
     stun_cb.on_rx_indication = &stun_on_rx_indication;
     status = pj_stun_session_create(&sess->stun_cfg, sess->obj_name, &stun_cb,
-				    PJ_FALSE, sess->grp_lock, &sess->stun);
+                                    PJ_FALSE, sess->grp_lock, &sess->stun,
+                                    conn_type);
     if (status != PJ_SUCCESS) {
 	do_destroy(sess);
 	return status;
diff --git a/pjnath/src/pjnath/turn_sock.c b/pjnath/src/pjnath/turn_sock.c
index dc6304d9f..633a2aa0b 100644
--- a/pjnath/src/pjnath/turn_sock.c
+++ b/pjnath/src/pjnath/turn_sock.c
@@ -1766,3 +1766,20 @@ static void turn_on_connection_bind_status(pj_turn_session *sess,
 					      peer_addr, addr_len);
     }
 }
+
+pj_bool_t pj_turn_sock_has_dataconn(pj_turn_sock *turn_sock,
+                                    const pj_sockaddr_t *peer)
+{
+    if (!turn_sock) return PJ_FALSE;
+
+    for (int i = 0; i < turn_sock->data_conn_cnt; ++i) {
+        tcp_data_conn_t* dataconn = &turn_sock->data_conn[i];
+        if (dataconn) {
+            pj_sockaddr_t* conn_peer = &dataconn->peer_addr;
+            if (pj_sockaddr_cmp(conn_peer, peer) == 0)
+                return PJ_TRUE;
+        }
+    }
+
+    return PJ_FALSE;
+}
diff --git a/pjnath/src/pjturn-client/client_main.c b/pjnath/src/pjturn-client/client_main.c
index 6f9f1ff1a..920ce58f1 100644
--- a/pjnath/src/pjturn-client/client_main.c
+++ b/pjnath/src/pjturn-client/client_main.c
@@ -1,5 +1,5 @@
 /* $Id$ */
-/* 
+/*
  * Copyright (C) 2008-2011 Teluu Inc. (http://www.teluu.com)
  * Copyright (C) 2003-2008 Benny Prijono <benny@prijono.org>
  *
@@ -15,7 +15,7 @@
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
  */
 #include <pjnath.h>
 #include <pjlib-util.h>
@@ -79,7 +79,7 @@ static void turn_on_rx_data(pj_turn_sock *relay,
 			    unsigned addr_len);
 static void turn_on_state(pj_turn_sock *relay, pj_turn_state_t old_state,
 			  pj_turn_state_t new_state);
-static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock, 
+static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock,
 				     pj_stun_sock_op op,
 				     pj_status_t status);
 static pj_bool_t stun_sock_on_rx_data(pj_stun_sock *stun_sock,
@@ -131,7 +131,7 @@ static int init()
     /* Create global ioqueue */
     CHECK( pj_ioqueue_create(g.pool, 16, &g.stun_config.ioqueue) );
 
-    /* 
+    /*
      * Create peers
      */
     for (i=0; i<(int)PJ_ARRAY_SIZE(g.peer); ++i) {
@@ -154,9 +154,9 @@ static int init()
 #endif
 
 	name[strlen(name)-1] = '0'+i;
-	status = pj_stun_sock_create(&g.stun_config, name, pj_AF_INET(), 
-				     &stun_sock_cb, &ss_cfg,
-				     &g.peer[i], &g.peer[i].stun_sock);
+        status = pj_stun_sock_create(&g.stun_config, name, pj_AF_INET(),
+                                     PJ_STUN_TP_UDP, &stun_sock_cb, &ss_cfg,
+                                     &g.peer[i], &g.peer[i].stun_sock);
 	if (status != PJ_SUCCESS) {
 	    my_perror("pj_stun_sock_create()", status);
 	    return status;
@@ -169,7 +169,7 @@ static int init()
 	    server = pj_str(o.srv_addr);
 	    port = (pj_uint16_t)(o.srv_port?atoi(o.srv_port):PJ_STUN_PORT);
 	}
-	status = pj_stun_sock_start(g.peer[i].stun_sock, &server, 
+	status = pj_stun_sock_start(g.peer[i].stun_sock, &server,
 				    port,  NULL);
 	if (status != PJ_SUCCESS) {
 	    my_perror("pj_stun_sock_start()", status);
@@ -258,8 +258,8 @@ static pj_status_t create_relay(void)
     if (o.nameserver) {
 	pj_str_t ns = pj_str(o.nameserver);
 
-	status = pj_dns_resolver_create(&g.cp.factory, "resolver", 0, 
-					g.stun_config.timer_heap, 
+	status = pj_dns_resolver_create(&g.cp.factory, "resolver", 0,
+					g.stun_config.timer_heap,
 					g.stun_config.ioqueue, &g.resolver);
 	if (status != PJ_SUCCESS) {
 	    PJ_LOG(1,(THIS_FILE, "Error creating resolver (err=%d)", status));
@@ -276,7 +276,7 @@ static pj_status_t create_relay(void)
     pj_bzero(&rel_cb, sizeof(rel_cb));
     rel_cb.on_rx_data = &turn_on_rx_data;
     rel_cb.on_state = &turn_on_state;
-    CHECK( pj_turn_sock_create(&g.stun_config, pj_AF_INET(), 
+    CHECK( pj_turn_sock_create(&g.stun_config, pj_AF_INET(),
 			       (o.use_tcp? PJ_TURN_TP_TCP : PJ_TURN_TP_UDP),
 			       &rel_cb, 0,
 			       NULL, &g.relay) );
@@ -331,7 +331,7 @@ static void turn_on_rx_data(pj_turn_sock *relay,
 static void turn_on_state(pj_turn_sock *relay, pj_turn_state_t old_state,
 			  pj_turn_state_t new_state)
 {
-    PJ_LOG(3,(THIS_FILE, "State %s --> %s", pj_turn_state_name(old_state), 
+    PJ_LOG(3,(THIS_FILE, "State %s --> %s", pj_turn_state_name(old_state),
 	      pj_turn_state_name(new_state)));
 
     if (new_state == PJ_TURN_STATE_READY) {
@@ -344,7 +344,7 @@ static void turn_on_state(pj_turn_sock *relay, pj_turn_state_t old_state,
     }
 }
 
-static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock, 
+static pj_bool_t stun_sock_on_status(pj_stun_sock *stun_sock,
 				     pj_stun_sock_op op,
 				     pj_status_t status)
 {
@@ -455,7 +455,7 @@ static void console_main(void)
 
 	if (fgets(input, sizeof(input), stdin) == NULL)
 	    break;
-	
+
 	switch (input[0]) {
 	case 'a':
 	    create_relay();
@@ -474,9 +474,9 @@ static void console_main(void)
 		peer = &g.peer[1];
 
 	    strcpy(input, "Hello from client");
-	    status = pj_turn_sock_sendto(g.relay, (const pj_uint8_t*)input, 
-					strlen(input)+1, 
-					&peer->mapped_addr, 
+	    status = pj_turn_sock_sendto(g.relay, (const pj_uint8_t*)input,
+					strlen(input)+1,
+					&peer->mapped_addr,
 					pj_sockaddr_get_len(&peer->mapped_addr));
 	    if (status != PJ_SUCCESS && status != PJ_EPENDING)
 		my_perror("turn_udp_sendto() failed", status);
@@ -525,8 +525,10 @@ static void console_main(void)
 	    }
 	    peer = &g.peer[input[0]-'0'];
 	    sprintf(input, "Hello from peer%d", input[0]-'0');
+            pj_ssize_t size;
 	    pj_stun_sock_sendto(peer->stun_sock, NULL, input, strlen(input)+1, 0,
-				&g.relay_addr, pj_sockaddr_get_len(&g.relay_addr));
+	                        &g.relay_addr, pj_sockaddr_get_len(&g.relay_addr),
+	                        &size);
 	    break;
 	case 'q':
 	    g.quit = PJ_TRUE;
@@ -618,14 +620,13 @@ int main(int argc, char *argv[])
 
     if ((status=init()) != 0)
 	goto on_return;
-    
+
     //if ((status=create_relay()) != 0)
     //	goto on_return;
-    
+
     console_main();
 
 on_return:
     client_shutdown();
     return status ? 1 : 0;
 }
-
diff --git a/pjnath/src/pjturn-srv/allocation.c b/pjnath/src/pjturn-srv/allocation.c
index 6c9c9ce11..da6fe4a1b 100644
--- a/pjnath/src/pjturn-srv/allocation.c
+++ b/pjnath/src/pjturn-srv/allocation.c
@@ -338,7 +338,8 @@ PJ_DEF(pj_status_t) pj_turn_allocation_create(pj_turn_transport *transport,
     sess_cb.on_rx_request = &stun_on_rx_request;
     sess_cb.on_rx_indication = &stun_on_rx_indication;
     status = pj_stun_session_create(&srv->core.stun_cfg, alloc->obj_name,
-				    &sess_cb, PJ_FALSE, NULL, &alloc->sess);
+                                    &sess_cb, PJ_FALSE, NULL, &alloc->sess,
+                                    PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS) {
 	goto on_error;
     }
diff --git a/pjnath/src/pjturn-srv/server.c b/pjnath/src/pjturn-srv/server.c
index 94dda29a3..6c90bdb8d 100644
--- a/pjnath/src/pjturn-srv/server.c
+++ b/pjnath/src/pjturn-srv/server.c
@@ -156,7 +156,7 @@ PJ_DEF(pj_status_t) pj_turn_srv_create(pj_pool_factory *pf,
 
     status = pj_stun_session_create(&srv->core.stun_cfg, srv->obj_name,
 				    &sess_cb, PJ_FALSE, NULL,
-				    &srv->core.stun_sess);
+                                    &srv->core.stun_sess, PJ_STUN_TP_UDP);
     if (status != PJ_SUCCESS) {
 	goto on_error;
     }
diff --git a/pjsip-apps/src/samples/icedemo.c b/pjsip-apps/src/samples/icedemo.c
index 07ccc31f0..c9165f1d5 100644
--- a/pjsip-apps/src/samples/icedemo.c
+++ b/pjsip-apps/src/samples/icedemo.c
@@ -42,8 +42,8 @@ static struct app_t
 	int	    max_host;
 	pj_bool_t   regular;
 	pj_str_t    stun_srv;
-	pj_str_t    turn_srv;
-	pj_bool_t   turn_tcp;
+        pj_str_t    turn_srv;
+        pj_bool_t   ice_tcp;
 	pj_str_t    turn_username;
 	pj_str_t    turn_password;
 	pj_bool_t   turn_fingerprint;
@@ -273,13 +273,14 @@ static void log_func(int level, const char *data, int len)
  * once (and only once) during application initialization sequence by 
  * main().
  */
+
 static pj_status_t icedemo_init(void)
 {
     pj_status_t status;
 
     if (icedemo.opt.log_file) {
-	icedemo.log_fhnd = fopen(icedemo.opt.log_file, "a");
-	pj_log_set_log_func(&log_func);
+        icedemo.log_fhnd = fopen(icedemo.opt.log_file, "a");
+        pj_log_set_log_func(&log_func);
     }
 
     /* Initialize the libraries before anything else */
@@ -297,109 +298,118 @@ static pj_status_t icedemo_init(void)
 
     /* Create application memory pool */
     icedemo.pool = pj_pool_create(&icedemo.cp.factory, "icedemo", 
-				  512, 512, NULL);
+                                  512, 512, NULL);
 
     /* Create timer heap for timer stuff */
     CHECK( pj_timer_heap_create(icedemo.pool, 100, 
-				&icedemo.ice_cfg.stun_cfg.timer_heap) );
+                                &icedemo.ice_cfg.stun_cfg.timer_heap) );
 
     /* and create ioqueue for network I/O stuff */
     CHECK( pj_ioqueue_create(icedemo.pool, 16, 
-			     &icedemo.ice_cfg.stun_cfg.ioqueue) );
+                             &icedemo.ice_cfg.stun_cfg.ioqueue) );
 
     /* something must poll the timer heap and ioqueue, 
      * unless we're on Symbian where the timer heap and ioqueue run
      * on themselves.
      */
     CHECK( pj_thread_create(icedemo.pool, "icedemo", &icedemo_worker_thread,
-			    NULL, 0, 0, &icedemo.thread) );
+                            NULL, 0, 0, &icedemo.thread) );
 
     icedemo.ice_cfg.af = pj_AF_INET();
 
     /* Create DNS resolver if nameserver is set */
     if (icedemo.opt.ns.slen) {
-	CHECK( pj_dns_resolver_create(&icedemo.cp.factory, 
-				      "resolver", 
-				      0, 
-				      icedemo.ice_cfg.stun_cfg.timer_heap,
-				      icedemo.ice_cfg.stun_cfg.ioqueue, 
-				      &icedemo.ice_cfg.resolver) );
+        CHECK( pj_dns_resolver_create(&icedemo.cp.factory, 
+                                      "resolver", 
+                                      0, 
+                                      icedemo.ice_cfg.stun_cfg.timer_heap,
+                                      icedemo.ice_cfg.stun_cfg.ioqueue, 
+                                      &icedemo.ice_cfg.resolver) );
 
-	CHECK( pj_dns_resolver_set_ns(icedemo.ice_cfg.resolver, 1, 
-				      &icedemo.opt.ns, NULL) );
+        CHECK( pj_dns_resolver_set_ns(icedemo.ice_cfg.resolver, 1, 
+                                      &icedemo.opt.ns, NULL) );
     }
 
     /* -= Start initializing ICE stream transport config =- */
 
     /* Maximum number of host candidates */
     if (icedemo.opt.max_host != -1)
-	icedemo.ice_cfg.stun.max_host_cands = icedemo.opt.max_host;
+        icedemo.ice_cfg.stun.max_host_cands = icedemo.opt.max_host;
 
     /* Nomination strategy */
     if (icedemo.opt.regular)
-	icedemo.ice_cfg.opt.aggressive = PJ_FALSE;
+        icedemo.ice_cfg.opt.aggressive = PJ_FALSE;
     else
-	icedemo.ice_cfg.opt.aggressive = PJ_TRUE;
+        icedemo.ice_cfg.opt.aggressive = PJ_TRUE;
+
+    /* Connection type to STUN server */
+    if (icedemo.opt.ice_tcp)
+        icedemo.ice_cfg.stun.conn_type = PJ_STUN_TP_TCP;
+    else
+        icedemo.ice_cfg.stun.conn_type = PJ_STUN_TP_UDP;
 
     /* Configure STUN/srflx candidate resolution */
     if (icedemo.opt.stun_srv.slen) {
-	char *pos;
+        char *pos;
 
-	/* Command line option may contain port number */
-	if ((pos=pj_strchr(&icedemo.opt.stun_srv, ':')) != NULL) {
-	    icedemo.ice_cfg.stun.server.ptr = icedemo.opt.stun_srv.ptr;
-	    icedemo.ice_cfg.stun.server.slen = (pos - icedemo.opt.stun_srv.ptr);
+        /* Command line option may contain port number */
+        if ((pos = pj_strchr(&icedemo.opt.stun_srv, ':')) != NULL) {
+            icedemo.ice_cfg.stun.server.ptr = icedemo.opt.stun_srv.ptr;
+            icedemo.ice_cfg.stun.server.slen = (pos - icedemo.opt.stun_srv.ptr);
 
-	    icedemo.ice_cfg.stun.port = (pj_uint16_t)atoi(pos+1);
-	} else {
-	    icedemo.ice_cfg.stun.server = icedemo.opt.stun_srv;
-	    icedemo.ice_cfg.stun.port = PJ_STUN_PORT;
-	}
+            icedemo.ice_cfg.stun.port = (pj_uint16_t)atoi(pos + 1);
+        } else {
+            icedemo.ice_cfg.stun.server = icedemo.opt.stun_srv;
+            icedemo.ice_cfg.stun.port = PJ_STUN_PORT;
+        }
 
-	/* For this demo app, configure longer STUN keep-alive time
-	 * so that it does't clutter the screen output.
-	 */
-	icedemo.ice_cfg.stun.cfg.ka_interval = KA_INTERVAL;
+        /* For this demo app, configure longer STUN keep-alive time
+         * so that it does't clutter the screen output.
+         */
+        icedemo.ice_cfg.stun.cfg.ka_interval = KA_INTERVAL;
     }
 
     /* Configure TURN candidate */
     if (icedemo.opt.turn_srv.slen) {
-	char *pos;
+        char *pos;
 
-	/* Command line option may contain port number */
-	if ((pos=pj_strchr(&icedemo.opt.turn_srv, ':')) != NULL) {
-	    icedemo.ice_cfg.turn.server.ptr = icedemo.opt.turn_srv.ptr;
-	    icedemo.ice_cfg.turn.server.slen = (pos - icedemo.opt.turn_srv.ptr);
+        /* Command line option may contain port number */
+        if ((pos=pj_strchr(&icedemo.opt.turn_srv, ':')) != NULL) {
+            icedemo.ice_cfg.turn.server.ptr = icedemo.opt.turn_srv.ptr;
+            icedemo.ice_cfg.turn.server.slen = (pos - icedemo.opt.turn_srv.ptr);
 
-	    icedemo.ice_cfg.turn.port = (pj_uint16_t)atoi(pos+1);
-	} else {
-	    icedemo.ice_cfg.turn.server = icedemo.opt.turn_srv;
-	    icedemo.ice_cfg.turn.port = PJ_STUN_PORT;
-	}
+            icedemo.ice_cfg.turn.port = (pj_uint16_t)atoi(pos+1);
+        } else {
+            icedemo.ice_cfg.turn.server = icedemo.opt.turn_srv;
+            icedemo.ice_cfg.turn.port = PJ_STUN_PORT;
+        }
 
-	/* TURN credential */
-	icedemo.ice_cfg.turn.auth_cred.type = PJ_STUN_AUTH_CRED_STATIC;
-	icedemo.ice_cfg.turn.auth_cred.data.static_cred.username = icedemo.opt.turn_username;
-	icedemo.ice_cfg.turn.auth_cred.data.static_cred.data_type = PJ_STUN_PASSWD_PLAIN;
-	icedemo.ice_cfg.turn.auth_cred.data.static_cred.data = icedemo.opt.turn_password;
+        /* TURN credential */
+        icedemo.ice_cfg.turn.auth_cred.type = PJ_STUN_AUTH_CRED_STATIC;
+        icedemo.ice_cfg.turn.auth_cred.data.static_cred.username = icedemo.opt.turn_username;
+        icedemo.ice_cfg.turn.auth_cred.data.static_cred.data_type = PJ_STUN_PASSWD_PLAIN;
+        icedemo.ice_cfg.turn.auth_cred.data.static_cred.data = icedemo.opt.turn_password;
 
-	/* Connection type to TURN server */
-	if (icedemo.opt.turn_tcp)
-	    icedemo.ice_cfg.turn.conn_type = PJ_TURN_TP_TCP;
-	else
-	    icedemo.ice_cfg.turn.conn_type = PJ_TURN_TP_UDP;
+        /* Connection type to TURN server */
+        if (icedemo.opt.ice_tcp)
+            icedemo.ice_cfg.turn.conn_type = PJ_TURN_TP_TCP;
+        else
+            icedemo.ice_cfg.turn.conn_type = PJ_TURN_TP_UDP;
 
-	/* For this demo app, configure longer keep-alive time
-	 * so that it does't clutter the screen output.
-	 */
-	icedemo.ice_cfg.turn.alloc_param.ka_interval = KA_INTERVAL;
+        /* For this demo app, configure longer keep-alive time
+         * so that it does't clutter the screen output.
+         */
+        icedemo.ice_cfg.turn.alloc_param.ka_interval = KA_INTERVAL;
+    }
+
+    if (icedemo.opt.ice_tcp) {
+        icedemo.ice_cfg.protocol = PJ_ICE_TP_TCP;
     }
 
     /* -= That's it for now, initialization is complete =- */
     return PJ_SUCCESS;
 }
 
-
 /*
  * Create ICE stream transport instance, invoked from the menu.
  */
@@ -608,6 +618,26 @@ static int encode_session(char buffer[], unsigned maxlen)
 				    sizeof(ipaddr), 0));
 	}
 
+        if (cand[0].transport != PJ_CAND_UDP) {
+            /** RFC 6544, Section 4.5:
+             * If the default candidate is TCP-based, the agent MUST include the
+             * a=setup and a=connection attributes from RFC 4145 [RFC4145],
+             * following the procedures defined there as if ICE were not in use.
+             */
+            PRINT("a=setup:");
+            switch (cand[0].transport) {
+            case PJ_CAND_TCP_ACTIVE:
+                PRINT("active\n");
+                break;
+            case PJ_CAND_TCP_PASSIVE:
+                PRINT("passive\n");
+                break;
+            default:
+                return PJ_EINVALIDOP;
+            }
+            PRINT("a=connection:new\n");
+        }
+
 	/* Enumerate all candidates for this component */
 	cand_cnt = PJ_ARRAY_SIZE(cand);
 	status = pj_ice_strans_enum_cands(icedemo.icest, comp+1,
@@ -709,10 +739,10 @@ static void icedemo_show_ice(void)
  */
 static void icedemo_input_remote(void)
 {
-    char linebuf[80];
+    char linebuf[120];
     unsigned media_cnt = 0;
     unsigned comp0_port = 0;
-    char     comp0_addr[80];
+    char comp0_addr[80];
     pj_bool_t done = PJ_FALSE;
 
     puts("Paste SDP from remote host, end with empty line");
@@ -722,204 +752,223 @@ static void icedemo_input_remote(void)
     comp0_addr[0] = '\0';
 
     while (!done) {
-	pj_size_t len;
-	char *line;
-
-	printf(">");
-	if (stdout) fflush(stdout);
-
-	if (fgets(linebuf, sizeof(linebuf), stdin)==NULL)
-	    break;
-
-	len = strlen(linebuf);
-	while (len && (linebuf[len-1] == '\r' || linebuf[len-1] == '\n'))
-	    linebuf[--len] = '\0';
-
-	line = linebuf;
-	while (len && pj_isspace(*line))
-	    ++line, --len;
-
-	if (len==0)
-	    break;
-
-	/* Ignore subsequent media descriptors */
-	if (media_cnt > 1)
-	    continue;
-
-	switch (line[0]) {
-	case 'm':
-	    {
-		int cnt;
-		char media[32], portstr[32];
-
-		++media_cnt;
-		if (media_cnt > 1) {
-		    puts("Media line ignored");
-		    break;
-		}
-
-		cnt = sscanf(line+2, "%s %s RTP/", media, portstr);
-		if (cnt != 2) {
-		    PJ_LOG(1,(THIS_FILE, "Error parsing media line"));
-		    goto on_error;
-		}
-
-		comp0_port = atoi(portstr);
-		
-	    }
-	    break;
-	case 'c':
-	    {
-		int cnt;
-		char c[32], net[32], ip[80];
-		
-		cnt = sscanf(line+2, "%s %s %s", c, net, ip);
-		if (cnt != 3) {
-		    PJ_LOG(1,(THIS_FILE, "Error parsing connection line"));
-		    goto on_error;
-		}
-
-		strcpy(comp0_addr, ip);
-	    }
-	    break;
-	case 'a':
-	    {
-		char *attr = strtok(line+2, ": \t\r\n");
-		if (strcmp(attr, "ice-ufrag")==0) {
-		    strcpy(icedemo.rem.ufrag, attr+strlen(attr)+1);
-		} else if (strcmp(attr, "ice-pwd")==0) {
-		    strcpy(icedemo.rem.pwd, attr+strlen(attr)+1);
-		} else if (strcmp(attr, "rtcp")==0) {
-		    char *val = attr+strlen(attr)+1;
-		    int af, cnt;
-		    int port;
-		    char net[32], ip[64];
-		    pj_str_t tmp_addr;
-		    pj_status_t status;
-
-		    cnt = sscanf(val, "%d IN %s %s", &port, net, ip);
-		    if (cnt != 3) {
-			PJ_LOG(1,(THIS_FILE, "Error parsing rtcp attribute"));
-			goto on_error;
-		    }
-
-		    if (strchr(ip, ':'))
-			af = pj_AF_INET6();
-		    else
-			af = pj_AF_INET();
-
-		    pj_sockaddr_init(af, &icedemo.rem.def_addr[1], NULL, 0);
-		    tmp_addr = pj_str(ip);
-		    status = pj_sockaddr_set_str_addr(af, &icedemo.rem.def_addr[1],
-						      &tmp_addr);
-		    if (status != PJ_SUCCESS) {
-			PJ_LOG(1,(THIS_FILE, "Invalid IP address"));
-			goto on_error;
-		    }
-		    pj_sockaddr_set_port(&icedemo.rem.def_addr[1], (pj_uint16_t)port);
-
-		} else if (strcmp(attr, "candidate")==0) {
-		    char *sdpcand = attr+strlen(attr)+1;
-		    int af, cnt;
-		    char foundation[32], transport[12], ipaddr[80], type[32];
-		    pj_str_t tmpaddr;
-		    int comp_id, prio, port;
-		    pj_ice_sess_cand *cand;
-		    pj_status_t status;
-
-		    cnt = sscanf(sdpcand, "%s %d %s %d %s %d typ %s",
-				 foundation,
-				 &comp_id,
-				 transport,
-				 &prio,
-				 ipaddr,
-				 &port,
-				 type);
-		    if (cnt != 7) {
-			PJ_LOG(1, (THIS_FILE, "error: Invalid ICE candidate line"));
-			goto on_error;
-		    }
-
-		    cand = &icedemo.rem.cand[icedemo.rem.cand_cnt];
-		    pj_bzero(cand, sizeof(*cand));
-		    
-		    if (strcmp(type, "host")==0)
-			cand->type = PJ_ICE_CAND_TYPE_HOST;
-		    else if (strcmp(type, "srflx")==0)
-			cand->type = PJ_ICE_CAND_TYPE_SRFLX;
-		    else if (strcmp(type, "relay")==0)
-			cand->type = PJ_ICE_CAND_TYPE_RELAYED;
-		    else {
-			PJ_LOG(1, (THIS_FILE, "Error: invalid candidate type '%s'", 
-				   type));
-			goto on_error;
-		    }
-
-		    cand->comp_id = (pj_uint8_t)comp_id;
-		    pj_strdup2(icedemo.pool, &cand->foundation, foundation);
-		    cand->prio = prio;
-		    
-		    if (strchr(ipaddr, ':'))
-			af = pj_AF_INET6();
-		    else
-			af = pj_AF_INET();
-
-		    tmpaddr = pj_str(ipaddr);
-		    pj_sockaddr_init(af, &cand->addr, NULL, 0);
-		    status = pj_sockaddr_set_str_addr(af, &cand->addr, &tmpaddr);
-		    if (status != PJ_SUCCESS) {
-			PJ_LOG(1,(THIS_FILE, "Error: invalid IP address '%s'",
-				  ipaddr));
-			goto on_error;
-		    }
-
-		    pj_sockaddr_set_port(&cand->addr, (pj_uint16_t)port);
-
-		    ++icedemo.rem.cand_cnt;
-
-		    if (cand->comp_id > icedemo.rem.comp_cnt)
-			icedemo.rem.comp_cnt = cand->comp_id;
-		}
-	    }
-	    break;
-	}
+        pj_size_t len;
+        char *line;
+
+        printf(">");
+        if (stdout)
+            fflush(stdout);
+
+        if (fgets(linebuf, sizeof(linebuf), stdin) == NULL)
+            break;
+
+        len = strlen(linebuf);
+        while (len && (linebuf[len - 1] == '\r' || linebuf[len - 1] == '\n'))
+            linebuf[--len] = '\0';
+
+        line = linebuf;
+        while (len && pj_isspace(*line))
+            ++line, --len;
+
+        if (len == 0)
+            break;
+
+        /* Ignore subsequent media descriptors */
+        if (media_cnt > 1)
+            continue;
+
+        switch (line[0]) {
+        case 'm': {
+            int cnt;
+            char media[32], portstr[32];
+
+            ++media_cnt;
+            if (media_cnt > 1) {
+                puts("Media line ignored");
+                break;
+            }
+
+            cnt = sscanf(line + 2, "%s %s RTP/", media, portstr);
+            if (cnt != 2) {
+                PJ_LOG(1, (THIS_FILE, "Error parsing media line"));
+                goto on_error;
+            }
+
+            comp0_port = atoi(portstr);
+
+        } break;
+        case 'c': {
+            int cnt;
+            char c[32], net[32], ip[80];
+
+            cnt = sscanf(line + 2, "%s %s %s", c, net, ip);
+            if (cnt != 3) {
+                PJ_LOG(1, (THIS_FILE, "Error parsing connection line"));
+                goto on_error;
+            }
+
+            strcpy(comp0_addr, ip);
+        } break;
+        case 'a': {
+            char *attr = strtok(line + 2, ": \t\r\n");
+            if (strcmp(attr, "ice-ufrag") == 0) {
+                strcpy(icedemo.rem.ufrag, attr + strlen(attr) + 1);
+            } else if (strcmp(attr, "ice-pwd") == 0) {
+                strcpy(icedemo.rem.pwd, attr + strlen(attr) + 1);
+            } else if (strcmp(attr, "rtcp") == 0) {
+                char *val = attr + strlen(attr) + 1;
+                int af, cnt;
+                int port;
+                char net[32], ip[64];
+                pj_str_t tmp_addr;
+                pj_status_t status;
+
+                cnt = sscanf(val, "%d IN %s %s", &port, net, ip);
+                if (cnt != 3) {
+                    PJ_LOG(1, (THIS_FILE, "Error parsing rtcp attribute"));
+                    goto on_error;
+                }
+
+                if (strchr(ip, ':'))
+                    af = pj_AF_INET6();
+                else
+                    af = pj_AF_INET();
+
+                pj_sockaddr_init(af, &icedemo.rem.def_addr[1], NULL, 0);
+                tmp_addr = pj_str(ip);
+                status =
+                    pj_sockaddr_set_str_addr(af, &icedemo.rem.def_addr[1], &tmp_addr);
+                if (status != PJ_SUCCESS) {
+                    PJ_LOG(1, (THIS_FILE, "Invalid IP address"));
+                    goto on_error;
+                }
+                pj_sockaddr_set_port(&icedemo.rem.def_addr[1], (pj_uint16_t)port);
+
+            } else if (strcmp(attr, "candidate") == 0) {
+                /**   Section 4.5, RFC 6544 (https://tools.ietf.org/html/rfc6544)
+                 *    candidate-attribute   = "candidate" ":" foundation SP component-id
+                 * SP "TCP" SP priority SP connection-address SP port SP cand-type [SP
+                 * rel-addr] [SP rel-port] SP tcp-type-ext
+                 *                             *(SP extension-att-name SP
+                 *                                  extension-att-value)
+                 *
+                 *     tcp-type-ext          = "tcptype" SP tcp-type
+                 *     tcp-type              = "active" / "passive" / "so"
+                 */
+                char *sdpcand = attr + strlen(attr) + 1;
+                int af, cnt;
+                char foundation[32], transport[12], ipaddr[80], type[32], tcp_type[32];
+                pj_str_t tmpaddr;
+                int comp_id, prio, port;
+                pj_ice_sess_cand *cand;
+                pj_status_t status;
+                pj_bool_t is_tcp = PJ_FALSE;
+
+                cnt =
+                    sscanf(sdpcand, "%s %d %s %d %s %d typ %s tcptype %s\n", foundation,
+                           &comp_id, transport, &prio, ipaddr, &port, type, tcp_type);
+                if (cnt != 7 && cnt != 8) {
+                    PJ_LOG(1, (THIS_FILE, "error: Invalid ICE candidate line", cnt));
+                    goto on_error;
+                }
+
+                if (strcmp(transport, "TCP") == 0) {
+                    is_tcp = PJ_TRUE;
+                }
+
+                cand = &icedemo.rem.cand[icedemo.rem.cand_cnt];
+                pj_bzero(cand, sizeof(*cand));
+
+                if (strcmp(type, "host") == 0)
+                    cand->type = PJ_ICE_CAND_TYPE_HOST;
+                else if (strcmp(type, "srflx") == 0)
+                    cand->type = PJ_ICE_CAND_TYPE_SRFLX;
+                else if (strcmp(type, "relay") == 0)
+                    cand->type = PJ_ICE_CAND_TYPE_RELAYED;
+                else {
+                    PJ_LOG(1, (THIS_FILE, "Error: invalid candidate type '%s'", type));
+                    goto on_error;
+                }
+
+                if (is_tcp) {
+                    if (strcmp(tcp_type, "active") == 0)
+                        cand->transport = PJ_CAND_TCP_ACTIVE;
+                    else if (strcmp(tcp_type, "passive") == 0)
+                        cand->transport = PJ_CAND_TCP_PASSIVE;
+                    else if (strcmp(tcp_type, "so") == 0)
+                        cand->transport = PJ_CAND_TCP_SO;
+                    else {
+                        PJ_LOG(1,
+                               (THIS_FILE, "Error: invalid transport type '%s'", tcp_type));
+                        goto on_error;
+                    }
+                } else {
+                    cand->transport = PJ_CAND_UDP;
+                }
+
+                cand->comp_id = (pj_uint8_t)comp_id;
+                pj_strdup2(icedemo.pool, &cand->foundation, foundation);
+                cand->prio = prio;
+
+                if (strchr(ipaddr, ':'))
+                    af = pj_AF_INET6();
+                else
+                    af = pj_AF_INET();
+
+                tmpaddr = pj_str(ipaddr);
+                pj_sockaddr_init(af, &cand->addr, NULL, 0);
+                status = pj_sockaddr_set_str_addr(af, &cand->addr, &tmpaddr);
+                if (status != PJ_SUCCESS) {
+                    PJ_LOG(1, (THIS_FILE, "Error: invalid IP address '%s'", ipaddr));
+                    goto on_error;
+                }
+
+                pj_sockaddr_set_port(&cand->addr, (pj_uint16_t)port);
+
+                ++icedemo.rem.cand_cnt;
+
+                if (cand->comp_id > icedemo.rem.comp_cnt)
+                    icedemo.rem.comp_cnt = cand->comp_id;
+            } else if (strcmp(attr, "setup") == 0) {
+                // TODO
+            } else if (strcmp(attr, "connection") == 0) {
+                // TODO
+            }
+        } break;
+        }
     }
 
-    if (icedemo.rem.cand_cnt==0 ||
-	icedemo.rem.ufrag[0]==0 ||
-	icedemo.rem.pwd[0]==0 ||
-	icedemo.rem.comp_cnt == 0)
-    {
-	PJ_LOG(1, (THIS_FILE, "Error: not enough info"));
-	goto on_error;
+    if (icedemo.rem.cand_cnt == 0 || icedemo.rem.ufrag[0] == 0 ||
+        icedemo.rem.pwd[0] == 0 || icedemo.rem.comp_cnt == 0) {
+        PJ_LOG(1, (THIS_FILE, "Error: not enough info"));
+        goto on_error;
     }
 
-    if (comp0_port==0 || comp0_addr[0]=='\0') {
-	PJ_LOG(1, (THIS_FILE, "Error: default address for component 0 not found"));
-	goto on_error;
+    if (comp0_port == 0 || comp0_addr[0] == '\0') {
+        PJ_LOG(1, (THIS_FILE, "Error: default address for component 0 not found"));
+        goto on_error;
     } else {
-	int af;
-	pj_str_t tmp_addr;
-	pj_status_t status;
+        int af;
+        pj_str_t tmp_addr;
+        pj_status_t status;
 
-	if (strchr(comp0_addr, ':'))
-	    af = pj_AF_INET6();
-	else
-	    af = pj_AF_INET();
+        if (strchr(comp0_addr, ':'))
+            af = pj_AF_INET6();
+        else
+            af = pj_AF_INET();
 
-	pj_sockaddr_init(af, &icedemo.rem.def_addr[0], NULL, 0);
-	tmp_addr = pj_str(comp0_addr);
-	status = pj_sockaddr_set_str_addr(af, &icedemo.rem.def_addr[0],
-					  &tmp_addr);
-	if (status != PJ_SUCCESS) {
-	    PJ_LOG(1,(THIS_FILE, "Invalid IP address in c= line"));
-	    goto on_error;
-	}
-	pj_sockaddr_set_port(&icedemo.rem.def_addr[0], (pj_uint16_t)comp0_port);
+        pj_sockaddr_init(af, &icedemo.rem.def_addr[0], NULL, 0);
+        tmp_addr = pj_str(comp0_addr);
+        status = pj_sockaddr_set_str_addr(af, &icedemo.rem.def_addr[0], &tmp_addr);
+        if (status != PJ_SUCCESS) {
+            PJ_LOG(1, (THIS_FILE, "Invalid IP address in c= line"));
+            goto on_error;
+        }
+        pj_sockaddr_set_port(&icedemo.rem.def_addr[0], (pj_uint16_t)comp0_port);
     }
 
-    PJ_LOG(3, (THIS_FILE, "Done, %d remote candidate(s) added", 
-	       icedemo.rem.cand_cnt));
+    PJ_LOG(3, (THIS_FILE, "Done, %d remote candidate(s) added",
+               icedemo.rem.cand_cnt));
     return;
 
 on_error:
@@ -1193,18 +1242,18 @@ static void icedemo_usage()
 int main(int argc, char *argv[])
 {
     struct pj_getopt_option long_options[] = {
-	{ "comp-cnt",           1, 0, 'c'},
-	{ "nameserver",		1, 0, 'n'},
-	{ "max-host",		1, 0, 'H'},
-	{ "help",		0, 0, 'h'},
-	{ "stun-srv",		1, 0, 's'},
-	{ "turn-srv",		1, 0, 't'},
-	{ "turn-tcp",		0, 0, 'T'},
-	{ "turn-username",	1, 0, 'u'},
-	{ "turn-password",	1, 0, 'p'},
-	{ "turn-fingerprint",	0, 0, 'F'},
-	{ "regular",		0, 0, 'R'},
-	{ "log-file",		1, 0, 'L'},
+        { "comp-cnt",           1, 0, 'c'},
+        { "nameserver",		1, 0, 'n'},
+        { "max-host",		1, 0, 'H'},
+        { "help",		0, 0, 'h'},
+        { "stun-srv",		1, 0, 's'},
+        { "turn-srv",		1, 0, 't'},
+        { "turn-tcp",		0, 0, 'T'},
+        { "turn-username",	1, 0, 'u'},
+        { "turn-password",	1, 0, 'p'},
+        { "turn-fingerprint",	0, 0, 'F'},
+        { "regular",		0, 0, 'R'},
+        { "log-file",		1, 0, 'L'},
     };
     int c, opt_id;
     pj_status_t status;
@@ -1213,57 +1262,58 @@ int main(int argc, char *argv[])
     icedemo.opt.max_host = -1;
 
     while((c=pj_getopt_long(argc,argv, "c:n:s:t:u:p:H:L:hTFR", long_options, &opt_id))!=-1) {
-	switch (c) {
-	case 'c':
-	    icedemo.opt.comp_cnt = atoi(pj_optarg);
-	    if (icedemo.opt.comp_cnt < 1 || icedemo.opt.comp_cnt >= PJ_ICE_MAX_COMP) {
-		puts("Invalid component count value");
-		return 1;
-	    }
-	    break;
-	case 'n':
-	    icedemo.opt.ns = pj_str(pj_optarg);
-	    break;
-	case 'H':
-	    icedemo.opt.max_host = atoi(pj_optarg);
-	    break;
-	case 'h':
-	    icedemo_usage();
-	    return 0;
-	case 's':
-	    icedemo.opt.stun_srv = pj_str(pj_optarg);
-	    break;
-	case 't':
-	    icedemo.opt.turn_srv = pj_str(pj_optarg);
-	    break;
-	case 'T':
-	    icedemo.opt.turn_tcp = PJ_TRUE;
-	    break;
-	case 'u':
-	    icedemo.opt.turn_username = pj_str(pj_optarg);
-	    break;
-	case 'p':
-	    icedemo.opt.turn_password = pj_str(pj_optarg);
-	    break;
-	case 'F':
-	    icedemo.opt.turn_fingerprint = PJ_TRUE;
-	    break;
-	case 'R':
-	    icedemo.opt.regular = PJ_TRUE;
-	    break;
-	case 'L':
-	    icedemo.opt.log_file = pj_optarg;
-	    break;
-	default:
-	    printf("Argument \"%s\" is not valid. Use -h to see help",
-		   argv[pj_optind]);
-	    return 1;
-	}
+        switch (c) {
+        case 'c':
+            icedemo.opt.comp_cnt = atoi(pj_optarg);
+            if (icedemo.opt.comp_cnt < 1 ||
+                icedemo.opt.comp_cnt >= PJ_ICE_MAX_COMP) {
+                puts("Invalid component count value");
+                return 1;
+            }
+            break;
+        case 'n':
+            icedemo.opt.ns = pj_str(pj_optarg);
+            break;
+        case 'H':
+            icedemo.opt.max_host = atoi(pj_optarg);
+            break;
+        case 'h':
+            icedemo_usage();
+            return 0;
+        case 's':
+            icedemo.opt.stun_srv = pj_str(pj_optarg);
+            break;
+        case 't':
+            icedemo.opt.turn_srv = pj_str(pj_optarg);
+            break;
+        case 'T':
+            icedemo.opt.ice_tcp = PJ_TRUE;
+            break;
+        case 'u':
+            icedemo.opt.turn_username = pj_str(pj_optarg);
+            break;
+        case 'p':
+            icedemo.opt.turn_password = pj_str(pj_optarg);
+            break;
+        case 'F':
+            icedemo.opt.turn_fingerprint = PJ_TRUE;
+            break;
+        case 'R':
+            icedemo.opt.regular = PJ_TRUE;
+            break;
+        case 'L':
+            icedemo.opt.log_file = pj_optarg;
+            break;
+        default:
+            printf("Argument \"%s\" is not valid. Use -h to see help",
+                   argv[pj_optind]);
+            return 1;
+        }
     }
 
     status = icedemo_init();
     if (status != PJ_SUCCESS)
-	return 1;
+        return 1;
 
     icedemo_console();
 
diff --git a/pjsip/src/pjsua-lib/pjsua_core.c b/pjsip/src/pjsua-lib/pjsua_core.c
index 474a8d07c..9257f07a4 100644
--- a/pjsip/src/pjsua-lib/pjsua_core.c
+++ b/pjsip/src/pjsua-lib/pjsua_core.c
@@ -1548,7 +1548,7 @@ static void resolve_stun_entry(pjsua_stun_resolve *sess)
 	stun_sock_cb.on_status = &test_stun_on_status;
 	sess->async_wait = PJ_FALSE;
 	status = pj_stun_sock_create(&pjsua_var.stun_cfg, "stunresolve",
-				     sess->af, &stun_sock_cb,
+				     sess->af, PJ_STUN_TP_UDP, &stun_sock_cb,
 				     NULL, sess, &sess->stun_sock);
 	if (status != PJ_SUCCESS) {
 	    char errmsg[PJ_ERR_MSG_SIZE];
-- 
2.24.1

